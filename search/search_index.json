{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Open MSCS","text":"<p>Open MSCS is an open source compendium of computer science course notes at the graduate level. You may find them useful for review if you are making your way through Georgia Tech's OMSCS program. </p> <p>Explore the site to find other helpful resources and tips for your graduate career!</p>"},{"location":"#quick-links","title":"Quick Links","text":"<p>Read crowdsourced ratings and reviews for OMSCS courses at OMSCentral.</p> <p>Join us and chat! The OMSCS Study Group Slack and r/OMSCS can be terribly distracting places to ask questions.</p>"},{"location":"grad-life-resources/","title":"Graduate Life Resources","text":""},{"location":"grad-life-resources/#course-work","title":"Course Work","text":"<ul> <li>Scribbr APA Citation Generator: makes generating citations and references near-painless.</li> <li>CyberChef a web app for data transformations: encryption, encoding, compression and data analysis. Open source on GitHub.</li> </ul>"},{"location":"grad-life-resources/#health","title":"Health","text":"<ul> <li>CalmyLeon: fully customizable sound generator with everything from nature sounds, rain, and abstract music to provide a backdrop to your studies.</li> <li>Sound of Colleagues: a more office or cafe-like background sound generator.</li> <li>Wakeout: gets you moving to refresh your brain -- break up a long study session.</li> </ul>"},{"location":"course-notes/","title":"OMSCS Course Notes","text":"<p>Choose a course to start learning, or use the search box to hunt for something in particular.</p> <p>Contributions and updates are welcome. You can join our open source project on GitHub!</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/","title":"Cyber-Physical Systems Security","text":"<p>Cyber-physical systems (CPS) integrate computing (processes, systems) and the physical world (processes, environments). Consequences can be more dire than in cyberspace: there's no \"rollback\" in the real world.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#textbooks","title":"Textbooks","text":"<ul> <li>Industrial Network Security, Second Edition: Securing Critical Infrastructure Networks for Smart Grid, SCADA, and Other Industrial Control Systems (2nd Edition), by Eric D. Knapp and Joel Thomas Langill, ISBN: 978-0124201149</li> <li>Applied Cyber Security and the Smart Grid: Implementing Security Controls into the Modern Power Infrastructure (1st Edition), by Eric D. Knapp and Raj Samani, ISBN: 978-1597499989</li> <li>Hacking Exposed Industrial Control Systems: ICS and SCADA Security Secrets &amp; Solutions (1st Edition), by Clint Bodungen, Bryan Singer, Aaron Shbeeb, Kyle Wilhoit, and Stephen Hilt, ISBN: 978-1259589713</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#security-goals","title":"Security Goals","text":"<ul> <li>Assurance: how trust is provided and managed</li> <li>Authentication: ability to determine that something is genuine</li> <li>Authorization: ensuring necessary permissions for an action</li> <li>Availability: accessibility of information in a timely manner</li> <li>Integrity: ensuring that information has not been altered</li> <li>Confidentiality: maintaining secrecy</li> </ul> <p>The main goal of a CPS is availability, while the typical goal of IT security is confidentiality.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#security-concepts-to-review","title":"Security Concepts to Review","text":"<ul> <li>Access control</li> <li>Symmetric and asymmetric encryption</li> <li>Public key cryptography and distribution</li> <li>Digital signatures</li> <li>Hash functions</li> <li>Message authentication</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#ten-security-principles","title":"Ten Security Principles","text":"<ol> <li>Economy of mechanism: complexity is the enemy of security, choose simplicity</li> <li>Fail-safe defaults: default behavior of a system should be the secure option</li> <li>Complete mediation: every access to a resource is checked for compliance to an authorization scheme, e.g. getting on a flight, session timeouts.</li> <li>Open design: open source systems can be examined and verified</li> <li>Separation of privilege: access should be granted only for the purpose of the access; i.e. separate groups reduces attack surface if unauthorized access is gained (see Security Zones)</li> <li>Least privilege: systems should grant the bare minimum privileges necessary for a task</li> <li>Least common mechanism: shared resources should be minimized, e.g. having separate user accounts</li> <li>Psychological accessibility: security should be intuitive for the user (if you make it too complicated, no one will do it)</li> <li>Work factor: security measures should not be unnecessarily excessive -- what will suffice?</li> <li>Compromise recording: it may make more sense to record a compromise than stop it</li> </ol>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#cps-challenges","title":"CPS Challenges","text":"<ul> <li>Interoperability: systems need to work together, i.e. compatible standards</li> <li>Predictability: system state and functionality, high predictability means reliability</li> <li>Reliability: degree of correctness</li> <li>Sustainability: efficiency, dynamic evolving</li> <li>Dependability: trust in the system, not failing</li> <li>Security: integrity and confidentiality</li> </ul> <p>Considerations for CPS include:</p> <ul> <li>Countermeasures: designing attack-resilient algorithms and systems</li> <li>Compliance with standards and regulation</li> <li>Detection and recovery: training operations in response, reconfiguration, fault detection, isolation</li> <li>Resilience and redundancy to guarantee availability</li> <li>Legislation and enforcement</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#networks","title":"Networks","text":"<ul> <li>Body Area Network (BAN): wearables, smartphone</li> <li>Local Area Network (LAN)</li> <li>Metropolitan Area Network (MAN)</li> <li>Wide Area Network (WAN): Internet</li> </ul> <p>Network segmentation can support security zones. Logical segments include:</p> <ul> <li>Public networks, e.g. Internet</li> <li>Business networks</li> <li>Operations networks</li> <li>Plant control networks</li> <li>Supervisory control networks<ul> <li>ICS servers, workstations, HMI</li> </ul> </li> <li>Basic or local control networks<ul> <li>Controllers, PLC, RTU, field devices, IED, subsystems</li> </ul> </li> <li>Process networks<ul> <li>Device network, analyzer network, equipment monitoring, automation systems</li> </ul> </li> <li>SIS and devices (see Safety Instrumented Systems (SIS))</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#network-topologies","title":"Network Topologies","text":"<ul> <li>Bus: all nodes are connected to one cable<ul> <li>Linear, serial, multiple devices via taps</li> <li>Shared resources, so limited reliability</li> <li>For a small number of devices</li> </ul> </li> <li>Mesh: each device is connected to all others, e.g. wireless<ul> <li>Maximum performance and uptime</li> <li>Redundant and fault-tolerant</li> <li>Expensive when wired</li> <li>Wireless mesh can be limited by power availability</li> </ul> </li> <li>Star: point-to-multi-point network with a central support</li> <li>Branch or tree: a trunk topology supporting additional branches</li> <li>Ring: circular serial nodes<ul> <li>provides redundancy</li> <li>for network access switches</li> </ul> </li> <li>Multihoming or dual-homing: single node connected to two or more networks<ul> <li>not recommended, instead use DMZ or read-only data diode or unidirectional gate</li> </ul> </li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#network-architecture-importance","title":"Network Architecture Importance","text":"Focus Industrial Command and Control Industrial Supervisory Business Network Real-time operation Critical High Best-effort Reliability or resiliency Critical High Best-effort Bandwidth Low Medium High Sessions Few, defined Few Many Latency Low, consistent Low, consistent Retransmission is OK Network Serial, ethernet Ethernet Ethernet Protocols Real-time, proprietary Not real-time, open Not real-time, open"},{"location":"course-notes/cpss/cyber-physical-systems-security/#network-considerations","title":"Network Considerations","text":"<ul> <li>Latency: round-trip time for a packet to traverse a network from source to destination<ul> <li>Consideration for data historians, choice of database, network hops, deep packet inspection</li> </ul> </li> <li>Jitter: variability in latency over time<ul> <li>Severe latency can affect vital precision for ICS</li> </ul> </li> <li>Bandwidth: total amount of data transmitted over a given period, e.g. MB/s or GB/s<ul> <li>Most ICS need low bandwidth but have bursts</li> </ul> </li> <li>Contention: competition between different active nodes in a segment</li> <li>Throughput: volume of data that can physically flow through a network<ul> <li>Affected by cabling, interfaces, MAC, protocol choice, application, network, packets per second</li> </ul> </li> </ul> <p>Quality of Service (QoS) is the ability to prioritize some types of traffic over other types. Traffic between a PLC and HMI needs to be prioritized so that the most critical communication isn't delayed. To identify important traffic, Type of Service (ToS) and Class of Service (CoS) are used.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#osi-model","title":"OSI Model","text":"<p>The Open Systems Interconnection (OSI) conceptual model has seven layers describing functionality.</p> Layer Protocols Data Type Function Application FTP, HTTP, SMTP, TFTP, DNS, SNMP, DHCP (most common ICS protocols are here) Message data High-level application APIs Presentation Message data Character encoding, compression, encryption and decryption Session Message data Communication session management Transport UDP, TCP, SCTP Segment, datagram Transmission of data; end-to-end communications over a network, including segmentation, acknowledgement, multiplexing Network IP, IPX, IGMP, ICMP, ARP Packets Addressing, routing, traffic control Data link 802.11 (wireless), Ethernet, LAN, WAN Frame Transmission of data frames between nodes physically connected Physical Bits Bits Transmission of raw bit stream over physical medium"},{"location":"course-notes/cpss/cyber-physical-systems-security/#tcp-vs-udp","title":"TCP vs. UDP","text":"<p>Transmission Control Protocol(TCP) is a byte stream without record bounds. User Datagram Protocol (UDP) sends connectionless diagrams.</p> <p>TCP offers reliability, retries, and flow control using a sliding window.</p> <p>See What is TCP/IP? Layers and protocols explained.</p> <p>TCP IP addressing examples (these don't correspond to the layers directly):</p> Layer Type Example Application Message Application-specific addresses <code>data[]</code> Transport Segment Port <code>80</code> Network Datagram Logical addresses <code>192.168.11</code> Data link Frame Physical addresses <code>12::34::56::78::9A::BC</code> Physical Bits <code>100101010</code> <p>A three-way TCP handshake has these steps:</p> <ol> <li>Sender sends initial sequence number (SYN)</li> <li>Receiver sends its initial sequence number with acknowledgement appended (ACK)</li> <li>Sender acknowledges receiver's acknowledgement with another appendage</li> </ol> <p>See What is TLS? Transport Layer Security encryption explained in plain english.</p> <p>TCP connection termination has these steps:</p> <ol> <li>Sender sends active close (FIN)</li> <li>Receiver sends ACK</li> <li>Receiver sends FIN</li> <li>Sender sends ACK</li> </ol>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#industrial-control-systems-ics","title":"Industrial Control Systems (ICS)","text":"<p>ICSs can be...</p> <ul> <li>Open-Loop: one-way flow, no feedback<ul> <li>Desired output &gt; controller &gt; actuator &gt; process &gt; output</li> </ul> </li> <li>Closed-Loop: additional control of output based on feedback signal compared to desired output<ul> <li>Desired output &gt; error &gt; controller &gt; actuator &gt; process &gt; actual output &gt; feedback &gt; adjust controller</li> <li>A fully automated loop means the process is controlled by comparing established set points against inputs</li> </ul> </li> <li>Multiloop Feedback Control System: same as closed-loop but more feedback loops</li> </ul> <p>Actuators include:</p> <ul> <li>Valves</li> <li>Boiler, Turbine, shaft, generators that carry output to someplace else</li> </ul> <p>Controllers include:</p> <ul> <li>Computers</li> <li>Speed generators</li> </ul> <p>Sensors include things that take measurements.</p> <p>The ISA95 is a standard for integration of enterprise and production control systems.</p> <p></p> <p>It defines these levels:</p> <ul> <li>L4: Business planning and logistics</li> <li>L3: Manufacturing operations and control</li> <li> <p>L2-L0:</p> <ul> <li>Batch, continuous, or discrete control</li> <li>Field devices and networks</li> <li>PLC, SCADA, HMI</li> </ul> </li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#ics-devices","title":"ICS Devices","text":"<ul> <li>Remote Terminal Unit (RTU)</li> <li>Intelligent Electronic Device (IED): supports specific function, e.g. managing unstable voltage</li> <li>Human-Machine Interface (HMI): the operator's buttons<ul> <li>Simplifies PLC logic</li> <li>Security relies on access control here</li> <li>Common attack vector</li> <li>Sends feedback that becomes input for control loops</li> </ul> </li> <li>Supervisory Workstations: a HMI with admin mode<ul> <li>Remote monitor</li> <li>May be a read-only dashboard</li> </ul> </li> <li>Data Historian: keeps historized data that can be analyzed for optimization<ul> <li>Interoperates with ICS server</li> <li>Hardened, strict user access controls</li> </ul> </li> <li>Business Information Console: provides business intelligence to upper management<ul> <li>Usually has the same data as HMI historian</li> <li>May be physical console, or remote HMI/historian</li> <li>The best place to isolate the process control network from outside systems</li> <li>Needs network security since the business info is kept outside of process control</li> </ul> </li> <li>Process Management: HMI control point with real-time information<ul> <li>Allows manually affecting output of the control loop (force) by translating function code to human-readable controls (a GUI)</li> <li>These have various protocols and are typically written in vendor-proprietary code</li> <li>Important to security, as a compromise can permanently alter systems (see The Real Story of Stuxnet)</li> </ul> </li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#programming-ics","title":"Programming ICS","text":"<p>A Programmable Logic Controller (PLC) has these components:</p> <ul> <li>Power supply (AC/DC)</li> <li>Communication module(s) (to talk to other PLCs, packaged equipment)</li> <li>Control processor</li> <li>Input module(s) (sensors)</li> <li>Output module(s) (actuators)</li> </ul> <p>A PLC scan (loop) has these steps:</p> <ol> <li>Check input status</li> <li>Execute program</li> <li>Update output status</li> </ol> <p>The IEC (International Electrotechnical Commission) officially recognizes five PLC programming languages in the IEC61131-3 Standard. They are Ladder Diagram (LD), Function Block (FBD), Structured Text (ST), Instruction List (IL), and Sequential Function Chart (SFC) (Source)</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#critical-infrastructure","title":"Critical Infrastructure","text":"<p>Initially defined in Homeland Security Presidential Directive 7 (HSPD-7) and revoked and redefined in Presidential Policy Directive 21 (PPD-21), critical infrastructure is described as these 16 sectors:</p> <ol> <li>Banking and finance</li> <li>Chemical</li> <li>Information technology</li> <li>Critical manufacturing</li> <li>Defense industrial base</li> <li>Food and agriculture</li> <li>Commercial facilities</li> <li>Communications</li> <li>Dams</li> <li>Emergency services</li> <li>Energy</li> <li>Government facilities</li> <li>Health care and public health</li> <li>Nuclear reactors, materials, waste</li> <li>Transportation systems</li> <li>Water and waste water systems</li> </ol>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#remote-access-controls","title":"Remote Access Controls","text":"<p>Considerations for remote access include:</p> <ul> <li>Minimizing attack vectors</li> <li>Least privilege (see Ten Security Principles)</li> <li>Minimal access paths</li> <li>Further segmentation:<ul> <li>Application control (limit remote users to certain authorized applications)</li> <li>No direct access to critical systems</li> <li>A strong security policy</li> <li>Avoidance of remote credential storage</li> <li>Ability to terminate the remote connection locally</li> <li>Log all the things</li> </ul> </li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#safety-instrumented-systems-sis","title":"Safety Instrumented Systems (SIS)","text":"<p>A SIS is a dedicated controller or logic solver designed to protect against the effects of an attack by reacting to unsafe conditions. A SIS is designed specifically for its purpose, e.g. providing protection at a gas refinery, or chemical or nuclear facility.</p> <p>The IEC 61511 standard describes design and management for SISs and describes Safety Integrity Levels (SIL) 1-4. See a description of the standard and purposes: S84 / IEC 61511 Standard for Safety Instrumented Systems.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#industrial-network-protocols","title":"Industrial Network Protocols","text":""},{"location":"course-notes/cpss/cyber-physical-systems-security/#fieldbus","title":"Fieldbus","text":"<p>Fieldbus is a category of protocols commonly found in process and control between sensors and actuators and their corresponding PLCs. A standard of nine protocol profiles was introduced in IEC 61784:</p> <ol> <li>FOUNDATION Fieldbus</li> <li>CIP</li> <li>PROFIBUS/PROFINET</li> <li>P-NET</li> <li>WorldFIP</li> <li>INTERBUS</li> <li>CC-Link</li> <li>HART</li> <li>SERCOS</li> </ol>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#modbus","title":"Modbus","text":"<p>Modicon communication bus (Modbus) was designed in 1979 and, as an open standard, is widely used today. It operates at the application layer of the TCP/IP protocol stack.</p> <p>Modbus on its own lacks security. There's no:</p> <ul> <li>Authentication</li> <li>Encryption</li> <li>Checksums</li> <li>Broadcast suppression (all devices receive all messages)</li> </ul> <p>Security recommendations include:</p> <ul> <li>Use of an ICS-aware IDS to monitor communications</li> <li>Fingerprint normal behavior patterns to facilitate whitelisting</li> <li>Use of an application-aware firewall</li> </ul> <p>A protocol data unit (PDU) consists of a function code and data.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551 Function code \u2551 \u2551               Data               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p>An application data unit (ADU) consists of an address, a PDU, and an error check.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551 Address \u2551 \u2551 Function code \u2551 \u2551               Data               \u2551 \u2551 Error check \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p>The Modbus data specification looks like this:</p> Data table Object type Access Data provided by Discrete input Single bit Read-only Physical I/O Coil Single bit Read-write Application Input register 16-bit word Read-only Physical I/O Holding register 16-bit word Read-only Read-write <p>A Modbus Application Protocol (MBAP) header consists of:</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551 Transaction ID \u2551 \u2551 Protocol ID \u2551 \u2551 Length \u2551 \u2551 Unit ID \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p>Variants of Modbus have been adapted for other purposes, including:</p> <ul> <li>Modbus over TCP/IP<ul> <li>Combines the Modbus Application Protocol (MBAP) header with a Modbus RTU ADU (legacy systems)</li> </ul> </li> <li>Modbus TCP<ul> <li>Combines the MBAP header with only the Modbus RTU PDU (modern)</li> </ul> </li> <li>Modbus RTU (binary)<ul> <li>Has an ADU of maximum 256 bytes</li> </ul> </li> <li>Modbus ASCII<ul> <li>Has an ADU of maximum 510 bytes</li> </ul> </li> <li>Modbus Plus</li> </ul> <p>Modbus is a request-response protocol with three PDUs:</p> <ol> <li>Modbus Request</li> <li>Modbus Response</li> <li>Modbus Exception Response</li> </ol> <p>A typical transaction without errors goes like this:</p> <ol> <li>Client initiates a request, sending the function code and data request</li> <li>Server performs the action and initiates a response, sending the function code and data response</li> <li>Client receives response</li> </ol> <p>Each device communicating via Modbus needs a specific address. Capturing packets with Wireshark is a great way to observe Modbus in action.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#distributed-network-protocol-dnp3","title":"Distributed Network Protocol (DNP3)","text":"<p>Designed for use in electric utility and extended for oil and gas, water, and wastewater, with specific features that apply to these industries, including:</p> <ul> <li>Report by exception</li> <li>Data quality indicators</li> <li>Time-stamped data including sequence-of-events, to aid reconstruction</li> <li>\"Select before operate\" two-pass procedure on outputs</li> </ul> <p>DNP3 is reliable and efficient, and well suited for real-time data transfer:</p> <ul> <li>Cyclical redundancy checks</li> <li>Optional link-layer acknowledgements</li> <li>Retransmission of faulty frames</li> </ul> <p>Two types of data:</p> <ul> <li>Static data, or class 0: represents a static value</li> <li>Event data, or class 1, 2, or 3 by priority: represents a change</li> </ul> <p>Communication is initiated from the master station to the slave outstation:</p> <ol> <li>Master sends request message</li> <li>Slave sends response message</li> <li>Master confirms (ACK)</li> </ol> <p>DNP3 also supports unsolicited responses for alarms:</p> <ol> <li>Slave sends unsolicited response</li> <li>Master confirms (ACK)</li> </ol> <p>Every DNP3 device needs a unique address.</p> <p>DNP3 lacks security. There's no:</p> <ul> <li>Authentication</li> <li>Encryption</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#secure-dnp3","title":"Secure DNP3","text":"<p>This DNP3 variant adds authentication to the response-request process, issued as a challenge by the receiving device. A unique session key is hashed with the message data to verify authority, integrity, and pairing. It can also operate over TLS for confidentiality.</p> <p>Secure DNP3 operates at the application layer of the TCP/IP protocol stack as a payload of the TCP/IP packet.</p> <pre><code>\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 IP Packet \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Payload \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                                                \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 DNP3 LPDU \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  HDLC  \u2551 \u2551 Source/Destination MAC \u2551 \u2551 Source/Destination IP \u2551 \u2551 DNP3 Header \u2551 \u2551 DNP3 Payload \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p>The process for critical requests looks like this:</p> <ol> <li>Master sends request message</li> <li>Slave sends authentication challenge</li> <li>Master sends authentication response</li> <li>Slave confirms ACK</li> <li>Slave sends response message</li> <li>Master confirms ACK</li> </ol>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#process-fieldbus-profibus","title":"Process Fieldbus (PROFIBUS)","text":"<p>Designed in late 1980s to allow PLCs to communicate with host computers, there are a number of specialized variants:</p> <ul> <li>PROFIBUS PA: for instrumentation for process automation<ul> <li>Developed to address needs of field instrumentation in hazardous areas (explosive vapors, dust)</li> <li>Uses intrinsic safety concept to to limit power on communication lines so that dust or vapor in the vicinity will not be ignited</li> </ul> </li> <li>PROFIsafe: safety applications</li> <li>PROFIdrive: high-speed drive applications</li> <li>PROFIBUS DP (decentralized periphery): the most widely deployed variant, and it's turtles all the way down...<ul> <li>PROFIBUS DP-V0</li> <li>PROFIBUS DP-V1</li> <li>PROFIBUS DP-V2</li> <li>These three variants are minor upgrade versions of the former</li> </ul> </li> </ul> <p>PROFIBUS communications have three profiles: asynchronous, synchronous, and via Ethernet (ethertype 0x8892) -- also called PROFINET.</p> <p>PROFIBUS uses token sharing to allow multiple master nodes (PLCs or RTUs) to communicate with its slaves (sensor, motor, or other control system device). Slaves can initiate communication to their master node or other slaves.</p> <p>PROFIBUS lacks security. There's no authentication (a spoofed node could impersonate a master node), but as it uses a naturally segmented serial network, compromise requires physical access. Stuxnet is an example of PROFIBUS exploitation.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#industrial-ethernet","title":"Industrial Ethernet","text":"<p>Adapts the IEEE 802.3 Ethernet standard to real-time industrial automation applications and provides physical enhancements to harden Ethernet, such as more rugged wiring, connectors, and hardware designed for industrial application. Some considerations:</p> <ul> <li>Electrical noise and interference (EMI)</li> <li>Vibration</li> <li>Extended temperatures and humidity</li> <li>Power requirements</li> <li>Support of real-time performance: low latency, low jitter, minimal packet loss</li> </ul> <p>There are 30 different varieties of Industrial Ethernet, because apparently we can't all just get along.</p> <p>The five most widely-accepted are:</p> <ol> <li>EtherNet/IP<ul> <li>Based on TCP/IP</li> <li>Real-time protocol using TCP and UDP</li> <li>Susceptible to any vulnerabilities of its underlying protocols</li> </ul> </li> <li>PROFINET<ul> <li>Based on TCP/IP</li> <li>Open standard (IEC 61158 and IEC 61784)</li> <li>Version 1: standard Ethernet and TCP/IP</li> <li>Version 2: software-based Real Time (RT) support with cycle times of 5-10ms</li> <li>Version 3: Isochronous Real Time (IRT) with cycle times of less than 1ms and jitter less than 1ms</li> <li>Susceptible to any vulnerabilities of its underlying protocols</li> </ul> </li> <li>EtherCAT<ul> <li>Direct Ethernet access</li> <li>Communicates large amounts of data over a single Ethernet frame</li> <li>Short cycle time, low jitter: only 1-2 frames required for a complete cycle</li> <li>Susceptible to any Ethernet vulnerabilities</li> <li>Highly susceptible to DoS attack</li> </ul> </li> <li>Ethernet POWERLINK<ul> <li>Direct Ethernet access</li> <li>Based on Fast Ethernet with direct encapsulation of Ethernet frames</li> <li>Three time periods: \"start of cycle\" frame, synchronous phase, then asynchronous phase</li> <li>Depends on controlled request-response cycles: susceptible to disruption</li> <li>Highly susceptible to DoS attack</li> <li>Susceptible to any Ethernet vulnerabilities</li> </ul> </li> <li>SERCOS III (Serial Real-Time Communication System)<ul> <li>Direct Ethernet access</li> <li>Deterministic real-time motion control and I/O applications</li> <li>High-speed, low jitter</li> <li>Network supports up to 511 slave devices in ring or straight topologies</li> <li>Cyclical master-slave protocol</li> <li>Susceptible to any Ethernet vulnerabilities</li> <li>When option to support embedded open TCP/IP and UDP/IP communications is enabled, a device using SERCOS III could launch an inbound attack to other systems</li> </ul> </li> </ol> <p>Security support for all these protocols include:</p> <ul> <li>Use of an ICS-aware IDS to monitor communications</li> <li>Use of an application-aware firewall</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#backend-protocols","title":"Backend Protocols","text":""},{"location":"course-notes/cpss/cyber-physical-systems-security/#open-process-communications-opc","title":"Open Process Communications (OPC)","text":"<p>A series of standard specifications (not actually a protocol) released in 1996 (referred to as OPC Classic). It provides a mechanism for various technologies to exchange data at a higher level than fieldbus. As a Windows interconnection, these technologies include:</p> <ul> <li>Object Linking and Embedded (OLE)</li> <li>Component Object Model (COM)</li> <li>Distributed Component Object Model (DCOM)</li> </ul> <p>A client application calls a local process that is executed on a remote server. A remote procedure call (RPC) is used to provide functionality. Roughly, this takes the form:</p> <ol> <li>OPC client establishes a connection to the OPC server</li> <li>OPC server communicates with a data source via native protocol (Modbus, DNP3, etc.)</li> <li>OPC server receives data.</li> <li>OPC client receives data over the network and provides it to the requesting application.</li> </ol> <p>OPC security concerns include:</p> <ul> <li>Use of DCOM and RPC, vulnerable to multiple attack vectors</li> <li>Host security concerns due to Windows support</li> <li>Legacy authentication services</li> </ul> <p>The newer Unified Architecture (OPC-UA) should be used over OPC Classic.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#inter-control-center-communications-protocol-iccp","title":"Inter-Control Center Communications Protocol (ICCP)","text":"<p>Designed for bidirectional Wide-Area Network (WAN) communication between a utility control center and other control centers, power plants, and substations.</p> <p>Used for:</p> <ul> <li>Establishing connection</li> <li>Accessing information (read requests)</li> <li>Information transmission</li> <li>Notifications of changes, alarms, exceptions</li> <li>Configuring remote devices</li> <li>Control of operating programs</li> </ul> <p>A bilateral table is used to define permissions to control access for each control center. It works like this:</p> <ol> <li>Client sends request</li> <li>Server checks bilateral table to validate permissions</li> <li>Server returns response</li> </ol> <p>Security concerns include:</p> <ul> <li>Lack of authentication and encryption</li> <li>Exploitation of bilateral tables to explicitly define trust</li> <li>High accessibility</li> </ul> <p>Secure ICCP variants incorporating digital certificates should be used where possible.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#iec-61850-standard","title":"IEC 61850 Standard","text":"<p>Designed originally for subsystem automation and adapted for other applications (hydroelectric plants, wind turbines, distribution feeders, high-voltage switch gears).</p> <ul> <li>Configuration by Substation Configuration Language (SCL) (based on XML)</li> <li>Data model and communications model</li> <li>Designed to run on standard Ethernet LAN</li> <li>Fiber optics has the advantages of avoid electromagnetic interference, prevent unplanned power conductors, and permit high throughput</li> <li>Seeks to be the single complete standard for configuration, monitoring, reporting, storing, and communicating</li> </ul> <p></p> <p>Classes of communications protocols:</p> <ul> <li>Machine-to-machine (M2M)<ul> <li>Based on Generic Substation Event (GSE) protocol (P2P layer 2 multicast)</li> <li>Generic Substation State Events (GSSE) and Generic Object Oriented Substation Events (GOOSE)</li> <li>GOOSE is most common and was designed to operate at layer 2 of the OSI model (link layer) to ensure 4ms performance requirement</li> </ul> </li> <li>Client-server</li> <li>Configuration protocols</li> </ul> <p>Doesn't include security specifications on its own (they're in IEC 62351-6):</p> <ul> <li>Requires TLS</li> <li>Use VLANs for protection (encryption would be too slow for GOOSE)</li> <li>VLANs can be spoofed</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#smart-grid","title":"Smart Grid","text":"<p>Many interconnected and inter-communicating systems using open and proprietary protocols, including:</p> <ul> <li>Billing systems</li> <li>Bulk electric generation systems</li> <li>Customer information and management systems</li> <li>Electric distribution systems</li> <li>Electric transmission systems</li> <li>Load management systems</li> <li>Meteorological and environment monitoring systems</li> <li>Meter data management systems<ul> <li>Smart meter device logs</li> <li>Storage of usage statistics</li> </ul> </li> <li>Protection systems</li> <li>Substation automation systems</li> </ul> <p>To remain available, the smart grid needs to have high resiliency. Threats to resiliency include:</p> <ul> <li>Growing demand and peak demand for resources<ul> <li>Baseload, intermediate load, and peak load correspond to rising costs</li> </ul> </li> <li>Cyber attacks</li> </ul> <p>Key components include:</p> <ul> <li>Substation automation</li> <li>Synchronized phasor measurements (using PMU)</li> <li>Advanced Metering Infrastructure</li> </ul> <p>Security strategies include:</p> <ul> <li>Monitoring for situational awareness</li> <li>Risk and threat analysis early in deployment and planning stages</li> <li>Separation of services</li> <li>Defense-in-depth</li> </ul> <p>Cyberattacks specific to the smart grid involve:</p> <ul> <li>Mapping grid architecture through reconnaissance and scanning</li> <li>Identifying and penetrating target systems</li> <li>Propagating throughout a breached system (more connections makes propagation easier)</li> </ul> <p>Common attack motives include:</p> <ul> <li>Information theft for profit or reconnaissance<ul> <li>PII of smart grid consumers</li> <li>Energy consumption information</li> <li>SCADA and automation systems that give operational details of smart grid</li> </ul> </li> <li>DoS</li> <li>Service manipulation, e.g. GPS spoofing to desynchronize phasors</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#generation-system-architecture","title":"Generation System Architecture","text":"<p>Familiarity with general common architectural components can help identify possible risks. Possible risk areas include:</p> <ul> <li>Manipulation of fuel supply</li> <li>Burner controls</li> <li>Valve or flow manipulation</li> <li>Turbine operation</li> <li>Intake pumps</li> <li>Voltage or capacity manipulation</li> <li>Generation SCADA (G-SCADA) for managing automation</li> </ul> <p>Anything with a microprocessor can be compromised, and the manipulation of any one component of a system can compromise the system.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#transmission-system-architecture","title":"Transmission System Architecture","text":"<p>Main focus areas:</p> <ul> <li>Generation control</li> <li>Delivery</li> <li>Energy storage</li> <li>Condition, reserve and interchange management</li> </ul> <p>Highly distributed, highly physically accessible systems covering wide areas. Primary components that present risk if compromised include:</p> <ul> <li>Substations, or yards (substation automation systems)<ul> <li>Provide voltage measurement and regulation, and line protection</li> <li>Handles step-up and step-down of voltage for distribution (see Transformers... below, not the movie)</li> </ul> </li> <li>GPS satellite timing (see PMU)</li> <li>Transmission SCADA (T-SCADA) for managing substation processes</li> <li>Phase measurement unit (PMU) systems and phase data concentrators<ul> <li>A PMU is also called synchrophasor, which sounds like a super 1337 80s-neon cyberweapon.</li> <li>Synchronizes multiple phasor measurements from different points on the grid using GPS, which allows accurate measurement of grid quality (voltage and current)</li> <li>Provides real-time data to TSCADA that is used to manage substation functions</li> <li>Uses IEEE C37.118 standard for phasor measurements (superseded by IEEE/IEC 60255-118-1-2018)<ul> <li>Lacks inherent security, uses intrinsic mechanisms for data and control</li> <li>If not properly protected, measurements can be easily intercepted and manipulated</li> </ul> </li> <li>Commercially produced, support multiple protocols, uses commercial OS like Windows, and are vulnerable to compromise</li> </ul> </li> <li>Line protection systems<ul> <li>Prevent surges (overcurrent) and outages (undercurrent) with breakers, line monitoring systems, automation</li> <li>Built on common commercial OS</li> </ul> </li> <li>Transformers (more than meets the eye)<ul> <li>Step-up for electric transmission, located at transmission system ingress</li> <li>Step-down for end-user consumption, located at transmission system egress to distribution</li> </ul> </li> <li>Gateway enabling communication with control center and WAN<ul> <li>Translates messages using many different protocols (broad attack surface) from substation systems and controllers and between a central transmission control</li> <li>Provides activity logs for the substation, i.e. to historian</li> <li>Prime target for attack as host security or malware prevention here is rare</li> <li>Direct, indirect, remote manipulation from attack will affect many components</li> </ul> </li> <li>Transmission RTU, IED, PMU, and wide area measurement</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#distribution-system-architecture","title":"Distribution System Architecture","text":"<p>Main focus areas:</p> <ul> <li>Load management and modelling</li> <li>Two-way power flow</li> <li>Risk analysis and outage management</li> <li>Dynamic feed or reconfiguration to avoid outages</li> </ul> <p>Primary components that present risk if compromise include:</p> <ul> <li>Distribution SCADA (D-SCADA)<ul> <li>Handles many remote C&amp;C functions, different protocols (broad attack surface)</li> <li>Established communication channel means you can use it to access many connected systems, e.g. AMI or G-SCADA</li> </ul> </li> <li>Field controller (RTU)<ul> <li>Many protocols supported (broad attack surface)</li> <li>Compromise may mess up protection systems, cause random false failures</li> </ul> </li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#advanced-metering-infrastructure-ami","title":"Advanced Metering Infrastructure (AMI)","text":"<p>Primary components:</p> <ol> <li>Smart meters<ul> <li>Solid-state meter with RT data collection</li> <li>Microprocessor and local memory</li> <li>Use of communication network, often including home network (additional attack surface)</li> <li>Diagnostic ports</li> <li>Remote management and configuration via software</li> </ul> </li> <li>Communication network<ul> <li>Broadband over powerline, powerline communications, radio, telecommunication network</li> </ul> </li> <li>AMI server or headend<ul> <li>Software based, commercial OS (usually Windows) and DB</li> </ul> </li> </ol> <p>Common features include:</p> <ul> <li>Remote meter reading</li> <li>Remote billing</li> <li>Demand and response</li> <li>Energy delivery</li> <li>Remote connect/disconnect</li> <li>Remote payment and pre-payment</li> </ul> <p>Common attack targets include:</p> <ul> <li>Meter data management system</li> <li>Customer information system</li> </ul> <p>Security concerns include:</p> <ul> <li>Protocols that vary widely in inherent security and vulnerabilities (broad attack surface)</li> <li>Smart meters are physically accessible and require board and chip security</li> <li>Home and business LAN can be used as ingress to AMI and thus smart grid</li> </ul> <p>Adjacent to Home Area Network (HAN), which provides additional attack entry points:</p> <ul> <li>In-Home Devices (IHD) (smart appliances, like your toaster)</li> <li>Home Energy Management Systems (HEMS)</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#hacking-ics","title":"Hacking ICS","text":"<ul> <li>Security does not lead to safety and vice versa</li> <li>The more details (an attacker has) the more damage (they can inflict)</li> </ul> <p>Possible cyberattack incidents include:</p> <ul> <li>Disrupting feedback loops</li> <li>Changing configuration, PLC logic, RTU programming, or other controllers</li> <li>C&amp;C channels affecting secure systems</li> </ul> <p>Impact of cyberattack on ICS is local, regional, possibly global, and includes:</p> <ul> <li>Damage to equipment, facilities, supply to end users, loss of life</li> <li>Deterioration of business reputation</li> <li>Loss of production and intellectual property</li> </ul> <p>Common targets include:</p> <ul> <li>SCADA servers via control network</li> <li>Engineering workstation (single host with access to configure control mechanisms)</li> <li>Yard protection equipment, e.g. via feeder measurements</li> <li>Energy management systems, e.g. manipulating current load</li> </ul> <p>Common attack methods include:</p> <ul> <li>MitM</li> <li>DoS</li> <li>Replay attack</li> <li>Reverse-engineering devices</li> <li>Use of known unpatched vulnerabilities</li> </ul> <p>Attacks succeed due to:</p> <ul> <li>Insecure communication protocols</li> <li>Lack of device-to-device authentication</li> <li>Fragile communication stacks in embedded devices</li> <li>Using readily available software tools on COTS components</li> </ul> <p>Handling infection (compromise):</p> <ul> <li>Removing malware immediately may activate dormant subsequent malware and removes the ability to learn from the compromise</li> <li>First logically isolate the infected host (remove from network or physical assets)<ul> <li>Possibly continue to allow malware C&amp;C in a sandbox</li> <li>Collect logs and other data for later investigation</li> </ul> </li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#cps-sensory-channel-attacks","title":"CPS Sensory Channel Attacks","text":"<p>Sensors are input for CPS. Sensory channels include:</p> <ul> <li>Visible light<ul> <li>Automatic controls, e.g. brightness control for LCDs</li> <li>Light detection and ranging (LIDAR)</li> <li>Use as side channels for sensitive data</li> </ul> </li> <li>Infrared light<ul> <li>Remote control systems</li> <li>Navigation assistance, obstacle avoidance</li> <li>3D mapping</li> <li>Covert channel support</li> </ul> </li> <li>Acoustic<ul> <li>Obstacle avoidance and map building (short burst sound wave used to take measurements by reflections, with transducers)</li> </ul> </li> <li>Seismic<ul> <li>Accelerometers</li> </ul> </li> </ul> <p>Maliciously, sensory channels can be used as:</p> <ul> <li>Triggers for existing malware on devices</li> <li>Transfer of malware between devices</li> <li>A combination medium with other sensory channels and traditional channels</li> </ul> <p>Conventional security focuses on traditional channels and is not sufficient for novel attacks on sensory channel threats.</p>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#securing-ics","title":"Securing ICS","text":"<p>Main challenges include:</p> <ul> <li>Zero tolerance for false positives</li> <li>Commercial security software may be unsuitable for time-sensitive, high-precision ICS</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#security-zones","title":"Security Zones","text":"<p>Establish security zones (logical or physical asset groups that have common security requirements) and defined conduits for communication. (See Separation of Privilege in Ten Security Principles)</p> <p>Zones can be created according to:</p> <ul> <li>Security level</li> <li>Logical (functional) requirements or discrete functionality</li> <li>Control loop or process</li> <li>Physical asset access</li> <li>Placing trusted and untrusted assets (i.e. those that use insecure protocols)</li> <li>Network connectivity</li> <li>Remote access requirements</li> <li>RBAC requirements</li> <li>Allowed and disallowed technologies within a zone</li> </ul> <p>Creating zones can help with:</p> <ul> <li>Areas where security controls should be applied</li> <li>Security policies needed</li> <li>Defining expected behavior in and between zones</li> <li>Placement for IDS and IPS, especially on conduits</li> <li>Seeing information flow requirements</li> <li>Seeing need for nesting based on security level</li> </ul> <p>Zone examples and security:</p> <ul> <li>Field zone<ul> <li>Often embedded systems, low cost and power means you can't install commercial security software</li> <li>Device security relies on manufacturer, e.g. with whitelisting</li> <li>On conduits to and between field zones: ICS firewall, protocol filter, IPS</li> </ul> </li> <li>Control zone<ul> <li>Whitelisting</li> <li>Anti-virus</li> <li>Configuration management and system hardening</li> <li>Separation of services</li> <li>Host IDS/IPS and DLP</li> <li>Event logging</li> <li>On conduits between: SCADA firewall and IDS/IPS, NAC, NBAD/NTBA, DLP</li> </ul> </li> <li>Energy services<ul> <li>On conduits to and from: enterprise firewall and IDS/IPS, NAC, NBAD/NTBA, DLP</li> </ul> </li> <li>Back-office services<ul> <li>Data integrity and information assurance tools: DB security, auditing, DLP<ul> <li>Value of data increases as you move inward from the field</li> <li>Increased reliance on integrity (less on availability)</li> </ul> </li> <li>DB Activity Monitoring (DAM)</li> <li>On conduits to and from: enterprise firewall and IDS/IPS, NAC, NBAD/NTBA, DLP</li> </ul> </li> <li>Enterprise zone<ul> <li>On conduits and from: enterprise firewall and IDS/IPS, NAC, NBAD/NTBA, DLP</li> </ul> </li> </ul> <p>Modelling systems and physical devices can provide CPS-specific rules for detecting anomalies and fingerprinting device behavior.</p> <p>Situational awareness is the process of perception, decision, and action that enables assessment of and reaction to a situation. (A widely applicable concept; see The Tao of Boyd: How to Master the OODA Loop.) Considerations include:</p> <ul> <li>Where is your data stored and how is it being used?</li> <li>Collecting information in a format that can be analyzed from a cybersecurity standpoint</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#compensating-controls","title":"Compensating Controls","text":"<p>These help meet security requirements when other measures are too difficult or impractical to implement. These include:</p> <ul> <li>Firewalls</li> <li>Industrial protocol filters</li> <li>IDS and IPS that perform DPI</li> <li>Network access control systems</li> <li>Application content inspection</li> <li>TLS</li> <li>Logging and monitoring<ul> <li>SIEM or log management tools can detect and compare anomalies after an incident<ul> <li>Automated capabilities include data correlation, scoring risk associated with assets, filtering and cross-referencing information with outside sources</li> </ul> </li> <li>Network forensics tools</li> <li>DLP detects sensitive information at rest and in motion, e.g. stop sensitive info from being saved to a USB drive</li> </ul> </li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#security-level-sl","title":"Security Level (SL)","text":"<ul> <li>ISA-62443 Security Level (SL) standard provides a measurement for the relative security of a zone or conduit</li> <li>Used to determine Target Security Level and Capability Security Level to help ensure assets grouped together meet the same SL</li> <li>Physical assessment determines the Achieved Security Level, for assurance</li> </ul>"},{"location":"course-notes/cpss/cyber-physical-systems-security/#privacy-in-cps","title":"Privacy in CPS","text":"<p>These patterns can be useful for analyzing our energy use for energy conservation but, together with data from other sources, the potential for extensive data mining is very significant. \u2060\u2014 Giovanni Buttarelli, assistant director of the European Data Protection Supervisor</p> <p>Privacy risks associated with the Smart Grid include:</p> <ul> <li>The ability to identify a person from data originating from AMI</li> <li>PII that is easily accessible due to lack of proper safeguards</li> <li>Integration with home smart appliances and communication channels (your smartphone)</li> <li>Third parties can utilize energy usage data to profile activities happening at a property<ul> <li>If the home is vacant</li> <li>How many individuals live there</li> <li>Number of appliances, use patterns, and identification using libraries of known patterns</li> <li>Whether a property is growing marijuana (subpoena of utility records; see Kyllo v. United States)</li> </ul> </li> <li>Data sold to third-parties</li> </ul> <p>Privacy strategies for the Smart Grid include periodic sampling and differential privacy.</p> <p>Privacy Impact Assessment (PIA) or Data Protection Impact Assessment (DPIA) analyzes privacy implications of a system and may:</p> <ul> <li>Satisfy, meet, or exceed legal requirements</li> <li>Demonstrate due diligence</li> <li>Help identify and manage risks</li> <li>Avoid unnecessary costs, inadequate solutions, loss of trust and reputation</li> <li>Inform organizational communications strategy</li> </ul> <p>DPIA subsequently has these options:</p> <ul> <li>Risk acceptance: acknowledge and take no action</li> <li>Risk mitigation or reduction: take steps to reduce the risk or its consequences to an acceptable level</li> <li>Risk transfer: transfer the risk to a third-party</li> <li>Risk avoidance: decide not to implement the risky system entirely</li> </ul> <p>Other CPS domains with security and privacy considerations include:</p> <ul> <li>Healthcare and medicine (implantable devices)</li> <li>Intelligent transportation (traffic management systems, infrastructure, vehicle advanced driver assistance systems)</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/","title":"Database Systems Concepts and Design","text":"<p>A database is a model of structures of reality.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#database-management-system","title":"Database Management System","text":"<p>... is a software system allowing users to create and maintain a database.</p> <p>When to use a DBMS:</p> <ul> <li>For data-intensive applications</li> <li>Persistent, centralized storage (centralized security, access policies)</li> <li>Controlling data redundancy (consistency, integrity)</li> <li>Multiple users</li> <li>Data sharing (communication)</li> <li>Documenting data via its structure</li> <li>Data independence allows modification without affecting UI</li> <li>Backup and recovery</li> </ul> <p>When not to use:</p> <ul> <li>Cost-benefit isn't worthwhile<ul> <li>Investment in *ware, training is too high</li> <li>Data and application is simple, stable</li> </ul> </li> <li>The points above (security, concurrency for multiple users, recovery) aren't needed</li> <li>Real-time requirements can't be met with a DB</li> </ul> <p>Characteristics of a DB approach:</p> <ul> <li>DB definition (metadata) is stored in the catalog</li> <li>NOSQL systems (no metadata) are self-describing</li> <li>Multiple different views of the database for different users</li> <li>Data access, transaction processing shared among users</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#process-modeling","title":"Process Modeling","text":"<ul> <li>Fix and represent a perception of processes of reality</li> <li>Processes are not reflected in DB structures, but reflected in how data is used through the DBMS</li> <li>Processes can be represented by being embedded in program code<ul> <li>DML between UI and DB acts as an interface for retrieving and displaying data to the user</li> </ul> </li> <li>... or executed ad-hoc<ul> <li>DML is directly used to build and run queries, do maintenance, ad-hoc</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#data-modeling","title":"Data Modeling","text":"<ul> <li>Select aspects of reality that are important to the model and use abstraction to organize them</li> <li>Examples of data models:<ul> <li>Extended Entity Relationship model is for fixing a perception of structures of reality</li> <li>Relational Model represents this perception as tables in a DB, and each table can be stored as a separate file</li> <li>Object Model defines a DB as objects, object properties and operations (methods) using classes organized in hierarchies (acyclic graphs)<ul> <li>Also object-relational or extended relational systems</li> </ul> </li> <li>Key-value data model where each value has a unique key</li> <li>Document data model stores data as documents, based on JSON</li> <li>Graph data model stores objects as graph nodes and relationships as directed graph edges</li> <li>Column-based data model stores columns of rows clustered on disk pages</li> <li>XML model, using hierarchal tree structures</li> <li>Hierarchical Model was the first DB system implemented in the IBM Information Management System (IMS) (fundamental model of XML DBs today)</li> </ul> </li> </ul> <p>Data models consist of formalizations to express:</p> <ul> <li>Data structures</li> <li>Constraints</li> <li>Operations</li> <li>Keys and identifiers</li> <li>Integrity and consistency</li> <li>Null values</li> <li>Surrogates</li> </ul> <p>Data model != a model of data. A data model:</p> <ul> <li>Is a type of data abstraction for conceptual representation</li> <li>Hides storage and granular implementation details</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#data-structures","title":"Data Structures","text":"<p>A database table (with a name) has columns (with names and data types). Collectively, these constitute the schema of the table. The schema is stable over time and doesn't usually change.</p> <p>The database also has rows with data in them. The rows and their data are the state of the database and reflect the reality modeled. The state is dynamic and changes over time.</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#constraints","title":"Constraints","text":"<p>Used to express rules that cannot be expressed by the data structure alone, for example:</p> <ul> <li>Uniqueness</li> <li>Cannot be NULL</li> <li>Minimum and maximum date, times, numbers</li> <li>Geographic restriction</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#operations","title":"Operations","text":"<p>Used to support data change and retrieval. Involves:</p> <ul> <li>The method, or operation, e.g. INSERT</li> <li>Conditions</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#keys-and-identifiers","title":"Keys and Identifiers","text":"<p>Can be used as uniqueness constraints, for example using an email as a primary key. Primary keys are unique.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#integrity-and-consistency","title":"Integrity and Consistency","text":"<p>Integrity is a measure of how well the database reflects reality. Consistency is a lack of internal conflicts in the DB's data.</p> <p>For example, it makes maintenance and consistency harder if you:</p> <ul> <li>Have a column for a user's City, State, ZIP, and an additional column for the user's Address</li> <li>Separately store date of birth and age of a user</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#null-values","title":"NULL Values","text":"<p>NULL may mean that no information is available for this row and column. Unknown data represented by NULL is an acceptable situation.</p> <p>If a NULL value instead means that this row and column in combination would be inapplicable (e.g. catch-all forms), the schema design is poor as it does not accurately reflect reality.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#surrogates","title":"Surrogates","text":"<p>An immutable, system-generated artificial identifier to represent an entity existing the real world in the DB.</p> <ul> <li>Name-based representation: a thing is known only by the data that comprises it</li> <li>Surrogate-based representation: a thing is identified with a system-generated ID that doesn't change even if its data changes</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#architecture-ansisparc-3-level","title":"Architecture: ANSI/SPARC 3-Level","text":"<p>A database has schema (intention, or types) and data (extension, or the data). Users query against the schema in order to retrieve data effectively and efficiently.</p> <p>ANSI/SPARC 3-Level separates the schema from how data is physically organized into an internal schema. This physical data independence allows changing the way data is stored (changing the internal schema) without affecting how the application has to query it (changing the conceptual or external schema).</p> <p>One or more external schema serves as a layer of abstraction for applications. This gives applications a stable API that talks to the conceptual schema, which in turn uses the internal schema to access the data.</p> <ul> <li>Internal schema: how the data is stored</li> <li>Conceptual schema: meaning of the data</li> <li>External schema: use of data</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#internal-schema","title":"Internal Schema","text":"<p>Describes how the information in the conceptual schema is physically stored to provide the best performance. For example, if users often query on <code>Email</code>, an index on <code>Email</code> would provide efficient performance. Additional indices can also increase efficiency.</p> <p>Indexes are a list of the column, e.g. <code>Email</code>, and a pointer (PTR) to the row that contains the Email value.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#physical-data-independence","title":"Physical Data Independence","text":"<p>How much the internal schema can change without affecting the conceptual schema.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#conceptual-schema","title":"Conceptual Schema","text":"<p>Describes the general structural aspects of reality shown by the data, excluding time, data representation, physical organization, and access. For example, the <code>RegularUser</code> table has <code>Email</code>, <code>DOB</code>, <code>Name</code>, <code>Sex</code>, etc.</p> <p>The conceptual schema does not offer information about how the data is displayed or accessed.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#logical-data-independence","title":"Logical Data Independence","text":"<p>How much the conceptual schema can change without affecting the application(s) or external schema. Harder to achieve than physical data independence due to a tighter coupling between the external and conceptual schema.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#external-schema","title":"External Schema","text":"<p>Derives and describes data from part of a conceptual schema in a convenient form for the user or application. For example, a virtual table <code>create view FemaleUsers...</code> by conditionally selecting on <code>Sex</code>.</p> <p>Virtual tables are views into the DB -- they don't really exist as tables.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#ansisparc-dbms-framework","title":"ANSI/SPARC DBMS Framework","text":"<p>Consists of two pieces: query transformer and schema compiler.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#schema-compiler","title":"Schema Compiler","text":"<p>The metadatabase stores definitions of the conceptual, external, and internal schemas.</p> <ul> <li>The \ud83e\uddcd enterprise administrator defines a conceptual schema using the language in interface (1).</li> <li>The \ud83d\udda5\ufe0f conceptual schema processor software verifies syntax and uses the language (2) to store that schema as metadata in the metadatabase.</li> <li>An \ud83e\uddcd application system administrator uses the language in interface (3) and the conceptual schema and expresses an external schema definition in interface (4). Multiple external schema can be defined.</li> <li>An \ud83d\udda5\ufe0f external schema processor software checks the external schema for correct syntax and to see that it is correctly and logically derived from the conceptual schema. It then stores the external schema definition in the metadatabase with interface (5).</li> <li>A \ud83e\uddcd database administrator uses the language in interface (3) and the conceptual schema to define an internal schema with the language in interface (13).</li> <li>The \ud83d\udda5\ufe0f internal schema processor software checks this internal schema definition for correct syntax and that it physically implements the conceptual schema. It then stores the internal schema definition in the metadatabase with interface (14).</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#query-transformer","title":"Query Transformer","text":"<ul> <li>The \ud83e\uddcd user expresses queries on the database using language interface (12), either using ad-hoc queries or through the application's program code (TODO prepared queries).</li> <li>An \ud83d\udda5\ufe0f external to conceptual schema transformer uses the definitions for the external and conceptual schemas in the metadatabase (using interface (36)) to translate the user's queries into a form fit for the internal schema (using interface (31)).</li> <li>The \ud83d\udda5\ufe0f conceptual to internal schema transformer reads the conceptual and internal schema definitions using interface (36) and translates the query from interface (31) through interface (30) to a form fit for the...</li> <li>\ud83d\udda5\ufe0f internal schema to storage transformer, which reads the internal schema definition from the metadatabase (through interface (34)). This translates the query from one that works on the internal schema to one that works on the data itself (OS or DB calls interface (21)).</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#framework-more-practically","title":"Framework, more practically","text":"<ul> <li>DBA staff write DDL statements that are compiled by the DDL compiler and stored in the metadatabase</li> <li>Users can write interactive queries that are compiled and optimized by the query compiler and query optimizer, respectively<ul> <li>This is then given as a DBA command to the runtime database processor</li> </ul> </li> <li>Programmers write applications that have host language code with embedded DB access; when these go through a precompiler, the host language compiler and DML compiler create compiled transactions<ul> <li>Compiled transactions are sent to the DB and executed by the runtime DB processor</li> </ul> </li> <li>A concurrency control subsystem ensures competing transactions on the DB are executed in order</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#metadata","title":"Metadata","text":"<p>Two types of metadata: system (critical to a DBMS) and business (critical in a data warehouse).</p> <p>System metadata includes:</p> <ul> <li>Where data came from</li> <li>How data was changed</li> <li>How data is stored and mapped</li> <li>Who owns and who can access data</li> <li>Data usage history and statistics</li> </ul> <p>Business metadata includes:</p> <ul> <li>What data are available and where it is located</li> <li>How to access the data</li> <li>What the data means</li> <li>Predefined reports and queries</li> <li>How current data are</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#database-application-development-methodology","title":"Database Application Development Methodology","text":"<p>Operates under some assumptions:</p> <ul> <li>Business processes are well-designed</li> <li>The documents (DB input and output), tasks, and system boundary are known</li> <li>We can design one DB schema that unifies all views<ul> <li>Difficulties include different interests, goals, power, and politics in the organization</li> <li>Organizations need shared goals</li> </ul> </li> </ul> <p>Software Process typically includes:</p> <ul> <li>Business process design</li> <li>*Analysis</li> <li>*Specification</li> <li>*Design</li> <li>*Implementation</li> <li>Testing</li> <li>Operation</li> <li>Maintenance</li> </ul> <p>*Unique for DB development</p> <p>DB design involves data first instead of software first.</p> <ul> <li>Requirements collection and analysis: ask questions of prospective users to document their data requirements</li> <li>Specify functional requirements, consisting of user-defined operations (transactions)</li> <li>Conceptual design: create a conceptual schema with a high-level data model</li> <li>Logical design (data model mapping): DB implementation using DBMS</li> <li>Physical design: specifies internal storage structures, organization, indexes, access paths</li> </ul> <p></p> <ol> <li>Analysis produces an Information Flow Diagram</li> <li>Specification produces an ER or EER Diagram, and from that, Tasks</li> <li>In Design, the ER Diagram is translated to a Relational Schema and the Tasks to Abstract Code (like SQL)</li> <li>In Implementation, the Relational Schema becomes a specific DB implementation, and the Abstract Code a specific programming language</li> </ol>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#analysis-information-flow-diagram","title":"Analysis: Information Flow Diagram","text":"<ul> <li>Denotes input and output documents, tasks, and system boundary</li> <li>Shows (possible) information flow, not control flow of the program<ul> <li>Denote direction of flow (input or output) with arrows</li> </ul> </li> <li>Never connect two documents or two tasks</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#specification","title":"Specification","text":"<p>Outputs:</p> <ul> <li>EER Diagram</li> <li>Data Formats</li> <li>Constraints</li> <li>Task Decomposition</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#extended-entity-relationship-model","title":"Extended-Entity Relationship Model","text":"<p>ER diagram notation:</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#words-matter","title":"Words Matter","text":"<p>and, or, not, must, may, always, never, sometimes, at least, at most, for some, for all, overlap, disjoint, exists, unique, single, multiple, type, instance, surrogate, value</p> <ul> <li>\"any\" of these options could be valid</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#entities","title":"Entities","text":"<p>An entity type and entity surrogate is a time-invariant representation of something, e.g. a user. Their names must be unique.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#properties","title":"Properties","text":"<p>Properties, or attributes, describe entities.</p> <p>Composite properties are composed (concat) of more than one part, e.g. <code>Name</code> is created with the component properties <code>FirstName</code> and <code>LastName</code>. Composite properties can be hierarchal.</p> <p>Simple or atomic attributes are not decomposable.</p> <p>An entity can have single-valued property types, e.g. an email or password.</p> <p>Multi-valued properties contain many values, for example, a field <code>Interests</code> that holds many interest values.</p> <p>Identifying properties or key attributes, e.g. an email, identifies a single entity instance. Key attributes may be composites, e.g. <code>Name</code>. An entity may have more than one key attribute (no primary key concept in ER).</p> <p>Related attribute values give us derived attributes and stored attributes. A DOB is a stored attribute, and a person's age can be derived from it. Derived attributes are often counts.</p> <p>DBs contain entity types: groups of entities (entity collection or entity set) that have the same attributes.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#classes-inheritance","title":"Classes, Inheritance","text":"<p>Supertype and subtype (superclass C and subclass S) give us class/subclass relationship types (is-a relationships).</p> \\[ \\mathit{S}\\subseteq\\mathit{C} \\] <p>These place entities into non-exclusive subcategories. For example, <code>Users</code> may be <code>Male</code> or <code>Female</code>, <code>AdminUser</code> or <code>RegularUser</code>. Supertypes and subtypes inherit the properties of the base type, e.g. all types of users have an email. Supertypes and subtypes also have local properties specific to that type, e.g. <code>Female</code> users have <code>MaidenName</code>. Creating a superclass entity from previously separate entities is called generalization (generalized entity type G).</p> <p>A specialization Z is a set of subclasses S with the same superclass, G (G/S\u1d62).</p> \\[ \\mathit{Z}=\\{\\mathit{S_1,S_2,...,S_n}\\} \\] <p>Z is said to be total if:</p> \\[ \\cup_{\\mathit{i=1}}^\\mathit{n}\\mathit{S_i}=\\mathit{G} \\] <p>Otherwise it is partial.</p> <p>Predicate-defined (condition-defined) subclasses, S, are defined by the defining prediciate, or a predicate p that is a constraint for that subclass. For example, a <code>Secretary</code> (S) is a predicate-defined subclass of the superclass <code>Employee</code> (C) where <code>JobType</code> (p) is <code>Secretary</code>.</p> \\[ \\mathit{S}=\\mathit{C[p]} \\] <p>When this is the case for all subclasses, the superclass C is called an attribute-defined specialization with subclasses indicated by the defining attribute, (A=c\u1d62), where c\u1d62 is a constant value from the domain of A.</p> <p>When subclasses are not defined with a condition, they are user-defined.</p> <p>Designing classes from the generalization to the specializations is top-down conceptual refinement. Moving in the other direction is bottom-up conceptual synthesis.</p> <p>Union entity types (category T) is a subclass of an entity union with another entity type (superclasses D).</p> \\[ \\mathit{T}\\subseteq(\\mathit{D_1}\\cup\\mathit{D_2}...\\cup\\mathit{D_n}) \\] <p>For example, entities in the <code>PrivateSector</code> or the <code>PublicSector</code> can both be <code>Employer</code>s. There exist no <code>Employer</code> entities that are not either a <code>PrivateSector</code> or <code>PublicSector</code> employer. As well, the intersection between <code>PrivateSector</code> and <code>PublicSector</code> is empty; no <code>Employer</code> can be both.</p> <p></p> <p>Categories can also be total or partial and may have different key attributes (names), depending on the subclass.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#tree-and-lattice","title":"Tree and Lattice","text":"<p>A tree structure (specialization or strict hierarchy) constrains every subclass to have only one parent (single inheritance of attributes and relationships). In a specialization lattice, subclasses may have more than one class/subclass relationship.</p> <p>Subclasses with more than one parent are shared subclasses (multiple inheritance of attributes and relationships); this implies a lattice.</p> <p>A leaf node is a class without subclasses.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#constraints_1","title":"Constraints","text":"<p>A disjointness constraint may apply to subclasses, where an entity can be a member of at most one subclass (can't be both). This includes attribute-defined specializations implicitly for single-value attributes. Specializations that overlap indicate that entities can be members of more than one subclass.</p> <p></p> <p>If neither of these constraints are indicated, subclasses are non-exclusive.</p> <p>A specialization (subclass) Z is said to be disjoint if:</p> \\[ \\mathit{S_i}\\cap\\mathit{S_j}=\\oslash \\] <p>for:</p> \\[ \\mathit{i}\\ne\\mathit{j} \\] <p>Otherwise it's overlapping. Both disjoint and overlapping constraints may be total or partial specializations.</p> <p>A totalness constraint (total specialization, total participation, existence dependency) means every entity in the superclass must be a member in at least one subclass; i.e.  every entity in the total set is related to the other entity.</p> <p></p> <p>Partial specialization (partial participation) allows entities not to belong to any subclass; i.e. some or part of the set of entities are related to the other entity.</p> <p>Relationships have cardinality, the maximum number of relationship instances an entity can participate in. Cardinality is expressed as a ratio. A relation with cardinality <code>1:1</code> is constrained as a one-to-one relationship. We also have one-to-many relationships (<code>1:N</code>) where one surrogate is linked to one or more other surrogates.</p> <ul> <li><code>1</code>: maximum one</li> <li><code>N</code> or <code>M</code>: \"many,\" no maximum number</li> </ul> <p>We may have minimum cardinality constraints as well.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#relationships","title":"Relationships","text":"<p>A mandatory one-to-many relationship is constrained so that surrogates from group B (the <code>N</code> side) must be mapped to a surrogate in group A (relation cannot be null). When all surrogates in group B are mapped to one from group A, this is a total function. A partial function means that not all surrogates from group B are mapped to a surrogate from group A.</p> <p>A many-to-many relationship (<code>M:N</code>) can have multiple surrogates from group A (the <code>N</code> side) associated with a particular surrogate in group B (the <code>M</code> side). Likewise, many surrogates from group B may be associated with a particular surrogate in group A. Any single element in either group may be mapped to multiple elements in the other group. This is not called a function, but a relationship in the mathematical sense.</p> <p></p> <p>Any composition of relationship types involving a <code>M:N</code> relationship or two <code>1:N</code> relationships is also <code>M:N</code>:</p> <p><code>A 1:N B</code> and <code>C M:N B</code> = <code>A M:N C</code></p> <p><code>A 1:N B</code> and <code>C 1:N B</code> = <code>A M:N C</code></p> <p>As opposed to binary relationship types, N-ary relationship types are defined by combinations of entities, e.g. <code>Email</code> for a person, <code>EventName</code> for a type of event, and <code>TeamName</code> for a team for that event. The person, event, and team are all required to specify the <code>Position</code>. These exist as it is not always possible to decompose a conjunction of three relationships into binary relationships, e.g., you could not accurately specify a position without the person, event, or team in question.</p> <p>Weak entities are identified by their identifying relationship, in which they always have total participation. For example, a <code>StatusUpdate</code> is uniquely identified by its <code>DateAndTime</code> (a partial identifier since it is not sufficient on its own to identify a unique <code>StatusUpdate</code>) as well as a <code>User</code>'s <code>Email</code>. <code>StatusUpdate</code> is a weak entity type since one cannot be uniquely found without the identifying relation to <code>Email</code> through <code>User</code>.</p> <p>Recursive or self-referencing relationships relate the entity type to itself in different roles, for example, one <code>AdminUser</code> is the manager of another <code>AdminUser</code>. Directional arrows help diagram this relationship.</p> <p>Implicit relationships exist whenever an attribute of one entity type refers to another entity type, e.g. an entity <code>Employee</code> has an attribute <code>Department</code> that refers to a particular <code>Department</code> entity.</p> <p>Relationships are not entities and don't have properties.</p> <ul> <li>Move properties onto entities that keep the most granular detail, e.g. <code>EmployedSinceDate</code> onto <code>Employee</code> as opposed to <code>Employer</code>, where the one value would be the same for everyone.</li> <li>Create a \"through\" entity or objectified relationship type, e.g. a <code>User</code> can map to many <code>SchoolsAttended</code> (with property <code>GPA</code>). A <code>School</code> can map to many <code>SchoolsAttended</code> and this creates a many-to-many relationship between <code>User</code> and <code>School</code>.</li> </ul> <p>Properties and entities are not necessarily consistent across databases. For example, <code>LastName</code> may be a property of <code>User</code> in one app. In another app it may be the central entity of a genealogy database, with properties for <code>Language</code>, <code>Era</code>, etc. Understanding the context is important.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#relational-model","title":"Relational Model","text":"<p>Each relation resembles a table of values; a flat file of records with a linear (flat) structure.</p> <ul> <li>Data structures</li> <li>Constraints</li> <li>Operations<ul> <li>Algebra</li> <li>Calculus<ul> <li>Two notations: tuple calculus in SQL (tuples of relations are variables) and domain calculus in QBE (cells of domains are variables)</li> </ul> </li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#data-structures_1","title":"Data Structures","text":"<p>Degree of a relationship type is its number of participating entities. Degree of two is binary, degree of three is ternary. A higher degree is more complex.</p> <p>Values that are atomic are indivisible (formally, in the relational model).</p> <p>A domain, D, is a set of atomic values (a type). Each simple attribute of an entity type has a domain of values (value set, or basic types, data types). These are not shown on basic ER diagrams.</p> <p>An attribute A of entity set E with value set V defined as a function from E to the power set P(V) (set of all subsets of V):</p> \\[ \\mathit{A}:\\mathit{E}\\to\\mathit{P}(\\mathit{V}) \\] <p>Value of attribute A for entity e is A(e).</p> <ul> <li>Null values are represented by empty set</li> <li>For single-value attributes, A(e) is restricted to being a singleton set</li> </ul> <p>For a composite attribute A, value set V is thw power set of the Cartesian product:</p> \\[ \\mathit{V}=\\mathit{P}(\\mathit{P}(\\mathit{V_{1}})\\times\\mathit{P}(\\mathit{V_{2}})\\times...\\times\\mathit{P}(\\mathit{V_{{n}}})) \\] <p>... where:</p> \\[ \\mathit{V_{i}},...,\\mathit{V_{n}} \\] <p>... are the value sets of the simple component attributes for A.</p> <p>A relation schema (or relation scheme, relation intension) consists of a relation name, R, and its list of attributes, A1 ... An, and is denoted R(A1, A2, ..., An). Each attribute is the name of a role of some domain D, i.e. a value of some data type. The domain of any attribute is dom(Ai). The degree or arity of a relation is the number of attributes it has.</p> <pre><code>STUDENT(Name, ID, Phone_number, Address)\n</code></pre> <p>A relation, r of the relation schema, is a set of tuples. (In a set, elements are distinct; mathematically, they are unordered.) Also relation state, this can be denoted r(R).</p> <p>The relation schema can be interpreted as a declaration, an assertion, or as a predicate, and each tuple interpreted as a fact or particular instance of the assertion, or as values that satisfy the predicate. Relations may represent facts about entities or relationships.</p> <p>The closed world assumption states that the only true facts in the universe are those present within the extension (state) of the relation(s) .</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#two-ways-to-define-relation","title":"Two Ways to Define Relation","text":"<p>Where a n-tuple is an ordered list of n values (the order of the values in the tuple is important):</p> <p>A relation (or relation state) r(R) is a mathematical relation of degree n on the domains dom(A1), dom(A2), ..., dom(An), which is a subset of the Cartesian product (denoted by x) of the domains that define R: $$ \\mathit{r(R)} \\subseteq (dom(A_{1}) \\times dom(A_{2}) \\times ... \\times dom(A_{n})) $$</p> <p>Alternatively, where tuples are defined as mappings and considered a set of (attribute, value) pairs. In this case the ordering of attributes is not important since the attribute name appears with its value (self-describing data):</p> <p>A relationship type, R, defines a set of associations (relationship set) among entities from entity types participating in R. Each individual entity participates in the relationship instance:</p> \\[ \\mathit{r_{i}}=(\\mathit{e_{1}},\\mathit{e_{2}},...,\\mathit{e_{n}},) \\] <p>R is a subset of the set of ordered n-tuples:</p> \\[ \\mathit{R}\\subseteq\\{&lt;\\mathit{d}_{1},\\mathit{d}_{2},...,\\mathit{d}_{n}&gt;|\\mathit{d}_{i}\\in\\mathit{D}_{i},\\mathit{i}\\=\\mathit{1},...,\\mathit{n}\\} \\] <p>This means that each element in the tuple,</p> \\[ \\mathit{d}_{i} \\] <p>is pulled from the corresponding domain</p> \\[ \\mathit{D}_{i} \\] <p>An attribute, <code>A</code>, is a unique name given to a domain in a relation and is used instead of referring to the position of a column in a table. The order of attributes and tuples is independent of what the value of the current relation is.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#relational-databases-and-their-schemas","title":"Relational Databases and their Schemas","text":"<p>A relational database schema S is a set of relation schemas:</p> \\[ \\mathit{S} = \\{\\mathit{R}_{1}, \\mathit{R}_{2}, ..., \\mathit{R}_{m}\\} \\] <p>... and a set of integrity constraints IC.</p> <p>A relational database state DB of S is a set of relation states:</p> \\[ DB = \\{\\mathit{r}_{1},\\mathit{r}_{2}, ..., \\mathit{r}_{m}\\} \\] <p>... such that each r\u1d62 is a state of R\u1d62; and the r\u1d62 relation states satisfy the IC. Whether a state obeys its IC is called valid state or not valid.</p> <p>A \"relational database\" implies both its schema and current state.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#constraints_2","title":"Constraints","text":"<p>State constraints (static constraints) define constraints that a valid state of the database must satisfy. Transition constraints (dynamic constraints) can be defined to deal with state changes in the database and are typically enforced by the application.</p> <p>Inherent model-based constraints or implicit constraints are, go figure, inherent in the data model.</p> <p>Schema-based constraints or explicit constraints can be directly expressed in the schemas of the data model, e.g. specifying them in the DDL. They include:</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#domain-constraints","title":"Domain Constraints","text":"<p>The value of each attribute within a tuple must be an atomic value from the domain.</p> <p>Violated if an attribute value does not appear in the corresponding domain (is the wrong data type).</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#key-constraints","title":"Key constraints","text":"<p>A uniqueness constraint states that no two tuples in a relation can be the same and also applies to superkeys. Where SK is a superkey of R:</p> \\[ \\mathit{t}_{1}[SK]\\ne\\mathit{t}_{2}[SK] \\] <ul> <li>The default superkey is the set of all a relation's attributes, which can include redundancy</li> <li>A key k has no redundancy and satisfies both uniqueness property and minimality property</li> <li>If you remove any attribute from K, you leave a set of attributes K' that is no longer a superkey of R</li> <li>A minimal superkey cannot have any attributes removed and still have its uniqueness hold<ul> <li>This minimality property is required for a key but optional for a superkey</li> </ul> </li> <li>A key with multiple attributes requires all its attributes together to have uniqueness</li> <li>A key is a superkey, but not vice versa; i.e. only a minimal superkey is a key (e.g. superkey with a single attribute)</li> <li>A key's set of attributes is a property of the relation schema and should hold on every valid relation state of the schema</li> <li>The property of a key is time-invariant and must hold when new tuples are inserted (i.e.<code>Name</code> is a poor key because two people can have the same name)</li> <li>A relation schema may have more than one candidate key, and one may be designated as the primary key; the other candidates are designated unique keys</li> </ul> <p>Violated if a new key value already exists in another tuple in the relation.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#constraints-on-nulls","title":"Constraints on NULLs","text":"<p>NULL values have several different meanings:</p> <ul> <li>Value unknown</li> <li>Value exists but is not available, or is withheld</li> <li>Not applicable attribute (or value undefined)</li> </ul> <p>Whether NULL values are permitted for the attribute.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#entity-integrity-constraints","title":"Entity Integrity Constraints","text":"<p>States that no primary key value can be NULL. Violated if any part of the PK is NULL.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#referential-integrity-constraints","title":"Referential Integrity Constraints","text":"<p>Specified between two relations; maintains consistency among tuples in both. A tuple in one relation that refers to another relation must refer to an existing tuple (no orphans). Specified on the relational database schema so the DBMS can enforce these constraints on the database states; defined via the DDL.</p> <p>Conditions for a foreign key specify a referential integrity constraint between R\u2081 (the referencing relation) and R\u2082 (the referenced relation). FK is a set of attributes in the relation schema R\u2081 that reference or refer to the relation R\u2082.</p> <ul> <li>FK attributes have the same domain(s) as the PK of the relation it references</li> <li> <p>The value of any FK either occurs as a value of PK for the tuple it refers to, or it is NULL:</p> \\[ t_{1}[FK] = t_{2}[PK] \\] </li> <li> <p>If these two conditions hold, the referential integrity constraint from R\u2081 to R\u2082 is said to hold.</p> </li> <li>A FK can refer to its own relation, e.g. EMPLOYEE has a Supervisor_ID which is another EMPLOYEE.</li> </ul> <p>These are diagrammed with directed arcs where the arrowhead points to the PK of the referenced relation.</p> <p>FKs reference primary keys (PK):</p> <ul> <li>Unique and must not be NULL, e.g. emails for <code>User</code>s</li> <li>When used in another table, e.g. <code>RegularUser</code>, the set of PKs that appear in <code>RegularUser</code> must be a subset of the values from the <code>User</code> table</li> </ul> <p>Violated if the value of any FK refers to a tuple that does not exist in the referenced relation.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#semantic-constraints","title":"Semantic Constraints","text":"<p>Application-based or semantic constraints or business rules cannot be expressed in the schemas of the data model and must be programmed into application logic. Sometimes they can be specified as assertions in SQL using triggers and assertions (constraint specification language).</p> <p>Data dependencies (functional, multivalued dependencies) are used for testing the design of a relational database and are utilized in normalization.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#update-operations-transactions-handling-constraint-violations","title":"Update Operations, Transactions, Handling Constraint Violations","text":"<p>Operations are either retrievals or updates. Retrievals are specified by relational algebra operations and answer the user's query with a result relation.</p> <p>Database modification or update operations change the states of relations in the database.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#insert","title":"Insert","text":"<p>Provides a list of attribute values for a new tuple t to be inserted into a relation R. If the insertion violates any constraint, the default option is to reject it.</p> <p>Alternatively an attempt may be made to correct the reason for rejecting the insertion: e.g. please provide a value for a non-nullable field, or please provide a value for the referenced relation if none exists before accepting a PK. This is not typically used for violations caused by Insert (a violation could cascade).</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#delete","title":"Delete","text":"<p>Can only violate referential integrity if the tuple being deleted is referenced by a FK elsewhere in the DB.</p> <p>If a violation occurs, options include:</p> <ul> <li>Restrict: reject the deletion</li> <li>Cascade: propagate the deletion by deleting tuples that reference the tuple being deleted</li> <li>Set null or set default: modify the referencing attribute values, e.g. set these to NULL or a default<ul> <li>If the referencing attribute is part of a PK, it cannot be set to NULL</li> </ul> </li> <li>It's also possible to combine these three</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#update","title":"Update","text":"<p>An Update or Modify is used to change the values of one or more attributes in tuple(s). If the updated attribute is not part of a PK or FK, no violations are usual. If it is, modification is similar to delete + insert and is dealt with similarly.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#transaction","title":"Transaction","text":"<p>A transaction is the executing program that includes database operations, e.g. reading, insertions, deletions, updates. Upon finishing, a transaction must leave the DB in a valid state (consistent state) that satisfies all constraints.</p> <p>Any number of retrieval and update operations form an atomic unit of work against the DB.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sql","title":"SQL","text":"<p>Structured Query Language (from Structured English QUEry Language, SEQUEL) provides a higher-level (than relational algebra operations) declarative language interface; i.e. the user specifies what the result should be, and optimization and execution is left up to the DBMS. SQL is based on tuple relational calculus, some algebra.</p> <ul> <li>Part of System R, 1973</li> <li>ANSI &amp; ISO Standards<ul> <li>SQL/86, SQL/89</li> <li>SQL/92 or SQL2</li> <li>SQL3, 1999</li> <li>Revisions: 2003, 2006, 2008, 2011</li> </ul> </li> <li>Supported by IBM, DB2, Oracle, SYBASE, SQLServer, MySQL</li> </ul> <p>A core specification is supposed to be implemented by SQL compliant RDBMS vendors; specialized extensions can be implemented as optional modules.</p> <p>Terms (SQL: formal relational model)</p> <ul> <li>table: relation</li> <li>row: tuple</li> <li>column: attribute</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#schema-and-catalog","title":"Schema and Catalog","text":"<p>A SQL schema is identified by a schema name; an authorization identifier, indicating the user/account who owns the schema; and descriptors for each element in the schema (tables, types, constraints, views, domains, authorization grants, etc).</p> <p>A catalog is a named collection of schemas (also, a cluster of catalogs). It contains a special INFORMATION_SCHEMA that provides information on all schemas in the catalog and element descriptors in those schemas.</p> <ul> <li>Integrity constraints (e.g. referential integrity) can be defined between relations only if they exist in schemas within the same catalog</li> <li>Schemas in the same catalog can share certain elements, e.g. type, domain definitions</li> </ul> <p>SQL keywords are not case-sensitive.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#attribute-data-types-domains","title":"Attribute Data Types, Domains","text":""},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#numeric","title":"Numeric","text":"<p>Includes:</p> <ul> <li>INTEGER or INT, SMALLINT</li> <li>Floating-point (real) numbers FLOAT or REAL, DOUBLE PRECISION</li> <li>Formatted numbers DECIMAL(i,j) or DEC(i,j) or NUMERIC(i,j)<ul> <li>Where i is precision (total number of decimal digits, default is implementation-defined) and j is scale (number of digits after decimal point, default 0)</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#character-string","title":"Character-string","text":"<p>Includes:</p> <ul> <li>Fixed length CHAR(n) or CHARACTER(n)<ul> <li>Shorter strings are padded with blank characters to the right</li> <li>Padded blanks are generally ignored when comparing strings</li> </ul> </li> <li>Varying length VARCHAR(n) or CHAR VARYING(n) or CHARACTER VARYING(n) with maximum n<ul> <li>CHARACTER LARGE OBJECT (CLOB) maximum length can be specified in kilobytes (K), megabytes (M), gigabytes (G); e.g. <code>CLOB(20M)</code></li> </ul> </li> </ul> <p>Strings are:</p> <ul> <li>Ordered in alphabetic (lexicographic) order; those that appear first are considered less than those appearing later<ul> <li>Nonalphabetic characters have a defined order</li> </ul> </li> <li>Concatenated with <code>||</code></li> </ul> <p>Single quotes enclose literal string values that are case-sensitive.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#bit-string","title":"Bit-string","text":"<p>Includes:</p> <ul> <li>Fixed length BIT(n)</li> <li>Varying length BIT VARYING(n) with maximum n<ul> <li>BINARY LARGE OBJECT or BLOB maximum length can be specified in kilobytes (K), megabytes (M), gigabytes (G); e.g. <code>BLOB(20G)</code></li> </ul> </li> </ul> <p>Default length for n is 1.</p> <p>Literal bit strings are enclosed by single quotes preceded with a <code>B</code>: <code>B'10101'</code>. Hexadecimal notation can be used for bit strings with multiple of 4, preceded by <code>X</code> instead.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#boolean","title":"Boolean","text":"<p>TRUE or FALSE with third possible value UNKNOWN.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#date-and-time","title":"DATE and TIME","text":"<ul> <li>DATE has ten positions for YEAR, MONTH, DAY as YYYY-MM-DD. Values must be valid.</li> <li>TIME has at least eight positions for HOUR, MINUTE, SECOND as HH:MM:SS. Values must be valid.<ul> <li>TIME(i) allows specifying i which is time fractional seconds precision<ul> <li>Specify i + 1 additional positions (additional period as separation character), and i positions for decimal fractions of a second</li> </ul> </li> <li>TIME WITH TIME ZONE includes additional six positions for specifying displacement from standard universal time zone: <code>+13:00</code> to <code>-12:59</code> (HOURS:MINUTES)<ul> <li>Default without WITH TIME ZONE is the local SQL session time zone</li> </ul> </li> </ul> </li> </ul> <p>Both can be compared with <code>&lt;</code> and <code>&gt;</code>. Earlier dates and times are considered smaller.</p> <p>Literal values are strings enclosed by single quotes and preceded with DATE or TIME: e.g. <code>DATE '2021-06-22'</code>, <code>TIME '11:54:12'</code>.</p> <p>TIMESTAMP includes DATE and TIME fields, plus minimum six positions for decimal fractions of seconds and optional WITH TIME ZONE qualifier. Literal values are preceded by TIMESTAMP: <code>TIMESTAMP '2021-06-22 11:54:12.421345'</code>.</p> <p>INTERVAL specifies a relative value that can be used to increment/decrement an absolute value (date, time, timestamp). Qualified as either YEAR/MONTH or DAY/TIME.</p> <p>DATE, TIME, TIMESTAMP can be cast or coerced into equivalent strings for comparison.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sql-create","title":"SQL Create","text":""},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#create-schema","title":"CREATE SCHEMA","text":"<ul> <li>Create a schema with all its definitions, or just name and authorization identifier (with the rest to be provided later), e.g.:</li> </ul> <pre><code>CREATE SCHEMA COMPANY AUTHORIZATION 'Jsmith';\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#create-table","title":"CREATE TABLE","text":"<ul> <li>Create a base table (new base relation; created and stored as a file by the DBMS) with a name, its attributes, and initial constraints</li> <li>Key, entity integrity, and referential integrity constraints can be specified in this statement or added later with ALTER TABLE</li> </ul> <pre><code>CREATE TABLE EMPLOYEE\n</code></pre> <p>Above, the schema is implicit; it can also be explicit:</p> <pre><code>CREATE TABLE COMPANY.EMPLOYEE\n</code></pre> <p>Full example:</p> <pre><code>CREATE TABLE DEPARTMENT\n(\n    Dname VARCHAR(15) NOT NULL,\n    Dnumber INT NOT NULL,\n    Manager CHAR(9) NOT NULL DEFAULT '123456789',\n    CONSTRAINT DEPTPK\n    PRIMARY KEY (Dnumber),\n    UNIQUE (Dname),\n    FOREIGN KEY (Manager) REFERENCES EMPLOYEE(Ssn)\n    ON DELETE SET DEFAULT ON UPDATE CASCADE\n);\n</code></pre> <p>Attributes are considered to be ordered in the sequence in which they are specified, but rows are not considered to be ordered in a table.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#create-view","title":"CREATE VIEW","text":"<p>Create a virtual relation (view) which may or may not correspond to a physical file.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#create-domain","title":"CREATE DOMAIN","text":"<p>Data type can be directly specified for an attribute. Alternatively, declare a domain (abstraction layer) e.g. for SSN_TYPE:</p> <pre><code>CREATE DOMAIN SSN_TYPE AS CHAR(9);\n</code></pre> <p>Then use SSN_TYPE in place of CHAR(9) later.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#create-type","title":"CREATE TYPE","text":"<p>Creates user-defined types (UDT).</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#constraints-in-sql","title":"Constraints in SQL","text":"<p>With CREATE you can specify CONSTRAINT, e.g. <code>NOT NULL</code></p> <p>... and DEFAULT, e.g. <code>DEFAULT 1</code></p> <ul> <li>Included whenever an explicit value is not specified</li> <li>If unspecified, is NULL unless there is a NOT NULL constraint</li> </ul> <p>The CHECK clause follows an attribute or domain definition and can specify constraint, e.g. restrict to integer between 1 and 20:</p> <pre><code>CREATE DOMAIN D_NUM AS INTEGER CHECK (D_NUM &gt; 0 AND D_NUM &lt; 21);\n</code></pre> <p>CHECK also specifies table constraints at the end of the CREATE TABLE statement called row-based constraints, which apply individually to each row. These are checked when a row is inserted or modified.</p> <pre><code>CHECK (Dept_create_date &lt;= Manager_start_date);\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#key-and-referential-integrity-constraints","title":"Key and Referential Integrity Constraints","text":"<p>For PK with a single attribute, can be specified following the attribute and domain:</p> <pre><code>Dnumber INT PRIMARY KEY;\n</code></pre> <p>UNIQUE can also be specified this way if it is a single attribute:</p> <pre><code>Dname VARCHAR(15) UNIQUE;\n</code></pre> <p>Referential integrity is specified with the FOREIGN KEY clause. A referential triggered action clause may be added with options:</p> <ul> <li>SET NULL</li> <li>CASCADE<ul> <li>Delete all referencing tuples or update value of all referencing FK attributes</li> <li>Generally suitable for relationship relations, relations that represent multivalue attributes, and relations that represent weak entity types</li> </ul> </li> <li>SET DEFAULT</li> </ul> <p>...qualified with one of:</p> <ul> <li>ON DELETE</li> <li>ON UPDATE</li> </ul> <p>Constraints can be optionally named, following the CONSTRAINT keyword.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sql-retrieval-queries","title":"SQL Retrieval Queries","text":"<p>The SELECT statement (different from SELECT operation in relational algebra) retrieves information from the DB.</p> <p>A SQL table is not a set of tuples (in a set, all members are unique); it is a multiset, or bag of tuples. A SQL relation may be constrained to be sets, e.g. when DISTINCT is used with SELECT.</p> <p>Basic form is called mapping or select-from-where block:</p> <pre><code>SELECT &lt;attribute list&gt;     -- attribute names for values you want to retrieve\nFROM &lt;table list&gt;           -- relation names\nWHERE &lt;condition&gt;;          -- Boolean expression to identify tuples to be retrieved\n</code></pre> <p>Only SELECT and FROM are mandatory.</p> <p>A query selects the relation's tuples that satisfy (evaluates to TRUE) the Boolean WHERE condition (selection condition in relational algebra) and projects the result on the attributes listed in the SELECT clause, which specifies the attributes whose values to retrieve (projection attributes in relational algebra).</p> <p>An implicit tuple variable is thought to iterate in the SQL query, looping over each tuple to evaluate the condition and return those for which it evaluates to TRUE.</p> <p>In WHERE, any number of selection conditions can choose a particular tuple (<code>Dname = 'Research'</code>); any number of join conditions can combine tuples from more than one relation (<code>Dnumber</code> from DEPARTMENT = <code>Dno</code> from EMPLOYEE):</p> <pre><code>SELECT Fname, Lname, Address\nFROM EMPLOYEE, DEPARTMENT\nWHERE Dname = 'Research' AND Dnumber = Dno;\n</code></pre> <p>A select-project-join query has only selection and join conditions plus projection attributes. Each tuple in the result is a combination of one of each of the joined tuples.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#logical-comparison-operators","title":"Logical Comparison Operators","text":"lanuage equal less than less than or equal greater than greater than or equal not equal SQL = &lt; &lt;= &gt; &gt;= &lt;&gt; relational algebra = &lt; \u2264 &gt; \u2265 \u2260 C/C++ = &lt; &lt;= &gt; &gt;= !="},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#renaming-tuple-variables","title":"Renaming, Tuple Variables","text":"<p>Attributes in different tables can have the same name; we sometimes need to qualify the attribute name with the relation name to prevent ambiguity. Use fully qualified attribute names: prefix the attribute name with the relation name, separated by a period.</p> <pre><code>SELECT Fname, EMPLOYEE.Name, Address\nFROM EMPLOYEE, DEPARTMENT\nWHERE DEPARTMENT.Name = 'Research' AND DEPARTMENT.Dnumber = EMPLOYEE.Dnumber;\n</code></pre> <p>Use an alias or tuple variable to give a shorthand to long relation names, or make relations that appear twice more understandable:</p> <pre><code>SELECT E.Fname, E.Lname, S.Fname, S.Lname\nFROM EMPLOYEE AS E, EMPLOYEE AS S\nWHERE E.Super_ssn = S.Ssn;\n</code></pre> <p>This creates two copies of the EMPLOYEE relation that can now be joined (one-level recursive query).</p> <p>Aliases can also directly follow the relation name: <code>FROM EMPLOYEE E</code>. Relation attributes can be renamed within the query with aliases:</p> <pre><code>FROM EMPLOYEE AS E(Fn, Ln)\n</code></pre> <p>Results can also be renamed:</p> <pre><code>SELECT E.Lname AS Employee_name, S.Lname AS Supervisor_name\nFROM EMPLOYEE AS E, EMPLOYEE AS S\nWHERE E.Ssn = S.Ssn;\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#unspecified-where-asterisk","title":"Unspecified WHERE, Asterisk","text":"<p>A missing WHERE clause selects all tuples from the specified relation; if more than one relation is specified in FROM, the CROSS PRODUCT (all possible tuple combinations) is selected. This can inadvertently select very large relations.</p> <p>To intentionally retrieve all attribute values, specify an asterisk, optionally prefixed with the relation name or alias, e.g. <code>EMPLOYEE*</code>.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#duplicates-distinct","title":"Duplicates, DISTINCT","text":"<ul> <li>Since SQL treats a table as a multiset, duplicates are not eliminated from query results by default; can also do this explicitly with <code>SELECT ALL</code></li> <li>A SQL table with a key is restricted to being a set, since the key must be distinct in each tuple</li> </ul> <p>To eliminate duplicates from the results, use DISTINCT in the SELECT clause:</p> <pre><code>SELECT DISTINCT Salary\nFROM EMPLOYEE;\n</code></pre> <p>or</p> <pre><code>SELECT DISTINCT(Attribute)\nFROM RegularUser;\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#set-operations","title":"Set Operations","text":"<p>The relational-algebra-equivalent set operations result in sets of tuples (distinct) and apply only to type-compatible relations.</p> <p>Corresponding multiset operations (not distinct) are followed by ALL, e.g. UNION ALL.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#union-set-union","title":"UNION: set union","text":"<p>Returns all cities from CurrentCity and HomeTown columns.</p> <pre><code>SELECT CurrentCity\nFROM RegularUser\nUNION\nSELECT HomeTown\nFROM RegularUser;\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#except-set-difference-also-minus","title":"EXCEPT: set difference, also MINUS","text":"<p>Give all CurrentCities except those that are someone's HomeTown.</p> <pre><code>SELECT CurrentCity\nFROM RegularUser\nEXCEPT\nSELECT HomeTown\nFROM RegularUser;\n</code></pre> <p>EXCEPT ALL to return cities if they appear more times as CurrentCities than as HomeTown; i.e. include it in results if it is a duplicate.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#intersect-set-intersection","title":"INTERSECT: set intersection","text":"<p>Returns distinct cities that are someone's CurrentCity and someone's HomeTown.</p> <pre><code>SELECT CurrentCity\nFROM RegularUser\nINTERSECT\nSELECT HomeTown\nFROM RegularUser\n</code></pre> <p>INTERSECT ALL to include duplicates.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#pattern-matching","title":"Pattern Matching","text":"<p>The LIKE comparison operator can be used for string pattern matching. The <code>%</code> reserved character replaces an arbitrary number of 0 or more characters (anything), and <code>_</code> replaces a single character.</p> <pre><code>SELECT Fname, Lname\nFROM EMPLOYEE\nWHERE Address LIKE '%Houston,%TX%';\n-- or\nWHERE Bdate LIKE '____06__'; -- June birthdays\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#literal-characters","title":"Literal Characters","text":"<ul> <li>Specify an escape character with ESCAPE: <code>'A\\_BC' ESCAPE '\\'</code> gives a literal <code>_</code>.</li> <li>For <code>'</code>, use <code>''</code>.</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#operators","title":"Operators","text":"<p>Arithmetic can be applied to numeric values or attributes (numeric domains): <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code></p> <pre><code>SELECT E.Fname, E.Lname, 1.1 * E.Salary AS Raise\nFROM EMPLOYEE AS E\n...\n</code></pre> <p>Strings can be concatenated with <code>||</code>.</p> <p>Date, time, timestamp, and interval data types can be incremented (<code>+</code>) or decremented (<code>-</code>) by an interval.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#comparison-operators","title":"Comparison Operators","text":"<ul> <li>BETWEEN is equivalent to <code>(Thing &gt;= INT) AND (Thing &lt;= INT)</code>.</li> <li>IN compares a value v with a set or multiset of values V and is TRUE if v is an element of V.</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#ordering-or-sorting","title":"Ordering, or Sorting","text":"<p>Use ORDER BY, optionally with DESC or ASC: <code>ORDER BY D.Dname DESC, E.Lname ASC, E.Fname ASC;</code></p> <p>Default is ascending order of values.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#modification-insert-delete-update","title":"Modification: INSERT, DELETE, UPDATE","text":"<p>INSERT adds a single row to the table given a relation name and list of values listed in the same order as the attributes:</p> <pre><code>INSERT INTO EMPLOYEE\n-- or specify attribute names, as long as all NOT NULL are included\nINSERT INTO EMPLOYEE(Fname, Lname, Phone)\nVALUES ('Jim', 'Bob', '1235559999');\n</code></pre> <p>Insert multiple tuples, separated by commas, by enclosing the attributes for each in parenthesis.</p> <p>Insert multiple rows if the insertion contains a query expression that identifies some data from the DB and inserts it in one of the DB tables.</p> <p>Create a temporary table by combining CREATE TABLE NEW_TABLE with INSERT INTO NEW_TABLE; values here may not remain updated (use a view for this instead). Later, remember to DROP TABLE.</p> <p>Create a similar table to an existing one (same attributes) using existing data (WITH DATA) with LIKE:</p> <pre><code>CREATE TABLE W9EMP LIKE EMPLOYEE\n(SELECT E.*\nFROM EMPLOYEE AS E\nWHERE E.Status = 'W9') WITH DATA;\n</code></pre> <p>DELETE removes tuples from a relation and can be used with WHERE. If WHERE is missing, all tuples are to be deleted, but the table remains until you DROP TABLE. Can delete a set of rows.</p> <p>UPDATE modifies attribute values in a single relation. The SET clause specifies the attributes to be modified, and new values, e.g. to update Project 10:</p> <pre><code>UPDATE PROJECT\nSET Plocation = 'Bellaire', Pmanager = 5\nWHERE Pnumber = 10;\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sql-access","title":"SQL Access","text":"<p>GRANT and REVOKE can modify privileges for specific statements on certain relations.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#null-logic","title":"NULL Logic","text":"<p>Any NULL value is considered to be distinct from any other NULL (can't use <code>=</code>); when compared, the result is considered UNKNOWN and may be TRUE or FALSE. Three-value logic is used:</p> AND TRUE FALSE UNKNOWN TRUE TRUE FALSE UNKNOWN FALSE FALSE FALSE FALSE UNKNOWN UNKNOWN FALSE UNKNOWN OR TRUE FALSE UNKNOWN TRUE TRUE TRUE TRUE FALSE TRUE FALSE UNKNOWN UNKNOWN TRUE UNKNOWN UNKNOWN NOT TRUE FALSE FALSE TRUE UNKNOWN UNKNOWN <p>Compare using the IS or IS NOT operator:</p> <pre><code>SELECT Fname, Lname\nFROM EMPLOYEE\nWHERE Ssn IS NULL;\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#nested-queries","title":"Nested Queries","text":"<p>Complete select-from-where blocks within another SQL query (outer query); can appear in the WHERE, FROM, or SELECT clauses.</p> <pre><code>SELECT DISTINCT Pnumber\nFROM PROJECT\nWHERE Pnumber IN\n(SELECT Pnumber\n    FROM PROJECT, DEPARTMENT, EMPLOYEE\n    WHERE Dnum = Dnumber AND\n        Manager = Ssn AND Lname = 'Smith')\n\n    OR\n    Pnumber IN\n(SELECT Pno\n    FROM WORKS_ON, EMPLOYEE\n    WHERE Employer = Ssn AND Lname = 'Smith');\n</code></pre> <ul> <li>Returns a scalar (single value) if result is a single attribute and a single tuple; can use <code>=</code> in this case</li> <li>Usually returns a table (relation: set or multiset of tuples)</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#comparing-nested-queries","title":"Comparing Nested Queries","text":"<p>Tuples can be used in comparisons, using parenthesis:</p> <pre><code>SELECT DISTINCT Essn\nFROM WORKS_ON\nWHERE (Pno, Hours) IN (SELECT Pno, Hours\n                        FROM WORKS_ON\n                        WHERE Essn = '56');\n</code></pre> <p>To compare a single value v with a set or multiset V:</p> <ul> <li>ANY or SOME is equivalent to IN<ul> <li>Can be combined with operators: <code>= ANY</code>, <code>&gt; SOME</code>, etc</li> </ul> </li> <li>ALL returns true if all the values in the set are true for the operator</li> </ul> <pre><code>SELECT Lname, Fname\nFROM EMPLOYEE\nWHERE Salary &gt; ALL (SELECT Salary\n                    FROM EMPLOYEE\n                    WHERE Dno = 5);\n</code></pre> <p>A reference to an unqualified attribute refers to the relation declared in the innermost nested query. Generally, create aliases for all tables referenced in a query to avoid ambiguity from same attribute names.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#correlated-nested-queries","title":"Correlated Nested Queries","text":"<p>When a condition in the WHERE clause references an attribute of a relation declared in the outer query, the two queries are correlated. The nested query is evaluated once for each tuple in the outer query.</p> <p>E.g. Find Email and BirthYear of RegularUsers who have no Interests.</p> <pre><code>SELECT R.Email, BirthYear\nFROM RegularUser R\nWHERE NOT EXIST\n    (SELECT *\n    FROM UserInterests U\n    WHERE U.Email = R.Email);\n</code></pre> <p>A query written with nested select-from-where blocks and using <code>=</code> or IN can always be expressed as a single block query instead.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#functions","title":"Functions","text":""},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#unique","title":"UNIQUE","text":"<p>Returns TRUE if there are no duplicate tuples in the result; otherwise FALSE.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#exists-and-not-exists","title":"EXISTS and NOT EXISTS","text":"<p>Boolean functions that return TRUE or FALSE; can be used in WHERE clause.</p> <p>EXISTS checks if the result of a nested query is empty; is FALSE if it is empty, and TRUE if it contains at least one tuple.</p> <pre><code>SELECT E.Fname, E.Lname\nFROM EMPLOYEE AS E\nWHERE EXISTS (SELECT *\n                FROM DEPENDENT AS D\n                WHERE E.Ssn = D.Essn); -- True if there is at least one tuple\n</code></pre> <p>There's also NOT EXISTS (sort of like \"does not have\"). Typically used with a correlated nested query.</p> <pre><code>SELECT Fname, Lname\nFROM EMPLOYEE\nWHERE NOT EXISTS (SELECT *\n                    FROM DEPENDENT\n                    WHERE Ssn = Essn); -- If this evalues to true (none exist) the EMPLOYEE tuple is returned\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#explicit-sets","title":"Explicit Sets","text":"<p>An explicit set of values can be used in the WHERE clause rather than a nested query (\"hard coding\").</p> <pre><code>SELECT DISTINCT Essn\nFROM WORKS_ON\nWHERE Pno IN (1,2,3);\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#joined-tables","title":"Joined Tables","text":"<p>A table resulting from a join operation in the FROM clause; may be easier to specify than a complex WHERE clause. Defaults to inner join.</p> <pre><code>SELECT Fname, Lname, EAddress\nFROM (EMPLOYEE JOIN DEPARTMENT ON Dno = Dnumber)\nWHERE Dname = 'Research';\n</code></pre> <p>Above returns a single joined table with all the attributes of the EMPLOYEE table followed by all those of the DEPARTMENT table.</p> <p>NATURAL JOIN does not specify any join condition:</p> <ul> <li>Defaults to a Cartesian Product if there are no same named attributes in the two relations</li> <li>Implicit EQUIJOIN condition for each pair of attributes with the same name is created and each pair is included once in the result</li> <li>If the attribute names don't match, they can be renamed to match before applying NATURAL JOIN</li> </ul> <p>Join types:</p> <ul> <li>JOIN or INNER JOIN: only pairs of tuples that match the join condition are retrieved</li> <li>OUTER JOIN: can be used to explicitly include all tuples<ul> <li>LEFT OUTER JOIN (<code>+=</code>): include every tuple in the left table in the result; right table padded with NULL values</li> <li>RIGHT OUTER JOIN (<code>=+</code>): include every tuple in the right table in the result; left table padded with NULL values</li> <li>FULL OUTER JOIN (<code>+=+</code>)</li> <li>Can also leave off OUTER keyword</li> </ul> </li> <li>Can specify the natural join variation: e.g. NATURAL LEFT OUTER JOIN</li> <li>CROSS JOIN: specifies CARTESIAN PRODUCT operation (all possible tuple combinations)</li> </ul> <p>Joins can be nested (multiway join):</p> <pre><code>SELECT Pnumber, Dnum, Lname, Bdate\nFROM ((PROJECT JOIN DEPARTMENT ON Dnum = Dnumber)\nJOIN EMPLOYEE ON Manager = Ssn)\nWHERE Plocation = 'Stafford';\n</code></pre> <p>Natural inner join with dot notation:</p> <pre><code>SELECT Email, RegularUser.BirthYear, Salary\nFROM RegularUser, YearSalary\nWHERE RegularUser.BirthYear = YearSalary.BirthYear;\n</code></pre> <p>...is the same as</p> <pre><code>SELECT Email, RegularUser.BirthYear, Salary\nFROM RegularUser NATURAL JOIN YearSalary;\n</code></pre> <p>where we don't have to specify the join condition.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#aggregate-functions","title":"Aggregate Functions","text":"<ul> <li>Built-in functions</li> <li>Summarize information from multiple tuples into a single-tuple summary</li> <li>Subgroups are made using grouping before summarization</li> <li>Excludes NULL values when applied to a collection of values; an empty collection returns NULL (COUNT returns 0)</li> </ul> <p>Functions are used in SELECT or HAVING clauses and include:</p> <ul> <li>COUNT: return the number of tuples or values resulting from the query<ul> <li>E.g. COUNT(*) returns number of rows (tuples) resulting from the query</li> <li>COUNT(Salary) returns number of salary values in the DB (NULL values discarded)</li> <li>COUNT(DISTINCT Salary) returns number of distinct salary values in DB (NULL values discarded)</li> </ul> </li> <li>SUM</li> <li>MAX</li> <li>MIN</li> <li>AVG (mean)</li> </ul> <p>These can be applied to nonnumeric domains that have total ordering, e.g. DATE, TIME, TIMESTAMP.</p> <pre><code>SELECT SUM(Salary), MAX(Salary), MIN(Salary), AVG(Salary)\nFROM EMPLOYEE;\n</code></pre> <p>SOME or ALL can be applied to Boolean values; TRUE is returned if the condition is true for SOME or ALL elements.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#grouping","title":"Grouping","text":"<p>Apply aggregate functions to a subgroup of tuples (partition the relation into exclusive subsets or groups using grouping attributes).</p> <p>GROUP BY specifies grouping attributes that appear in the SELECT clause; the value resulting from the aggregate function appears with the value of the grouping attribute.</p> <pre><code>SELECT Dno, COUNT(*), AVG(Salary) -- List for each department\nFROM EMPLOYEE\nGROUP BY Dno;   -- Results are grouped by department no. before the aggregate functions are applied\n</code></pre> <p>A separate group is created for NULL value tuples in the grouping attribute.</p> <p>When used with a join condition, grouping and aggregation is applied after the joining in WHERE clause.</p> <p>HAVING applies conditions whereby only the groups that satisfy it are retrieved in the results:</p> <pre><code>SELECT Pnumber, Pname, COUNT(*)\nFROM PROJECT, WORKS_ON\nWHERE Pnumber = Pno -- join condition (project number)\nGROUP BY Pnumber, Pname\nHAVING COUNT(*) &gt; 2; -- only return results for projects with more than two employee rows in the table\n</code></pre> <p>Execution order: WHERE, then HAVING.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#with","title":"WITH","text":"<p>A user-defined temporary table that is used once for a particular query; convenience method.</p> <pre><code>WITH BIGDEPTS (Dno) AS (\n    SELECT Dno\n    FROM EMPLOYEE\n    GROUP BY Dno\n    HAVING COUNT (*) &gt;5;\n)\nSELECT Dno, COUNT(*)\nFROM EMPLOYEE\nWHERE Salary &gt; 40000 AND Dno IN BIGDEPTS\nGROUP BY Dno;\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#case","title":"CASE","text":"<p>A case switch.</p> <pre><code>UPDATE EMPLOYEE\nSET Salary =\nCASE WHEN Dno = 5 THEN Salary +2000\n     WHEN Dno = 4 THEN Salary +1500\n     ELSE Salary + 0;\n</code></pre> <p>Useful for inserting tuples where different attributes may be NULL.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#recursive-queries","title":"Recursive Queries","text":"<p>Employee and Supervisor (both rows in the EMPLOYEE table) is an example of a recursive relationship. A recursive operation could retrieve all supervisees of a Supervisor at all levels.</p> <pre><code>WITH RECURSIVE SUP_EMP (SupSsn, EmpSsn) AS  -- defines a view SUP_EMP to hold result\n(SELECT SupervisorSsn, Ssn\nFROM EMPLOYEE                               -- base query loads the first level\nUNION                                       -- combines each successive level\nSELECT E.Ssn, S.SupSsn                      -- selects this level's supervisor\nFROM EMPLOYEE AS E, SUP_EMP AS S\nWHERE E.SupervisorSsn = S.EmpSsn)\nSELECT*                                     -- return everything from SUP_EMP\nFROM SUP_EMP;\n</code></pre> <p>Above will query recursively, combining the results with previous levels (UNION), until a fixed point is reached, when all the results are in the view.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sql-assertions","title":"SQL Assertions","text":"<p>General constraints can be specified with declarative assertions using CREATE ASSERTION and giving it a name:</p> <pre><code>CREATE ASSERTION SALARY_CONSTRAINT\nCHECK\n(NOT EXISTS\n(SELECT *\nFROM EMPLOYEE E, EMPLOYEE M, DEPARTMENT D\nWHERE E.Salary&gt;M.Salary -- Employee salary cannot exceed Manager salary; violated if this is true\n    AND E.Dno = D.Dnumber\n    AND D.Manager = M.Ssn)\n);\n</code></pre> <ul> <li>The DBMS is responsible for ensuring the condition is not violated (doesn't evaluate to FALSE).</li> <li>CHECK clauses on individual attributes, domains, and tuples are only checked when tuples are inserted or updated, so use them when the constraint can only be violated by insert or update.</li> <li>Use CHECK on attributes instead, if possible, for efficiency.</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sql-trigger","title":"SQL Trigger","text":"<p>CREATE TRIGGER sets a condition used to monitor the DB. A typical ECA trigger has three components:</p> <ul> <li>Event(s), usually database update operations<ul> <li>Specify after the BEFORE or AFTER keyword</li> </ul> </li> <li>Condition: an optional condition may be evaluated to determine if action should be executed (if TRUE); if no condition, action will execute<ul> <li>Specified with WHEN</li> </ul> </li> <li>Action to be taken, e.g. stored procedure</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sql-views","title":"SQL Views","text":"<ul> <li>A view (single table derived from other tables) is a virtual table<ul> <li>Limited update operations</li> <li>Made up of defining tables</li> <li>Definition is stored in the catalog</li> </ul> </li> <li>Unlike base tables which are physically stored in the DB</li> </ul> <pre><code>CREATE VIEW DEPT_INFO(Dept_name, No_of_emps, Total_sal) -- specify new attribute names if they are not inherited (no functions)\nAS SELECT Dname, COUNT(*), SUM(Salary)\nFROM DEPARTMENT, EMPLOYEE\nWHERE Dnumber = Dno\nGROUP BY Dname;\n</code></pre> <ul> <li>Column names are inherited from base tables or can be explicitly named in the definition</li> <li>Computed columns must be explicitly named</li> </ul> <p>Query views like any table. DROP VIEW to dispose of one.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#updating-views","title":"Updating Views","text":"<ul> <li>Supposed to be always up to date; materialized when we specify a query on a view (not necessarily at time of view definition)</li> <li>DBMS is responsible for keeping view up to date</li> </ul> <p>Two main approaches for efficient querying:</p> <ul> <li>Query modification transforms the submitted query into a query on the underlying base tables<ul> <li>Inefficient for views defined with complex (time consuming) queries</li> </ul> </li> <li>View materialization physically creates (thus stores) a temporary or permanent view table when the view is first queried or created</li> </ul> <p>Need efficient strategy for automatically updating the view table:</p> <ul> <li>Incremental update: DBMS determines what new tuples need inserting/modifying/deleting in the materialized view table when such operation is applied to the underlying base table<ul> <li>The view is kept materialized as long as it is being queried and the physical table may be automatically removed after some time (then needs to be recomputed next time)</li> </ul> </li> <li>Immediate update strategy updates the view when the base tables are changed</li> <li>Lazy update strategy updates the view when needed by a view query</li> <li>Periodic update strategy updates the view periodically; some queries may not have the latest data</li> </ul> <p>Issuing INSERT, DELETE, UPDATE on view tables may not be possible; generally this is feasible when there is only one possible update on the base relations to accomplish the operation on the view.</p> <ul> <li>View with single defining table is updatable if view attributes contain the PK of the base relation and all attributes with NOT NULL constraint that do not have default values specified</li> <li>Add WITH CHECK OPTION to the view definition if INSERT, DELETE, or UPDATE on this view is expected; allows system to reject operations that violate SQL rules for view updates</li> </ul> <p>Generally not updatable (can't insert, delete, update):</p> <ul> <li>Contains JOIN, UNION, INTERSECT, EXCEPT, DISTINCT</li> <li>Has a GROUP BY clause</li> <li>Uses HAVING</li> <li>Views defined on multiple tables using joins</li> <li>Views defined using grouping and aggregate functions</li> </ul> <p>Generally updatable if:</p> <ul> <li>Every column in the view corresponds to a uniquely identifiable base table column</li> <li>FROM clause references just one table (base table or updatable view)<ul> <li>The table referenced cannot be referenced in the FROM clause of a nested WHERE clause</li> </ul> </li> </ul> <p>An in-line view is defined using the FROM clause within a query itself.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#materialized-view","title":"Materialized View","text":"<ul> <li>Definition stored in catalog</li> <li>Select Query is run and results are stored in the materialized view table</li> </ul> <pre><code>CREATE MATERIALIZED VIEW ViewName\n[REFRESH [FAST|COMPLETE|FORCE][ON DEMAND|ON COMMIT]][BUILD IMMEDIATE|BUILD DEFERRED]\nAS Select Query;\n</code></pre> <p>Options includes:</p> <ul> <li>REFRESH FAST: incremental refresh method uses changes made to the underlying tables in a log file</li> <li>REFRESH COMPLETE: complete refresh: re-runs the query</li> <li>REFRESH FORCE: a fast refresh should be performed if possible, but if not, a complete refresh is performed</li> <li>REFRESH ON DEMAND: a refresh will occur manually whenever specific package functions are called</li> <li>REFRESH ON COMMIT: a fast refresh occurs whenever a transaction commits that makes changes to any of the underlying tables</li> <li>BUILD IMMEDIATE: the materialized view will be populated immediately (default)</li> <li>BUILD DEFERRED: the materialized view is populated on the next refresh operation</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#views-for-authorization","title":"Views for Authorization","text":"<ul> <li>Views can be used to only show certain information to certain users</li> <li>Create the appropriate view and grant only those certain users access to it instead of the base tables</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#schema-change-statements","title":"Schema Change Statements","text":"<p>Altering schema (add or drop tables) is done with schema evolution commands.</p> <p>DROP can drop named elements (tables, domains, types, constraints) as well as a whole schema. Drop behavior options:</p> <ul> <li>CASCADE (<code>DROP SCHEMA COMPANY CASCADE</code>): remove everything and any referencing elements</li> <li>RESTRICT (<code>DROP SCHEMA COMPANY RESTRICT</code>): only if there are no elements in it or it is not referenced in any constraints</li> </ul> <p>DROP TABLE also removes the table definition from the catalog. DELETE will remove the records but retain the table definition.</p> <p>ALTER makes changes to base tables (alter table actions) or other named schema elements.</p> <pre><code>ALTER TABLE COMPANY.EMPLOYEE ADD COLUMN Job VARCHAR(12);\n</code></pre> <p>Provide any missing values or SET DEFAULT to something, otherwise missing ones are NULL.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#relational-algebra","title":"Relational Algebra","text":"<ul> <li>Formal language; defines a set of operations for the formal relational model</li> <li>Basic retrieval requests are a sequence of relational algebra operations forming relational algebra expressions</li> <li>Provides a formal foundation for relational model operations</li> <li>Used as a basis for implementing and optimizing queries in the processing and optimization modules in RDBMS</li> <li>Closed algebra: each time you do an operation on rational numbers you get a rational number back of the same type as you started with</li> <li>Use previous thoughts to form new thoughts and build higher level models</li> <li>Relations are sets (relational algebra is a closed query language)<ul> <li>Sets means that duplicates in results are eliminated</li> <li>E.g. \u03c0BirthYear (\u03c3HomeTown='Atlanta'(RegularUser))</li> <li>Duplicate BirthYear, duplicate 'Atlanta' are eliminated</li> </ul> </li> </ul> <p>A retrieval query results in a new relation.</p> <p>Relational calculus:</p> <ul> <li>Formal language; provides higher-level declarative language for specifying relational queries</li> <li>These have no order of operations for the queries, only what information the result should contain</li> <li>Two variations:<ul> <li>Tuple relational calculus</li> <li>Domain relational calculus</li> </ul> </li> </ul> <p>Relational algebra can be divided into groups of operations.</p> <p>Set operations from mathematical set theory:</p> <ul> <li>UNION</li> <li>INTERSECTION</li> <li>SET DIFFERENCE</li> <li>CARTESIAN PRODUCT (CROSS PRODUCT)</li> </ul> <p>And special operators:</p> <ul> <li>PROJECTION (eliminate columns)</li> <li>SELECTION (eliminate rows)</li> </ul> <p>Constructor operations (joins):</p> <ul> <li>Natural join</li> <li>Outer join<ul> <li>Left, right, full</li> </ul> </li> <li>Theta join</li> </ul> <p>And quite special operators:</p> <ul> <li>Divideby</li> <li>Rename</li> </ul> <p>Relational database operations:</p> <ul> <li>Unary operations operate on a single relation:<ul> <li>SELECT</li> <li>PROJECT</li> </ul> </li> <li>Binary operations operate on two tables by combining related tuples (records) based on join conditions<ul> <li>JOIN</li> </ul> </li> <li>... and others.</li> </ul> <p>In addition to the original relational algebra operations:</p> <ul> <li>Aggregate functions summarize data from tables</li> <li>Additional OUTER JOINs and OUTER UNIONs</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#unary-relational-operations","title":"Unary Relational Operations","text":""},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#select-operation","title":"SELECT Operation","text":"<ul> <li>SELECT chooses a subset of the tuples from a relation (selects rows) that satisfy a selection condition, i.e. a filter</li> <li>Thought of as horizontal partition of the relation into two sets of tuples (those that satisfy the condition and are selected; those that are filtered out)</li> </ul> \\[ \\sigma _{Dno=4}(EMPLOYEE) \\] <p>SELECT notation:</p> \\[ \\sigma_{&lt;selection condition&gt;}(R) \\] <ul> <li>Sigma denotes SELECT</li> <li>R is generally a relational algebra expression whose result is a relation</li> <li>The resulting relation from the operation has the same attributes as R and the same degree<ul> <li>The number of tuples in the result is always &lt;= R: $$ |\\sigma{c}(R)|\\leq|R| $$</li> </ul> </li> </ul> <p>The selection condition is a Boolean expression on the relation R</p> <ul> <li>Made up of a number of clauses with one of the forms:<ul> <li><code>&lt;attribute name&gt; &lt;comparison op&gt; &lt;constant value&gt;</code></li> <li><code>&lt;attribute name&gt; &lt;comparison op&gt; &lt;attribute name&gt;</code></li> <li>Which is:<ul> <li>The name of an attribute of R</li> <li>One of the operators <code>{=, &lt;, \u2264, &gt;, \u2265, \u2260}</code> which can apply to attributes whose domains are ordered values (numeric, date, strings)<ul> <li>For unordered values (e.g. set of color strings without order specified) only <code>{=, \u2260}</code> can be used</li> <li>Domains may have additional comparison operators, e.g. SUBSTRING_OF</li> </ul> </li> <li>Constant value from the attribute domain</li> </ul> </li> <li>Clauses can be connected with and, or, not to form selection conditions</li> </ul> </li> <li>Use of parenthesis changes the order of expression</li> <li>NOT() negates the expression <p>Composite expressions with AND, OR, NOT have their normal effect:</p> <ul> <li>(one AND two) is TRUE if both are true</li> <li>(one OR two) is TRUE if either or both are true</li> <li> <p>(NOT condition) is TRUE if condition is not the case</p> </li> <li> <p>The selectivity of the condition is the fraction of tuples selected.</p> </li> <li>SELECT is commutative (independent of order) so a sequence (cascade) of SELECTs can be applied in any order and can be combined into a single SELECT with AND (conjunctive condition)</li> </ul> <p>To determine the result of a SELECT operation:</p> <ul> <li>The selection condition is applied independently to each individual tuple (one tuple at a time), t, in R by:<ul> <li>Substituting each occurrence of an attribute A\u1d62 in the selection condition with its value in the tuple t[A\u1d62].</li> </ul> </li> <li>If the condition evaluates to TRUE, t is selected.</li> </ul> <p>SELECT is specified in the WHERE clause of a SQL query:</p> \\[ \\sigma_{Dno=4 AND Salary&gt;25000}(EMPLOYEE) \\] <p>... corresponds to:</p> <pre><code>SELECT *\nFROM EMPLOYEE\nWHERE Dno=4 AND Salary&gt;25000;\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#project-operation","title":"PROJECT Operation","text":"<ul> <li>PROJECT selects certain columns from the table and discards others</li> <li>Project the relation over only certain attributes of a relation</li> <li>Thought of as vertical partition of the relation into two relations (one with needed columns, the result; another with discarded columns)</li> </ul> \\[ \\pi_{Lname, Fname, Salary}(EMPLOYEE) \\] <p>PROJECT notation:</p> \\[ \\pi_{&lt;attribute list&gt;}(R) \\] <ul> <li>Pi denotes PROJECT</li> <li>attribute list is the desired sublist of attributes from relation R<ul> <li>Result of PROJECT has the attributes specified in the same order as the given list; thus the same degree as the given list</li> </ul> </li> <li>Any duplicate tuples are removed (result is distinct and a valid relation); duplicate elimination prevents result from being a multiset or bag since it must be a set</li> <li>The number of tuples in the result is always &lt;= the number of tuples in R</li> <li>If the projection list is a superkey of R and includes some key of R, the resulting relation has the same number of tuples as R</li> <li>No commutativity</li> </ul> <p>PROJECT is specified in the SELECT clause of a SQL query:</p> \\[ \\pi_{Sex, Salary}(EMPLOYEE) \\] <p>...corresponds to:</p> <pre><code>SELECT DISTINCT Sex, Salary\nFROM EMPLOYEE\n</code></pre>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#rename-operation","title":"RENAME Operation","text":"<p>Rename either the relation:</p> \\[ \\rho_{S}(R) \\] <p>...or attribute names:</p> \\[ \\rho_{B1, B2, ..., Bn}(R) \\] <p>... or both:</p> \\[ \\rho_{S(B1, B2, ..., Bn)}(R) \\] <ul> <li>RENAME is denoted by rho</li> <li>S is the new relation name</li> <li>B\u2081, B\u2082, ..., B\u2099 are the new attribute names</li> </ul> <p>In SQL, renaming is accomplished with AS.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sequence-of-operations","title":"Sequence of Operations","text":"<p>If not using nested relational algebra expressions, we can apply one operation at a time; we then need names in order to refer to intermediate result relations.</p> <p>An in-line expression is a single relational algebra expression:</p> \\[ \\pi_{Fname, Lname, Salary}(\\sigma_{Dno=5}(EMPLOYEE)) \\] <p>To instead show the explicit sequence of operations, give intermediate relations a name with the assignment operation (left arrow):</p> \\[ DEP5\\_EMPS \\leftarrow \\sigma_{Dno=5}(EMPLOYEE) \\] \\[ RESULT \\leftarrow \\pi_{Fname, Lname, Salary}(DEP5\\_EMPS) \\] <p>We can also rename the attributes in the intermediate and result relations:</p> \\[ TEMP \\leftarrow \\sigma_{Dno=5}(EMPLOYEE) \\] \\[ R(First\\_name, Last\\_name, Salary) \\leftarrow \\pi_{Fname, Lname, Salary}(TEMP) \\] <p>If not renamed, the resulting relation has the same attribute names in the same order as the projection list. Can also use the RENAME operation.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#binary-operations","title":"Binary Operations","text":"<p>Each of these is binary: applied to two sets of tuples.</p> <p>Union compatible or type compatible in relational databases states that the two relations to which any of these operations are applied must have the same type of tuples; that is, the same degree, and each corresponding pair of attributes has the same domain.</p> <p>For UNION, SET INTERSECTION, SET DIFFERENCE, the two operands must be type compatible:</p> <ul> <li>The number of attributes of the two operands must be the same</li> <li>The types of the operands must be compatible</li> </ul> <p>UNION and INTERSECTION are commutative (order doesn't matter):</p> \\[ R \\cup S = S \\cup R\\ and\\ R \\cap S = S \\cap R \\] <p>... and can be treated as n-ary operations (applicable to any number of relations) because they are associative operations:</p> \\[ R \\cup (S\\cup T) = (R\\cup S) \\cup T \\ and\\ (R\\cap S)\\cap T = R \\cap (S \\cap T) \\] <p>MINUS is not commutative (order matters):</p> \\[ R - S \\ne S - R \\] <p>INTERSECTION can be expressed as union and set difference:</p> \\[ R \\cap S = ((R \\cup S) - (R - S)) - (S - R) \\] <p>Multiset operations that do not eliminate duplicates:</p> <ul> <li>UNION ALL</li> <li>INTERSECT ALL</li> <li>EXCEPT ALL</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#union","title":"UNION","text":"<p>Relational algebra operations from set theory (mathematical operations on sets or set theoretic operations) are used to merge the elements of two sets:</p> <p>UNION includes all tuples that are in either R or S or in both; duplicates are eliminated.</p> <p>UNION notation:</p> \\[ R_{1} \\cup R_{2} \\] <p>Indicated by OR: e.g. \"Find all cities that are a CurrentCity or a HomeTown for some RegularUser\"</p> \\[ \\pi_{CurrentCity}(RegularUser)\\cup\\pi_{HomeTown}(RegularUser) \\] <p></p> <p>We get a single list of cities that are either CurrentCity or HomeTown; duplicates are eliminated from the result.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#outer-union","title":"OUTER UNION","text":"<p>Takes the union of tuples from two relations R(X,Y) and S(X,Y) that have some common attributes but that are not type compatible, if they are partially compatible (only some of the attributes X are union compatible).</p> <ul> <li>Attributes that are union compatible are represented once in the result</li> <li>Attributes that are not union compatible are also kept in the result (same as FULL OUTER JOIN)<ul> <li>Tuples without a match are padded with NULL values</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#intersect","title":"INTERSECT","text":"<p>INTERSECTION includes all tuples from R that are in both R and S.</p> <p>INTERSECTION notation:</p> \\[ R_{1} \\cap R_{2} \\] <p>Indicated by AND: e.g. \"Find all cities that are a CurrentCity for someone and a HomeTown for some RegularUser\"</p> \\[ \\pi_{CurrentCity}(RegularUser)\\cap\\pi_{HomeTown}(RegularUser) \\] <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#minus","title":"MINUS","text":"<p>SET DIFFERENCE (MINUS or EXCEPT) includes all tuples that are in R but not in S.</p> <p>DIFFERENCE notation:</p> \\[ R_{1} - R_{2} \\] <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#cartesian-product","title":"CARTESIAN PRODUCT","text":"<p>Also CROSS PRODUCT or CROSS JOIN:</p> <ul> <li>Binary set operation</li> <li>Relations do not have to be union compatible (need not have the same type of tuples, corresponding pairs of the same domains)</li> <li>Binary form: produce a new element by combining every tuple from one set with every tuple from the other set</li> </ul> <p>The result of:</p> \\[ R(A_{1},A_{2},...,A_{n}) \\times S(B_{1},B_{2},...,B_{m}) \\] <p>Is a relation Q with degree n+m attributes:</p> \\[ Q(A_{1},A_{2},...,A_{n},B_{1},B_{2},...,B_{m}) \\] <ul> <li>Has one tuple for each combination of tuples (one from R and one from S):</li> <li>R has nR tuples:     $$     |R| = _{nR}     $$</li> <li>S has nS tuples:     $$     |S| = _{nS}     $$</li> <li>Then R x S will have nR * nS tuples.</li> </ul> <p>The n-ary extension of the above produces new tuples by concatenating all possible combinations of tuples from n underlying relations. Useful when followed by a selection that matches values of attributes produced from the component relations, e.g. retrieve a list of female employee's dependents, or create an invitation list of users matched with all the interests they do not have.</p> <ul> <li>Create combined attributes of two relations with CARTESIAN PRODUCT<ul> <li>Can be realized using CROSS JOIN option in joined tables</li> <li>If there are two tables in FROM clause and no corresponding join condition in the WHERE clause, result will be CARTESIAN PRODUCT of the two tables</li> </ul> </li> <li>SELECT related tuples from the product with a useful selection condition</li> </ul> <p>CARTESIAN PRODUCT notation:</p> \\[ R_{1}\\times R_{2} \\] <p>CARTESIAN PRODUCT followed by SET DIFFERENCE:</p> \\[ (\\pi_{Email}(RegularUser)\\times\\pi_{Interest}(UserInterests))\\div\\pi_{Email, Interest}(UserInterests) \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#binary-relational-operations","title":"Binary Relational Operations","text":""},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#join","title":"JOIN","text":"<p>Combine related tuples from two relations into single \"longer\" tuples. E.g. get the manager of each department by combining DEPARTMENT with EMPLOYEE and projecting result over necessary attributes:</p> \\[ DEPT\\_MGR \\leftarrow DEPARTMENT \\Join _{Mgr\\_ssn=Ssn} EMPLOYEE \\] \\[ RESULT \\leftarrow \\pi_{Dname, Lname, Fname}(DEPT\\_MGR) \\] <ul> <li>Referential integrity constraint helps in having matching tuples in the referenced relation</li> <li>JOIN can be specified as a CARTESIAN PRODUCT operation followed by SELECT<ul> <li>Where two operations are required for CARTESIAN PRODUCT, a single JOIN may be used</li> </ul> </li> </ul> <p>General form of a JOIN operation on two relations (resulting from general relational algebra expressions):</p> \\[ R(A_{1},A_{2},...,A_{n})\\ and\\ S(B_{1},B_{2},...,B_{m}) \\] <p>...is:</p> \\[ R\\Join _{&lt;join\\ condition&gt;}S \\] <ul> <li>The join condition is specified on attributes from R and S and is evaluated for each combination</li> <li>Each combination for which the join condition is TRUE is included in the resulting Q as a single combined tuple</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#theta-join","title":"THETA JOIN","text":"<p>A JOIN with a general join condition is called a THETA JOIN:</p> \\[ A_{i} \\theta B_{j} \\] <ul> <li>Ai is an attribute of R</li> <li>Bj is an attribute of S</li> <li>Ai and Bj have the same domain</li> <li>Theta is one of the comparison operators <code>{=, &lt;, \u2264, &gt;, \u2265, \u2260}</code></li> <li>If the join condition is FALSE for the tuple it does not appear in the results<ul> <li>Tuples that do not get combined with matching ones are omitted from the result (information loss)</li> </ul> </li> <li>Both join attributes appear in the result</li> <li>All attributes are preserved</li> <li>Inner join; tuples that do not match each other are not in the results</li> </ul> <p>THETA JOIN notation:</p> \\[ R_{1} \\Join _{&lt;join\\ condition&gt;}R_{2} \\] <p>E.g.</p> \\[ RegularUser\\Join_{BirthYear&lt;EventYear}MajorEvents \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#equijoin","title":"EQUIJOIN","text":"<ul> <li>JOIN involving join conditions with equality comparisons only</li> <li>Always has one or more pairs of attributes that have identical values (Mgr_ssn = Ssn)</li> <li>One of each pair of attributes with identical values is superfluous</li> </ul> \\[ R_{1} \\Join _{&lt;join\\ condition&gt;}R_{2} $$ ...or $$ R_{1}\\Join_{(&lt;join\\ attributes\\ 1&gt;),(&lt;join\\ attributes\\ 2&gt;)}R_{2} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#natural-join","title":"NATURAL JOIN","text":"<ul> <li>EQUIJOIN followed by the removal of superfluous attributes</li> <li>Will match on the identically named variables (defaults to a Cartesian Product if there are no same named attributes in the two relations)</li> <li>Each pair of join attributes must have the same name in both relations<ul> <li>May need to be renamed first</li> </ul> </li> <li>If no combination of tuples satisfies the join condition, the result is an empty relation with zero tuples</li> </ul> <p>In general:</p> <ul> <li>R has nR tuples:     $$     |R| = _{nR}     $$</li> <li>S has nS tuples:     $$     |S| = _{nS}     $$</li> <li>Then R x S will have nR * nS tuples.</li> </ul> <p>Result of a JOIN operation will have between zero and a maximum size of nR * ns tuples. The expected size of the join result divided by the maximum size leads to a ratio join selectivity.</p> <p>If there is no join condition, all combinations of tuples can be selected and this becomes a CARTESIAN PRODUCT.</p> <p>JOIN in SQL can be realized by:</p> <ul> <li>Specifying join condition in WHERE clause</li> <li>Using nested relation</li> <li>Using joined tables</li> </ul> <p>NATURAL JOIN notation:</p> \\[ R_{1}*_{&lt;join\\ condition&gt;}R_{2} \\] <p>...or</p> \\[ R_{1*\\ (&lt;join\\ attributes 1&gt;),(&lt;join\\ attributes 2&gt;)}R_{2} \\] <p>...or</p> \\[ R_{1} * R_{2} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#inner-vs-outer-join","title":"Inner vs Outer Join","text":"<p>Inner join:</p> <ul> <li>Tuples with no match are eliminated (information loss)</li> <li>A single JOIN operation combines data from two relations, presented in a single table</li> <li>Match-and-combine; CARTESIAN PRODUCT followed by SELECTION</li> <li>Also n-way join combining multiple tables</li> </ul> <p>Outer join:</p> <ul> <li>Keeps all tuples in R or S (both relations) in the join result regardless of whether they have matching tuples in the other relation</li> <li>Combine tables by matching corresponding rows without losing any tuples that don't have matching values<ul> <li>If there is no matching value, use NULL</li> </ul> </li> <li>LEFT OUTER JOIN: keep all tuples from first relation (outer part) in addition to the inner part of the query</li> <li>RIGHT OUTER JOIN: keep all tuples from second relation (outer part) in addition to the inner part of the query</li> <li>FULL OUTER JOIN: keep all tuples without matching tuples, pad with NULL</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#complete-set","title":"Complete Set","text":"<p>The operations (sigma, pi, union, rho, minus, multiply):</p> \\[ {\\sigma, \\pi, \\cup, \\rho, -, \\times} \\] <p>Are a complete set of relational algebra operations: any of the other original relational algebra operations can be expressed as a sequence of operations from this set, e.g.:</p> <ul> <li>INTERSECTION can be expressed using UNION and MINUS</li> <li>JOIN can be specified as CARTESIAN PRODUCT followed by SELECT</li> <li>NATURAL JOIN can be specified as RENAME then CARTESIAN PRODUCT followed by SELECT and PROJECT</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#division-operation","title":"DIVISION Operation","text":"<p>Convenience for queries that involve universal quantification or the all condition.</p> <p>Applied to two relations where the attributes of S (R2) are a subset of the attributes of R:</p> <p>DIVISION notation:</p> \\[ R_{1}(Z) \\div R_{2}(X) \\] <p>...that is, X \u2286 Z. Let Y be the set of attributes of R that are not attributes of S: Y = Z - X and the result of DIVISION is a relation T(Y).</p> <p>Produces a relation R(X) that includes all tuples t[X] in R1(Z) that appear in R1 in combination with every tuple from R2(Y), where Z = X\u222aY</p> <p>In order for a tuple to appear in the result, the values of the tuple must appear in R in combination with every tuple in S.</p> <p>Express as a sequence of pi, times, and minus operations:</p> \\[ T1 \\leftarrow \\pi_{y}(R) \\] \\[ T2 \\leftarrow \\pi_{y}((S \\times T1) - R) \\] \\[ T \\leftarrow T1 - T2 \\] <p>Not directly implemented with most RDBMS, nor SQL.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#query-tree-notation","title":"Query Tree Notation","text":"<p>A query tree (query evaluation tree, query execution tree) is a data structure that corresponds to a relational algebra expression.</p> <p>Input relations of the query are leaf nodes on the tree; relational algebra operations are internal nodes. Execution:</p> <ul> <li>Executing an internal node operation whenever its operands (child nodes) are available</li> <li>Replace that internal node by the resulting relation</li> <li>Terminate when root node is executed</li> <li>Produces the result relation for the query</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#generalized-projection","title":"Generalized Projection","text":"<p>Extension of projection operation: allow functions of attributes to be included in the projection list. Useful for reports where computed values must be produced in the columns of a query result, e.g. compute net salary (rename) from EMPLOYEE.Salary.</p> \\[ \\pi _{F1, F2, ..., Fn}(R) \\] <p>Where F are functions over the attributes in relation R (arithmetic operations, constant values).</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#aggregate-and-grouping","title":"AGGREGATE and Grouping","text":"<ul> <li>Mathematical aggregate functions cannot be expressed in basic relational algebra<ul> <li>E.g. get average salary of all employees, get total salary of all employees, get total number of employee tuples</li> <li>SUM, AVERAGE, MAXIMUM, MINIMUM are commonly applied to collections of numeric values</li> <li>COUNT is for tuples or values</li> </ul> </li> <li>In general, duplicates are not eliminated (unless in SQL, DISTINCT is used)</li> <li>NULL values are not considered in the aggregation</li> <li>Results in a relation (not a scalar number)<ul> <li>Relational algebra is a closed mathematical system</li> </ul> </li> </ul> <p>Grouping: tuples in a relation are grouped by the value of some of their attributes before an aggregate function is independently applied to each group.</p> <p>AGGREGATE FUNCTION operation notation (from textbook -- there's no single agreed-upon notation):</p> \\[ _{&lt;grouping\\ attributes&gt;}\\Im_{&lt;function\\ list&gt;}(R) \\] <p>... where grouping attributes is a list of attributes of the relation specified in R, and function list is a list of function-attribute pairs, where:</p> <ul> <li>Function is one of the allowed functions, e.g. SUM, AVERAGE, MAXIMUM, MINIMUM, COUNT</li> <li>Attribute is an attribute of the relation specified by R</li> <li>Resulting relation has the grouping attributes plus one attribute for each element in the function list<ul> <li>The resulting attributes may be renamed</li> <li>If not renamed, the resulting attributes will each be the function name concatenated with the attribute name: <code>&lt;function&gt;_&lt;attribute&gt;</code> (SQL)</li> </ul> </li> <li>If no grouping, functions are applied to all the tuples in the relation; result is a single tuple only</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#recursive-closure-operations","title":"Recursive Closure Operations","text":"<p>A recursive closure cannot be specified in the basic original relational algebra. It is applied to a recursive relationship between tuples of the same type (e.g. EMPLOYEE, SUPERVISOR).</p> <p>Requires a looping mechanism.</p> <p>The operation transitive closure of relations (proposed) would compute the recursive relationship as far as the recursion proceeds.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#relational-calculus","title":"Relational Calculus","text":"<p>Formal query language for the relational model: relational calculus; tuple and domain.</p> <p>Uses declarative expression to specify retrieval request:</p> <ul> <li>No description of how or in what order the evaluation should be done</li> <li>What is retrieved rather than how to retrieve it; nonprocedural language</li> <li>Unlike procedural relational algebra: sequence of operations</li> <li>Basic relational algebra and relational calculus have identical expressive power</li> <li>A relational query language is complete if we can express in it any query that can be expressed in relational calculus</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#range-expression","title":"Range expression","text":"<p>t is a tuple of relation R:</p> \\[ t\\in R \\] <p>and</p> \\[ R(t) \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#attribute-value","title":"Attribute value","text":"<p>t.A denotes the value of t on attribute A.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#constant","title":"Constant","text":"<p>c denotes a constant.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#comparison-operators_1","title":"Comparison Operators","text":"<p>Denoted by theta \u03b8:<code>{=, &lt;, \u2264, &gt;, \u2265, \u2260}</code></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#tuple-relational-calculus","title":"Tuple Relational Calculus","text":"<ul> <li>Tuple relational calculus is based on specifying a number of tuple variables</li> <li>Each tuple variable ranges over a particular database relation and may take its value from any individual tuple in the relation</li> <li>Queries have variables that range over sets of tuples</li> </ul> <p>Tuple relational calculus query:</p> \\[ \\{ t | COND(t)\\} \\] <p>...where t is a tuple variable and COND(t) is a conditional Boolean expression involving t. Different assignments of tuples to the variable t evaluate to TRUE (satisfies COND(t)) or FALSE.</p> <p>The result is the set of all tuples that satisfy the condition.</p> \\[ \\{t | EMPLOYEE(t)\\ AND\\ t.Salary&gt;50000\\} \\] <p>In a tuple relational calculus, specifiy:</p> <ul> <li>The range relation (R of t, R(t))<ul> <li>The condition EMPLOYEE(t) specifies that the range relation of t is EMPLOYEE</li> <li>If no range relation is specified, the variable t ranges over all possible tuples</li> </ul> </li> <li>A condition to select particular combinations of tuples<ul> <li>Selected combinations are ones for which the condition evaluates to TRUE</li> </ul> </li> <li>The requested attributes, a set of attributes to be retrieved for each selected combination</li> </ul> <p>Tuple relational calculus general expression:</p> \\[ \\{t_{1}.A_{j},t_{2}.A_{k},...,t_{n}.A_{m}\\ |\\ COND(t_{1},t_{2},...,t_{n},t_{n+1},t_{n+2},...,t_{n+m},)\\} \\] <p>Where all t are tuple variables, all A is an attribute of the relation on which each t ranges, and COND is a condition or formula (or Boolean condition, well-formed formula, WFF) of the tuple relational calculus.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#selection","title":"Selection","text":"\\[ \\{ r\\ |\\ r\\in RegularUser \\} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#selection-composite-expression","title":"Selection Composite Expression","text":"\\[ \\{ r\\ |\\ r\\in RegularUser\\ and\\ (r.CurrentCity=r.HomeTown\\ or\\ r.HomeTown='Atlanta')\\} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#projection","title":"Projection","text":"<p>Find Email, BirthYear, and Sex for RegularUsers with HomeTown Atlanta.</p> \\[ \\{ r.Email,\\ r.BirthYear,\\ r.Sex\\ |\\ r\\in RegularUser\\ and\\ r.HomeTown='Atlanta' \\} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#union_1","title":"Union","text":"<p>Find all cities that are a CurrentCity or a HomeTown for some Regular User.</p> \\[ \\{ s.City\\ |\\ \\exists(r\\in RegularUser)(s.City=r.CurrentCity)\\ or\\ \\exists(t\\in RegularUser)(s.City=t.HomeTown) \\} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#intersection","title":"Intersection","text":"<p>Find all cities that are a CurrentCity for some RegularUser and a HomeTown for some RegularUser.</p> \\[ \\{ s.City\\ |\\ \\exists(r\\in RegularUser)(s.City=r.CurrentCity)\\ and\\ \\exists(t\\in RegularUser)(s.City=t.HomeTown) \\} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#set-difference","title":"Set Difference","text":"<p>Find all cities that are a CurrentCity for some RegularUser, excluding those that are a HomeTown for some RegularUser.</p> \\[ \\{ s.City\\ |\\ \\exists(r\\in RegularUser)(s.City=r.CurrentCity)\\ and\\ not(\\exists(t\\in RegularUser)(s.City=t.HomeTown)) \\} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#natural-join_1","title":"Natural Join","text":"<p>Find Email, Year, Sex, Event when the BirthYear of the User is the same as the EventYear of Events</p> \\[ \\{ t.Email, t.Year, t.Sex, t.Event | \\exists(r\\in RegularUser)\\exists(s\\in Events)(r.Year=s.Year\\ and\\ t.Email=r.Email\\ and\\ t.Year=r.Year\\ and\\ t.Sex=r.Sex\\ and\\ t.Event=s.Event)\\} \\] <ul> <li>Matches on identically named variables by default</li> <li>t is the resulting tuple, so <code>t.A =</code> illustrates what we want in the result.</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#cartesian-product_1","title":"Cartesian Product","text":"<p>Combine all RegularUser tuples with all UserInterests tuples.</p> \\[ \\{ r,\\ s\\ |\\ r\\in RegularUser\\ and\\ s\\in UserInterests \\} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#divideby","title":"Divideby","text":"<p>Find Email of all users with at least all the interests of Use1.</p> \\[ \\{ r.Email | r \\in UserInterests\\ and\\ \\forall (s \\in UserInterests)((s.Email \\ne 'User1')\\ or\\ \\exists (t \\in UserInterests)(r.Email=t.Email\\ and\\ t.Interest=s.Interest))\\} \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#tuple-relational-calculus-atoms","title":"Tuple Relational Calculus Atoms","text":"<p>A formula is made up of predicate calculus atoms connected by logical operators AND, OR, NOT, and which can be of any of these forms where  t\u1d62 is a tuple variable.</p> <ul> <li>R(t\u1d62) or t\u2208R<ul> <li>Where R is a relation name</li> <li>If t is assigned to a tuple that is a member of the relation R, the atom is TRUE</li> </ul> </li> <li>t\u1d62.A op t\u2c7c.B or r.A \u03b8 s.B<ul> <li>Where A and B are attributes over which their t ranges</li> <li>And op is one of <code>{=, &lt;, \u2264, &gt;, \u2265, \u2260}</code></li> <li>If the tuple variables are assigned to tuples such that the values of the specified attributes of the tuples satisfy the condition, the atom is TRUE</li> </ul> </li> <li>t\u1d62.A op c or c op t\u2c7c.B or r.A \u03b8 c<ul> <li>Where A and B are attributes over which their t ranges</li> <li>And op is one of <code>{=, &lt;, \u2264, &gt;, \u2265, \u2260}</code></li> <li>Where c is a constant value</li> <li>If the tuple variables are assigned to tuples such that the values of the specified attributes of the tuples satisfy the condition, the atom is TRUE</li> </ul> </li> </ul> <p>The truth value of an atom is whether it evaluates to TRUE or FALSE.</p> <p>A formula is defined recursively by these rules:</p> <ol> <li>Every atom is a formula</li> <li>If F\u2081 and F\u2082 are formulas, then so are (F\u2081 AND F\u2082), (F\u2081 OR F\u2082), NOT (F\u2081) and NOT (F\u2082). Truth values are derived from F\u2081 and F\u2082 (same as rules for AND, OR, NOT).</li> <li>(F\u2081 AND F\u2082): TRUE if both are TRUE</li> <li>(F\u2081 OR F\u2082): FALSE if both are FALSE, otherwise TRUE</li> <li>NOT (F\u2081): TRUE if F\u2081 is FALSE, otherwise FALSE</li> <li>NOT (F\u2082): TRUE if F\u2082 is FALSE, otherwise FALSE</li> <li>If F is a formula, then so is (\u2203t)(F), where t is a tuple variable</li> <li>Evaluates to TRUE if F is true for at least one tuple assigned to free occurrences of t in F</li> <li>If F is a formula, then so is (\u2200t)(F), where t is a tuple variable</li> <li>Evaluates to TRUE if F is true for every tuple assined to free occurrences of t in F</li> </ol>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#predicate","title":"Predicate","text":"<p>An atom is a predicate if P\u2081 and P\u2082 are predicates. So are:</p> <ul> <li>(P\u2081)</li> <li>not(P\u2081)</li> <li>P\u2081 or P\u2082</li> <li>P\u2081 and P\u2082</li> <li>P\u2081 \u2192 P\u2082</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#quantifiers","title":"Quantifiers","text":"<p>Can appear in formulas: universal quantifier (\u2200) (all in the universe) and existential quantifier (\u2203) (if there exists).</p> <p>If P(t) is a predicate, t is a free variable in P, and R is a relation, then:</p> <ul> <li>\u2200(t\u2208R)(P(t))</li> <li>\u2203(t\u2208R)(P(t))</li> </ul> <p>both are predicates.</p> <p>A tuple variable t is bound if quantified; otherwise it is free.</p> <ul> <li>A tuple variable in a formula that is an atom is free in that formula</li> <li>A tuple variable t in a formula made up of logical connectives (AND, OR, NOT) is free or bound depending on whether it is free or bound in the component formulas, if it occurs in any component formula<ul> <li>i.e. a tuple variable t that appears in F\u2081 or F\u2082 in the formula (F\u2081 AND F\u2082) is free or bound in F\u2081 or F\u2082 respectively</li> </ul> </li> <li>All free occurrences of t in F are bound in a formula of the form F\u2032= (\u2203t)(F) or F\u2032 = (\u2200t)(F)</li> </ul> <p>Free tuple variables in a tuple relational calculus expression should appear to the left of the bar <code>|</code>.</p> <p>Universal and existential quantifiers can be transformed into the other to get an equivalent expression; some special cases, shown with \u2261 (equivalent to):</p> <ul> <li>(\u2200x) (P(x)) \u2261 NOT (\u2203x) (NOT (P(x)))</li> <li>(\u2203x) (P(x)) \u2261 NOT (\u2200x) (NOT (P(x)))</li> <li>(\u2200x) (P(x) AND Q(x)) \u2261 NOT (\u2203x) (NOT (P(x)) OR NOT (Q(x)))</li> <li>(\u2200x) (P(x) OR Q(x)) \u2261 NOT (\u2203x) (NOT (P(x)) AND NOT (Q(x)))</li> <li>(\u2203x) (P(x)) OR Q(x)) \u2261 NOT (\u2200x) (NOT (P(x)) AND NOT (Q(x)))</li> <li>(\u2203x) (P(x) AND Q(x)) \u2261 NOT (\u2200x) (NOT (P(x)) OR NOT (Q(x)))</li> </ul> <p>Cases where \u2192 symbol means implies:</p> <ul> <li>(\u2200x)(P(x)) \u2192 (\u2203x)(P(x))</li> <li>NOT (\u2203x)(P(x)) \u2192 NOT (\u2200x)(P(x))</li> </ul> <p>Definition of a universal quantifier says that in order to be true, the inner formulas must be TRUE for all tuples in the universe</p> <ul> <li>For F\u2032 = (\u2200x)(F) to be TRUE, we must have the formula F be TRUE for all tuples in the universe that can be assigned to x<ul> <li>We must exclude from the universal quantification all tuples we don't want by making the condition TRUE for those tuples</li> <li>A universally quantified tuple variable must evaluate to true for every possible tuple assigned to it</li> <li>E.g. use NOT(PROJECT(x)), which evaluates to TRUE all tuples x that are not in the PROJECT relation</li> </ul> </li> <li>This eliminates tuples from consideration in the truth value of F</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#safe-expression","title":"Safe Expression","text":"<p>The domain of a tuple relational calculus expression is the set of all values that either appear as constant values in the expression or exist in any tuples in the relations referenced in the expression.</p> <p>A safe expression in relational calculus is guaranteed to yield a finite number of tuples as a result. All values in its result are from the domain of the expression.</p> <p>An unsafe expression has no finite guarantee, e.g. { t | NOT (EMPLOYEE(t))} yields all tuples that are not EMPLOYEE tuples, i.e. is infinitely numerous. It includes values from outside the EMPLOYEE relation (outside the domain of expression).</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#domain-relational-calculus","title":"Domain Relational Calculus","text":"<p>Or domain calculus, proposed after Query-By-Example (QBE).</p> <p>Domain variables range over single values from domains of attributes. To form a relation of degree n for a query result, we need n domain variables, one for each attribute.</p> <p>Domain calculus expression notation:</p> \\[ \\{x_{1},x_{2},...,x_{n}\\ |\\ COND(x_{1},x_{2},...,x_{n+1},x_{n+2},...,x_{n+m},)\\} \\] <p>... where x are domain variables that range over domains of attributes, and COND is a condition or formula of the domain relational calculus.</p> <p>Formulas are made up of atoms of the form:</p> <ul> <li>R(x\u2081, x\u2082, ... , x\u2c7c)<ul> <li>Where R is the name of a relation of degree j and each x\u1d62, 1 \u2264 i \u2264 j, is a domain variable</li> <li>A list of values  must be a tuple in the relation named R, where x\u1d62 is the value of the ith attribute value of the tuple <li>List of variables can be written without commas: R(x\u2081x\u2082x\u2083)</li> <li>If the domain variables are assigned values corresponding to the tuple of the relation R, then the atom is TRUE</li> <li>x\u1d62 op x\u2c7c<ul> <li>Where op is one of <code>{=, &lt;, \u2264, &gt;, \u2265, \u2260}</code></li> <li>And x are domain variables</li> <li>If the domain values are assigned variables that satisfy the condition, the atom is TRUE</li> </ul> </li> <li>x\u1d62 op c or c op x\u2c7c<ul> <li>Where op is one of <code>{=, &lt;, \u2264, &gt;, \u2265, \u2260}</code></li> <li>And x are domain variables</li> <li>And c is a constant value</li> <li>If the domain values are assigned variables that satisfy the condition, the atom is TRUE</li> </ul> </li>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#abstraction-knowledge-representation","title":"Abstraction, Knowledge Representation","text":"<ul> <li>KR goal: develop concepts for accurately modeling a domain of knowledge through creation of an ontology</li> <li>KR includes reasoning mechanisms to deduce additional facts from facts stored in DB; answer queries with inferences</li> <li>Ontology enables storing and manipulating knowledge to draw inferences, make decisions, or ask questions</li> </ul> <p>Types of abstraction include:</p> <ul> <li>Classification and instantiation (define entity types)</li> <li>Identification</li> <li>Generalization and specification (supported by super/subtype relationships)</li> <li>Aggregation (an instance composed of instances of other parts) and association<ul> <li>EER can't model this</li> </ul> </li> </ul> <p>A list of properties as a result of a query needs a type (using a closed query language) in order to continue operating on it. The lack of a closed query language in EER is (in Leo's opinion) the reason commercial DBMS are not based on EER.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#classification","title":"Classification","text":"<ul> <li>Systematically assigning similar objects or entities to classes or entity types</li> <li>Allows us to reason about the classes rather than its individual members; simplifies discovering their properties</li> <li>One class may be an instance of another class (meta-class)<ul> <li>EER diagrams cannot show this (no multi-level class notation, only superclass/subclass)</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#instantiation","title":"Instantiation","text":"<ul> <li>Inverse of classification; generate and examine a specific object in a class</li> <li>Related to class by is-an-instance-of or is-a-member-of relationship</li> <li>Instances not displayed on EER diagrams</li> <li>Some objects differ from others in the same class: these are exception objects</li> <li>Class properties apply to the class as a whole and not its individual objects</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#identification","title":"Identification","text":"<ul> <li>Classes and objects are made uniquely identifiable with an identifier, e.g. name, uuid</li> <li>Multiple manifestations of a real-world object in the DB (duplicates) must be caught</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#specialization-generalization","title":"Specialization, Generalization","text":"<ul> <li>Specialization (dividing a class into subclasses: conceptual refinement) is inverse of generalization (lumping several classes into a higher level abstract class: conceptual synthesis)</li> <li>Uses is-a-subclass-of or is-a relationship</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#aggregation","title":"Aggregation","text":"<ul> <li>Building composite objects from component objects, e.g.:<ul> <li>Aggregating attribute values of an object to form the whole object</li> <li>Representing an aggregation relationship as an ordinary relationship</li> <li>Combining related objects (of a particular relationship instance) into a higher-level aggregate object (can't do this in EER)</li> </ul> </li> <li>Relationship between primitive object and aggregate object: is-a-part-of or is-a-component of</li> <li>If deleted, participating objects cease to exist</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#association","title":"Association","text":"<ul> <li>Associating objects from several independent classes</li> <li>Represented by relationship types (EER) and associations (UML)</li> <li>Uses is-associated-with relationship</li> <li>If deleted, participating objects continue to exist</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#ontologies","title":"Ontologies","text":"<p>A specification of a conceptualization (Gruber, 1995).</p> <ul> <li>Conceptualization: set of concepts and relationships used to represent a part of reality or knowledge</li> <li>Specification: language and volcabulary terms used to specify the conceptualization</li> <li>Can use different languages for the same specification: two ontologies</li> <li>No one method: thesaurus, taxonomy, database schema, logical theory</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#eer-relational-mapping","title":"EER Relational Mapping","text":"<ul> <li>The identifying property of an entity becomes its primary key in the table</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#composite-properties","title":"Composite Properties","text":"<p>Composite properties are flattened:</p> <ul> <li>Relations are tuples constructed from domains with atomic values<ul> <li>Atomic values are indivisible</li> </ul> </li> <li>Relational model is inherently flat (flat file)</li> <li>Composite properties are flattened to their components in the table, e.g:</li> </ul> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#multi-value-properties","title":"Multi-value Properties","text":"<p>There are no multi-valued attributes in a relational model (flat relational model):</p> <ul> <li>e.g. <code>Entity</code> with primary key <code>A</code> and multi-value property <code>E</code></li> <li>Multi-value properties become new relations, named by the entity type hyphenated with the property name: becomes the separate relation <code>Entity-E</code></li> <li>This <code>Entity-E</code> table has a foreign key <code>A</code> to the <code>Entity</code> table<ul> <li>As long as the combination of <code>A</code> and <code>E</code> is unique, we can now have different values for <code>E</code></li> </ul> </li> </ul> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#one-to-one-relationship","title":"One-to-one Relationship","text":"<p>One-to-one relationships are mapped with foreign keys.</p> <p></p> <p>If Role is a total function (doubled orange line above) use the second method of putting the foreign key in the Role relation. This avoids having NULL fields in the User table in the first option since not all Users will have a Role, but all Roles will have a User.</p> <p>For relation, with attributes, that has a total function to some entity, map the relation's attribute to that entity's table.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#one-to-many-relationship","title":"One-to-Many Relationship","text":"<p>One-to-many relationships are also mapped with foreign keys. For example, many instances of Role can point to a single instance of User:</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#many-to-many-relationship","title":"Many-to-Many Relationship","text":"<p>Many-to-many relationships are mapped with a new table for the relation. The relation table uniquely identifies each combination with its composite key.</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#weak-entities","title":"Weak Entities","text":"<p>Mapping weak entity relationships is done by inserting a foreign key to the strong entity in the weak entity's table. The composite key uniquely identifies the combination.</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#mandatory-disjoint-relationship","title":"Mandatory Disjoint Relationship","text":"<p>Mandatory disjoint relationships map to separate tables for each subclass. No table is created for the superclass entity, since each instance of the superclass is contained in one of the subclasses.</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#mandatory-overlapping-relationship","title":"Mandatory Overlapping Relationship","text":"<p>One approach to mapping a mandatory overlapping relationship is to create one relation with all attributes from super and subclasses, plus an attribute for <code>type</code> to denote the subclass. This results in NULL fields if the instance is only one of the subclasses, i.e. where immediate attributes for the other subclass(es) have no value, and can have consistency problems.</p> <p>A preferable approach is to create a relation for each entity: each superclass and subclass. The subclass relations will contain foreign keys to the superclass relation. Foreign key values may appear multiple times among the subclasses.</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#non-mandatory-overlapping-relationship","title":"Non-Mandatory Overlapping Relationship","text":"<p>Similar to mandatory overlapping, a non-mandatory overlapping relationship can also be mapped with a single relation. This option has the same issues with NULL fields and consistency.</p> <p>Preferably, separate relations are again created for each entity (superclass and subclass).</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#non-mandatory-disjoint-relationship","title":"Non-Mandatory Disjoint Relationship","text":"<p>Though it looks similar in the EER diagram, a non-mandatory disjoint relationship has no option to be mapped as a single relation.</p> <p>Separate relations are again created for each entity (superclass and subclass). A User may be in either Admin or Member classes, but not both.</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#union-types","title":"Union Types","text":"<p>Recall that with Union types such as in this example, User is a subset of the union of Admin and Member, and the intersection of Admin and Member must be empty. I.e., User must be either an Admin or a Member, and there are no Users that are not one of these subtypes.</p> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#indexing","title":"Indexing","text":"<p>When deciding to index, consider:</p> <ul> <li>Size of the table</li> <li>Whether the table is in the access path of multiple queries and updates</li> <li>Relative frequencies of reads or writes</li> <li>Whether it is already indexed by the DBMS (e.g. MySQL, PostgreSQL on primary key)</li> </ul> <p>Additionally:</p> <ul> <li>Multiple frequencies add up, consider all the different ways a table is accessed</li> <li>Writes suffer when indices must be maintained, but reads benefit</li> <li>Some DBMS have benchmarking tools, or can show query graphs to help determine if indexing is appropriate<ul> <li>Make small changes and compare measurements</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#size-of-the-table","title":"Size of the Table","text":"<p>The size of a record is the sum of its bytes, e.g.</p> <pre><code>RegularUser(\n  Email varchar(254),\n  City varchar(50)\n);\n</code></pre> <p>A RegularUser record is 304 bytes.</p> <p>What is the DBMS block size?</p> <ul> <li>Highly formatted data typically uses a lower block size; with large objects in tables, a higher block size is used</li> <li>All blocks are typically only 66%-80% filled to avoid overflow with inserts</li> </ul> <p>Find records per block by taking 80% of the block size:</p> <ul> <li>E.g. 4k block: 3.2k</li> <li>Divide by record size: 3,200 / 304 = ~10.5</li> <li>About 10 records per block</li> </ul> <p>Consider how many records (rows in the DB):</p> <ul> <li>E.g. 4 million records / 10 blocks is 400,000 blocks to store the RegularUser table</li> <li>Table size in MB is the number of blocks by the block size: e.g. 1.6 MB</li> </ul> <p>With many tables, can't always have them in memory (stored on disk) and scans take time:</p> <ul> <li>If we estimate (make an assumption) that a page fault takes 0.01 s</li> <li>To scan 400,000 blocks (that are not indexed) takes 66 mins</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#multiple-access-paths","title":"Multiple Access Paths","text":"<ul> <li>How many queries and operations access the table?</li> <li>Determine relative frequency of access from all queries to find weight of access on the table</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#reads-and-writes","title":"Reads and Writes","text":"<ul> <li>Consider operations: SELECT (read), UPDATE (write), INSERT (write)</li> <li>Generally, if table is indexed: reads are faster, writes are slower<ul> <li>Multiple indices on a table slows down writes (maintaining all the indices)</li> <li>Writes are preceded by reads</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#functional-dependency","title":"Functional Dependency","text":"<p>A functional dependency (FD) is:</p> <ul> <li>Denoted X \u2192 Y (read \"X determines Y\") and X,Z \u2192 Y (read \"a combination of X and Z determines a unique Y\")</li> <li>Specifies a contraint on the possible tuples that can form a relation state r of R</li> <li>A property of the semantics (meaning) of attributes</li> <li>A property of the relation schema R<ul> <li>Cannot be inferred from a relation extension r but is defined explicitly by knowledge of the semantics of R</li> </ul> </li> <li>Describe a relation schema R by constraints on its attributes that must hold all the time</li> </ul> <p>Use keys to enforce functional dependencies, since values of keys are unique.</p> <p>Let X and Y be sets of attributes in R; Y is functionally dependent on X in R if for each x \u2208 R.X there is precisely one y \u2208 R.Y</p> <ul> <li>I.e. City is dependent on Email if, for each Email value, there is only one City value</li> <li>I.e. City and Email are unique together</li> <li>Email is the unique key since all attributes of the relation are FD on it</li> </ul> <p>Let X and Y be sets of attributes in R; Y is fully functionally dependent on X in R if Y is functionally dependent on X and Y is not functionally dependent on any proper subset of X.</p> <ul> <li>E.g. in RegularUser table with columns Email, Age, and Interest, if Email, Age \u2192 Interest you need both Email and Age to determine Interest<ul> <li>Any two tuples that have the same Email, Age must also have the same Interest</li> </ul> </li> <li>Email and Interest make the unique key</li> </ul> <p>Values of the Y component (right side) of a tuple in r depend on (are determined by) the values of the X component (left side); conversely, values of the X component functionally (uniquely) determine values of the Y component.</p> <p>For any two tuples t\u2081 and t\u2082 that have t\u2081[X] = t\u2082[X], they must also have t\u2081[Y] = t\u2082[Y]. Y is functionally dependent on X (or, X functionally determines Y only if whenever two tuples of r(R) agree on the X value, they also agree on the Y value).</p> <p>If X is a candidate key of R in a relation instance r(R), this implies X \u2192 Y for any subset of attributes Y of R since no two values can have the same X. Then, X \u2192 R.</p> <p>If X \u2192 Y in R, it does not indicate whether Y \u2192 X in R.</p> <p>Legal relation states (legal extensions) of R are relation states or relation extensions (r of R or r(R)) that satisfy functional dependency constraints.</p> Teacher Course Text Smith Data Structures Bartram Smith Data Management Martin Hall Compilers Hoffman Brown Data Structures Horowitz <p>Textbook example: this relation disproves any FD of:</p> <ul> <li><code>Teacher \u2192 Course</code> (Smith, twice, with different courses)</li> <li><code>Course \u2192 Text</code> (Data Structures with different Texts)</li> </ul> <p>There is a possible FD:</p> <ul> <li><code>Text \u2192 Course</code> (each text only once)</li> <li><code>Text \u2192 Teacher</code> (each text only once)</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#evaluating-relation-schema","title":"Evaluating Relation Schema","text":"<p>Relation schemas can be evaluated at the</p> <ul> <li>Logical or conceptual level: how users interpret the schema and meaning of attributes<ul> <li>Applies to base relations and views (virtual relations)</li> </ul> </li> <li>Implementation or physical storage level<ul> <li>Applies to base relations</li> </ul> </li> </ul> <p>Design methodologies include:</p> <ul> <li>Bottom-up design methodology (design by synthesis)<ul> <li>Takes the basic relationships among individual attributes as a starting point to construct relation schemas</li> <li>Not popular: need to collect a large number of binary relationships, nearly impossible in practice</li> </ul> </li> <li>Top-down design methodology (subsequently, relational design by analysis)<ul> <li>Group attributes based on relations that exist naturally</li> <li>Analyze and decompose until desired properties are met</li> </ul> </li> </ul> <p>Relational database design produces a set of relations with the goals of information preservation and minimum redundancy. Informally:</p> <ul> <li>Ensure the semantics (meaning of a relation resulting from interpretation of attribute values in a tuple) of attributes is clear in the schema<ul> <li>Ensure meaning can easily be explained</li> </ul> </li> <li>Reduce redundant information in tuples</li> <li>Reduce NULL values in tuples<ul> <li>Avoid placing attributes in a base relation with values that may frequently be NULL</li> </ul> </li> <li>Disallow generation of spurious tuples (spurious information that is not valid, i.e. more instances of a value that do not correspond to real-world multiples)<ul> <li>Design schemas that can be joined with appropriately-related (PK, FK) attributes</li> <li>Avoid relations that contain matching attributes that are not (FK, PK) combinations</li> </ul> </li> </ul> <p>Recall that NULL has multiple interpretations:</p> <ul> <li>Attribute does not apply to this tuple</li> <li>Attribute value is unknown</li> <li>Value is known but absent (not recorded yet)</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#relational-decomposition","title":"Relational Decomposition","text":"<p>Get rid of unwanted dependencies in order to achieve higher normal forms (1NF is lowest, BCNF is highest).</p> <p>A single universal relation schema includes all attributes of the DB. An implicit universal relation assumption states that every attribute name is unique. Using FDs, design algorithms decompose the universal relation schema R into a set of relation schemas: D = {R\u2081, R\u2082, ..., R\u2098} that become the relational database schema. D is decomposition of R.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#normalization","title":"Normalization","text":"<p>Normal form of a relation refers to the highest normal form condition that it meets and indicates the degree to which it has been normalized.</p> <p>A process of analyzing the given relation schemas based on their FDs and PKs to achieve the desirable properties of minimal redundancy and minimal insertion, deletion, and update anomalies.</p> <p>Relation schemas are decomposed into smaller schemas (with a subset of the original attributes) until they meet the normal form test.</p> <p>Generally, design relation schemas so they have neither partial nor transitive dependencies.</p> <p>How to decompose a relation without losing information and functional dependencies?</p> <ol> <li>No redundancy of facts</li> <li>No cluttering of facts</li> <li>Must preserve information</li> <li>Must preserve functional dependencies</li> </ol> <p>Or as three goals:</p> <p>Nonadditive join or lossless join property: no spurious tuples -- must be achieved at any cost. Refers to loss of information, not tuples.</p> <ul> <li>Claim: the decomposition D\u2082 = {R\u2081, R\u2082, ..., R\u1d62\u208b\u2081, Q\u2081, Q\u2082, ..., Q\u2096, R\u1d62\u208a\u2081, ..., R\u2098} of R has the nonadditive join property with respect to F if:<ul> <li>D = {R\u2081, R\u2082, ..., R\u2098} of R has the nonadditive join property in respect to a set of FD F on R, and if</li> <li>D\u1d62 = {Q\u2081, Q\u2082, ..., Q\u2096} of R\u1d62 has the nonadditive join property in respect to the projection of F on R\u1d62</li> </ul> </li> <li>A decomposition D = {R\u2081, R\u2082, ..., R\u2098} has the lossless (nonadditive) join property with respect to the set of dependencies F on R if, for every relation state r of R that satisfies F, and where <code>*</code> is the NATURAL JOIN of all the relations in D, the following holds:</li> </ul> \\[ *(\\pi_{R_{1}}(r), ..., \\pi_{R_{m}}(r)) = r \\] <p>Dependency preservation property: each FD is represented in some individual relation after decomposition -- sometimes sacrificed.</p> <ul> <li>Claim: it is always possible to find a dependency-preserving decomposition D with respect to F such that each relation R\u1d62 in D is in 3NF</li> <li>A decomposition is dependency preserving with respect to F if the union of the projections of F on each R\u1d62 in D is equivalent to F</li> </ul> \\[ (( \\pi_{R_{1}}(F)) \\cup K \\cup (\\pi_{R_{m}}(F)))^+ =F^+ \\] <ul> <li>Non-first-normal-form (NF\u00b2): a data structure that is not a relation, e.g. multi-value (non-atomic values)</li> </ul> <p>Attribute preservation condition: ensure that each attribute in R will appear in at least one relation schema R\u1d62 so that no attributes are lost.</p> \\[ \\bigcup _{i=1}^{m} R_{i} = R \\] <p>A multivalue attribute can be normalized by creating a row for each one, with the associated information repeated across the new multiple rows; this has problems:</p> <ul> <li>Redundancy: RegularUser table may now have multiple entries for the same user that all need to be kept in sync</li> <li>Insertion anomaly: inserting a new value for which there are no values in the other columns would give a row with mostly NULLs</li> <li>Deletion anomaly: deleting a row that contains the only instance of a particular column value means that column value is lost inadvertently</li> <li>Update anomaly (modification anomaly): if there are multiple rows for a particular user, they all need to be updated and kept in sync (not just the first one)</li> </ul> <p>A table (e.g. RegularUser) can be decomposed into multiple tables; this has problems:</p> <ul> <li>Information loss: Recombining rows from these tables may result in duplicated information<ul> <li>Application forms now have to consider multiple tables</li> </ul> </li> <li>Dependency loss: new tables may not have tuples that coexist as expected</li> </ul> <p>Perfect decomposition avoids:</p> <ul> <li>Redundancy: values, e.g. many rows for one user, aren't repeated</li> <li>Insertion, deletion, and update anomalies<ul> <li>Facts represented by the functional dependencies are separated into their own tables</li> </ul> </li> <li>Information and dependency loss<ul> <li>Joining doesn't create incorrect totals, etc.</li> <li>Separate relation for each functional dependency</li> </ul> </li> </ul> <p>Relations may be left at lower normal forms for performance reasons.</p> <p>Denormalization is the process of storing the join of higher normal form relations as a base relation, which is in a lower normal form.</p> <p>Review: a superkey of a relation schema is a set of attributes with the property that no two tuples in any legal relation state will have the same value. A key is a superkey with the additional property that the removal of any attributes will cause it not to be a superkey anymore -- a key has to be minimal.</p> <p>A relation schema may have more than one key and each of these is a candidate key. One of these is arbitrarily designated to be the PK and the rest are called secondary keys. If no candidate key is known for the relation, the entire relation can be considered the default superkey.</p> <p>A prime attribute of R is a member of some candidate key of R. If it is not a member of any candidate key, an attribute is nonprime.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#normal-forms","title":"Normal Forms","text":"<p>Four:</p> <ul> <li>The whole set of data structures is non-first normal form (NF\u00b2)</li> <li>Subset of NF\u00b2 is first normal form (1NF) relations</li> <li>Subset of 1NF is second normal form (2NF) relations</li> <li>Subset of 2NF is third normal form (3NF)</li> <li>Subset of 3NF is Boyce-Codd Normal Form (BCNF); this is the main goal</li> </ul> <p>By definition, a 3NF already satisfies 2NF.</p> <p>A prime attribute is one that is part of any candidate key.</p> <p>Full functional dependency: (X \u2192 Y) if removal of any attribute A from X means that the dependency does not hold anymore.</p> <p>Partial dependency: if some attribute A can be removed from X and the dependency still holds.</p> <p>Transitive dependency: a functional dependency (X \u2192 Y) in a relation schema R if there exists a set of attributes Z in R that is neither a candidate key nor a subset of any key of R, and both X \u2192 Z and Z \u2192 Y hold.</p> <p>A binary decomposition is a decomposition of a relation into two relations. The NJB property test is limited to binary decompositions.</p> <p>Nonadditive Join Test for Binary Decomposition (NJB): a decomposition D = {R\u2081, R\u2082} of R has the lossless join property in respect to a set of functional dependencies F on R only if either the FD:</p> \\[ (( R_{1} \\cap R_{2}) \\rightarrow ( R_{1} - R_{2})) \\] <p>... is in F\u207a\u00b9\u2075, or</p> \\[ (( R_{1} \\cap R_{2}) \\rightarrow ( R_{2} - R_{1})) \\] <p>... is in F\u207a.</p> <p>For lossless joins when decomposing relations, the join field must be a key in at least one of the relations.</p> <p>We preserve functional dependencies if the meaning implied by the remaining functional dependencies is the same (may be implied by transitivity).</p> <p>When a relation has overlapping keys, it may be the case that it can only be decomposed to 3NF (not BCNF) while being lossless and preserving dependencies -- though this doesn't happen in practice.</p> <p>Three main techniques to achieve 1NF:</p> <ol> <li>Remove the violating attribute to a separate relation with the primary key of the original relation. The new relation's PK is the combination of the old PK and the moved attribute.</li> <li>Expand the key to create a separate tuple in the original relation. (Introduces redundancy -- rarely used.)</li> <li>If the maximum number of values is known for the offending attribute, replace it with a numbered atomic attribute for each. (Introduces NULL values if most of the other tuples would not have values for these new attributes; introduces spurious semantics as well, as it imposes a new ordering. Best avoided.)</li> </ol> <p></p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#first-normal-form","title":"First Normal Form","text":"<ul> <li>R is in 1NF if all domain values are atomic (indivisible)</li> <li>Relations within relations, or relations as attribute values within tuples are disallowed</li> <li>Multivalued attributes that are themselves composite are disallowed (nested relations -- tuple has a relation within it)</li> <li>Unnest relations into a set of 1NF relations by removing the nested attributes into a new relation and propagating the PK into it</li> <li>Test: relations should have no multivalued attributes or nested relations</li> <li>Fix: form new relations for each multivalue attribute or nested relation</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#second-normal-form","title":"Second Normal Form","text":"<p>A relation schema R is in 2NF if every nonprime attribute (not part of a candidate key) A in R is...</p> <ul> <li>Fully functionally dependent on the PK of R.</li> <li> <p>Not partially dependent on any key of R.</p> </li> <li> <p>R is in 2NF if R is in 1NF and every nonprime attribute is fully dependent on the key</p> </li> <li>Test: fails when the PK contains multiple attributes and there are nonkey attributes that depend on only part of the PK (no nonkey attributes should be functionally dependent on a part of the PK)<ul> <li>Each nonkey attribute of the relation must depend on the whole key</li> </ul> </li> <li>Fix: decompose into new relations; each PK with its attribute and any FD dependents</li> <li>Test for functional dependencies whose left side attributes are part of the primary key<ul> <li>If this is just a single attribute, no test needed</li> </ul> </li> <li>Second-normalize a relation into a number of 2NF relations with nonprime attributes associated with only the part of the PK on which they are functionally dependent</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#third-normal-form","title":"Third Normal Form","text":"<p>Codd: a relation schema R is in 3NF if...</p> <ul> <li>It satisfies 2NF and no nonprime attribute of R is transitively dependent on the PK.</li> <li>If whenever a nontrivial FD X \u2192 A holds in R,<ul> <li>Either X is a superkey of R</li> <li>Or A is a prime attribute of R</li> </ul> </li> <li>{A-X} is a prime attribute of R.</li> </ul> <p>Alternatively, R is in 3NF if R is 2NF and every nonprime attribute of R is...</p> <ul> <li>Non-transitively dependent on every key of R</li> <li> <p>Fully functionally dependent on every key of R (no nonprime attribute of R is transitively dependent on the PK)</p> </li> <li> <p>Test: relation should not have a nonkey attribute functionally determined by another (single or set of) nonkey attribute(s) -- no transitive dependency of a nonkey attribute on the PK</p> </li> <li>Fix: decompose into relations that include the nonkey attribute that FD other nonkey attributes</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#boyce-codd-normal-form","title":"Boyce-Codd Normal Form","text":"<p>A relation schema R is in BCNF if whenever a nontrivial FD X \u2192 A holds in R, then X is a superkey of R.</p> <ul> <li>R is in BCNF if every determinant is a candidate key (or, there is no determinant other than a key)<ul> <li>Determinant: set of attributes on which some other attribute is fully functionally dependent</li> </ul> </li> <li>Every relation in BCNF is also in 3NF, but reverse isn't necessarily true</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#multivalued-dependency","title":"Multivalued Dependency","text":"<p>A multivalued dependency X \u2192 Y (where X and Y are both subsets of R) specified on relation schema R, specifies the following constraints on relation state r of R: if tuples t\u2081 and t\u2082 exist in r, then t\u2083 and t\u2084 should exist also with the following properties:</p> <ul> <li>t\u2083[X] = t\u2084[X] = t\u2081[X] = t\u2082[X]</li> <li>t\u2083[X] = t\u2081[X] and t\u2084[X] = t\u2082[X]</li> <li>t\u2083[X] = t\u2082[X] and t\u2084[X] = t\u2081[X]</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#fourth-normal-form","title":"Fourth Normal Form","text":"<p>A relation schema R is in 4NF with respect to a set of dependencies F (including FD and multivalued dependencies) if, for every nontrivial multivalued dependency X \u21a0 Y in F\u207a,\u00b2\u00b9 X is a superkey for R.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#join-dependencies","title":"Join Dependencies","text":"<p>A join dependency (JD), denoted JD(R\u2081, R\u2082, ..., R\u2099), specified on relation schema R, specifies a constraint on the states r of R. The constraint states that every legal state r of R should have a nonadditive join decomposition into R\u2081, R\u2082, ..., R\u2099. For every such r we have</p> \\[ * (\\pi_{R1}(r),\\pi_{R2}(r), ..., \\pi_{Rn}(r)) = r \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#fifth-normal-form","title":"Fifth Normal Form","text":"<p>A relation schema R is in 5NF or project-join normal form (PJNF) with respect to a set of functional, multivalued, and join dependencies, if for every nontrivial join dependency JD(R\u2081, R\u2082, ..., R\u2099) in F\u207a (implied by F), \u00b2\u00b2 every R\u1d62 is a superkey of R.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#inference-rules","title":"Inference Rules","text":"<p>Inference rules can be used to infer new dependencies from a given set. Repeated use of inference rules on a superkey generates all attributes of the relation.</p> <p>A FD X \u2192 Y is inferred from or implied by a set of dependencies F specified on R if X \u2192 Y holds in efery legal relation state of R. Whenever r satisfies all the dependencies in F, X \u2192 Y also holds in r.</p> <p>Inferred FD need not be explicitly stated in addition to given FDs; a closure (denoted F\u207a) is the set of all dependencies that include F as well as all possible dependencies that can be inferred from the given set F.</p> <p>The closure of X under F, X\u207a, is the set of attributes that can be functionally determined by X (based on F).</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#armstrongs-rules","title":"Armstrong's Rules","text":"<p>Computing with functional dependencies.</p> <ul> <li>IR1 or reflexive rule: if Y is a subset of X, then X determines Y<ul> <li>If X \u2287 Y, then X \u2192 Y</li> <li>Is Y a subset of X?</li> <li>Generates dependencies that are always true (trivial dependencies):<ul> <li>X \u2192 Y is trivial if X \u2287 Y</li> <li>Any set of attributes functionally determines itself</li> </ul> </li> <li>Email, Interest \u2192 Interest</li> </ul> </li> <li>IR2 or augmentation rule: if X determines Y, then WX determines WY<ul> <li>{X \u2192 Y |=XZ \u2192 YZ}</li> <li>Also: X \u2192 Y |= XZ \u2192 Y<ul> <li>Augmenting the left side attributes of a FD (or adding the same set of attributes to both sides) produces another valid FD</li> </ul> </li> <li>If Email \u2192 BirthYear, then Email, Interest \u2192 BirthYear, Interest</li> </ul> </li> <li>IR3 or transitive rule: if X determines Y and Y determines Z, then X determines Z<ul> <li>{X \u2192 Y, Y \u2192 Z} |= X \u2192 Z</li> <li>Email \u2192 BirthYear and BirthYear \u2192 Salary, then Email \u2192 Salary</li> </ul> </li> </ul> <p>Three other inference rules follow:</p> <ul> <li>IR4 or decomposition (projective) rule: {X \u2192 YZ} |=X \u2192 Y<ul> <li>Can remove attributes from the right side of a dependency to decompose the FD into a set of dependencies</li> </ul> </li> <li>IR5 or union (additive) rule: {X \u2192 Y, X \u2192 Z} |=X \u2192 YZ<ul> <li>Can combine a set of dependencies into a single FD</li> </ul> </li> <li>IR6 or pseudotransitive rule: {X \u2192 Y, WY \u2192 Z} |=WX \u2192 Z<ul> <li>Can replace a set of attributes Y on the left side of a dependency with another set X that functionally determines Y</li> </ul> </li> </ul> <p>IR1-3 are sound and complete and can be proven by direct proof or by contradiction (assume it is not true then prove this is not possible).</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#equivalence","title":"Equivalence","text":"<p>A set of FDs F is said to cover another set of FDs E if every FD in E is also in F\u207a. If every dependency in E can be inferred from F, we say that E is covered by F.</p> <p>Two sets of FDs E and F are equivalent if E\u207a = F\u207a. Every FD in E can be inferred from F, and every FD in F can be inferred from E. Both conditions E covers F and F covers E hold.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#minimal-sets","title":"Minimal Sets","text":"<p>We shrink the set F to its minimal form such that the set is still equivalent to the original set F.</p> <p>A minimal cover of a set of functional dependencies E is a minimal set of dependencies equivanlent to E. There is always at least one minimal cover F for any set of dependencies E.</p> <p>An extraneous attribute is one that can be removed without changing the closure of the set of dependencies. Given a set of FDs F and a FD X \u2192 A in F, an attribute Y is extraneous in X if Y \u2282 X, and F logically implies:</p> \\[ (F - (X \\to A) \\cup \\{ (X - Y) \\to A\\}) \\]"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#disk-storage","title":"Disk Storage","text":"<p>Main categories of a storage hierarchy:</p> <ul> <li>Primary storage is operated on by the CPU, e.g. main memory, cache memory<ul> <li>Fast access to data, limited storage capacity</li> <li>Expensive relative to other tiers</li> <li>Contents are lost in power failure or system crash (volatile)</li> </ul> </li> <li>Secondary storage, or \"disk,\" either magnetic disk hard drives or flash memory solid-state drives (SSD)<ul> <li>Cannot be processed directly by CPU, must first be copied onto primary storage</li> </ul> </li> <li>Tertiary storage includes optical disks (or it used to...) e.g. CDs, DVDs; any removable storage medium that can serve as offline storage<ul> <li>Typically larger capacity, slower, and less expensive than primary storage devices</li> <li>Cannot be processed directly by CPU, must first be copied onto primary storage</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#memory","title":"Memory","text":"<p>Higher the speed, higher the cost of capacity.</p> <p>Storage capacity is measured in units of bytes:</p> <ul> <li>KB: kilobytes (Kbyte) or 1,000 bytes</li> <li>MB: megabytes, or 1 million bytes</li> <li>GB: gigabytes, or 1 billion bytes</li> <li>TB: terabytes, or 1,000 GB (1,000\u2074 bytes)</li> <li>PB: petabytes, or 1,000 TB (1,000\u2075 bytes)</li> <li>EB: exabyte (1,000\u2076 bytes)</li> <li>ZB: zettabyte (1,000\u2077 bytes)</li> <li>YB: yottabyte (1,000\u2078 bytes)</li> </ul> <p>Primary storage:</p> <ul> <li>Cache memory, or static RAM (the most expensive primary storage)<ul> <li>Used by CPU to speed up execution of program instructions (prefetching, pipelining)</li> </ul> </li> <li>Main memory, or DRAM<ul> <li>Main work area for CPU to keep program instructions and data</li> <li>Lower cost, higher volatility, lower speed compared with static RAM</li> <li>Main memory databases are useful in real-time applications, when fast response times are needed</li> </ul> </li> </ul> <p>Flash memory is nonvolatile, high density, and high performance:</p> <ul> <li>Uses electrically erasable programmable read-only memory (EERPROM)</li> <li>Fast access speed</li> <li>Entire blocks must be erased and written over simultaneously</li> <li>NAND and NOR types</li> </ul> <p>Secondary and tertiary storage:</p> <ul> <li>Magnetic disks</li> <li>Mass storage, e.g. optical drives (CD, DVD), magnetic tapes</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#storage","title":"Storage","text":"<p>Persistent data must persist over long periods of time. Transient data must persist only for a limited time during program execution.</p> <p>Volatile storage will lose data when power is lost or the system crashes; nonvolatile storage does not.</p> <p>Data stored on disk is organized as files (records). When data is needed, it must be:</p> <ul> <li>Located on disk</li> <li>Copied to main memory for processing</li> <li>Have any changes rewritten to the disk</li> </ul> <p>Data is stored on a disk surface of concentric circles or a continuous spiral; each circle is called a track. Disks can be assembled into disk packs, and overlapped tracks on a disk pack are called cylinders. Data stored on one cylinder is faster to retrieve than data distributed across multiple cylinders.</p> <p>Tracks are divided into hard-coded sectors (or disk blocks or pages). This size is set by the OS during formatting or initialization and fixed afterwards. Blocks are separated by fixed-size interblock gaps which hold information used to determine which block on the track follows each gap.</p> <p>The hardware address of a block consists of:</p> <ul> <li>Cylinder number</li> <li>Track number</li> <li>Block number</li> </ul> <p>Or, a single number logical block address (LBA) is mapped automatically to a block by the disk drive controller, plus the address of a buffer (reserved area in main storage that holds one disk block).</p> <p>Read: disk block is copied into the buffer.</p> <p>Write: buffer contents are copied into the disk block.</p> <p>Factors affecting speed of read/write include:</p> <ul> <li>Seek time</li> <li>Rotational delay or latency</li> <li>Block transfer time (may be helped by bulk transfer rate)</li> </ul> <p>Locating data on disk is the major bottleneck for DB applications. Disks are random access secondary storage devices because arbitrary blocks may be randomly accessed with a specified address.</p> <p>Magnetic tapes are sequential access devices; to access block n, the preceding n-1 blocks must be scanned. Tapes are important for DB backup and archive.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#efficient-data-access","title":"Efficient Data Access","text":"<ul> <li>Bufferring data in memory so that new data can be held in the buffer while old data is processed by the application</li> <li>Organizing data on disk for efficiency, e.g. keep related data in contiguous blocks</li> <li>Reading data ahead of request (read blocks from the rest of a requested track) to minimize seek time on the likelihood they will be needed next; counterproductive for random block reads</li> <li>Schedule I/O requests for efficiency, e.g. read from tracks in order (minimize backtracking for the arm); elevator algorithm</li> <li>Temporarily hold writes in log disks sequentially, where they are ordered for more efficient writes</li> <li>Use SSDs or flash memory for recovery, especially in high-frequency applications</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#efficiency","title":"Efficiency","text":"<p>RAM is volatile, fast, small, relatively expensive; disk is permanent, comparatively slow, comparatively big, and comparatively cheap. Assume the vast majority of a DB is stored on disk.</p> <ul> <li>Main memory access time typicallu 3ons (nanoseconds): 0.3x10\u207b\u2077s</li> <li>Disk access time about 10ms (milliseconds): 1x10\u207b\u00b2s</li> </ul> <p>In cost computation, ignore main memory access time (it's too small to make a difference) -- only input/output cost matters.</p> <p>Records take up space (bytes) in a block. Blocks are units of data transfer between disk and memory. Typically we assume blocks are 80% filled.</p> <p>To calculate unused space (bytes) in a block of size B bytes: B - (bfr * R) where bfr is the blocking factor (number of records in a block).</p> <p>Calculate bfr with bfr = \u230aB/R\u230b where \u230a(x)\u230b is the floor function (round down to nearest integer).</p> <p>Leftover space in blocks that would not fit a complete record can be utilized in different ways:</p> <ul> <li>Spanned: break up the record, using up the remainder of a block and putting the rest of the record in the next block<ul> <li>Uses the whole block, every byte; blocks no factor in records per track</li> <li>This is the only option if record sizes are larger than block size</li> <li>E.g. track bytes: 2 mil, block bytes: 8k, record bytes: 120</li> <li>Spanned records per track = track bytes / record bytes = 2 mil / 120 = 16,666 records in a track using up all the space<ul> <li>No need to consider block size</li> </ul> </li> </ul> </li> <li>Unspanned: ignore the unused space in the block (most DBMS do this)<ul> <li>May not use a whole block, so calculate blocks per track to find records per track</li> <li>E.g. track bytes: 2 mil, block bytes: 8k, record bytes: 120</li> <li>blocks per track = 2 mil / 8k = 250</li> <li>bfr = block size / record size = 8000/120 = 66 records fit in a block (floor)</li> <li>Unspanned records per track = blocks per track * bfr = 16,500 records in a track ignoring unused space</li> </ul> </li> </ul> <p>Files consist of multiple blocks that are linked by address pointers (they may not be sequential; pointers tell you where to go).</p> <p>Example numbers:</p> <ul> <li>Record size 159 bytes</li> <li>Block size 4k bytes (80% filled)</li> <li>About 20 records per block</li> <li>Block pointers are 4 bytes (32-bit architecture)</li> <li>If you have 4 million records / 20 records per block, you need 200,000 blocks</li> <li>Since block size is 4k, file size is 800MB</li> </ul> <p>Some assumptions to help make estimates:</p> <ul> <li>Page fault times<ul> <li>Seek time: 3-8ms</li> <li>Rotational delay: 2-3ms</li> <li>Transfer time: 0.5-1ms</li> <li>Total of 5-12ms or 0.01s</li> </ul> </li> <li>Extent (bulk) transfers save seek time and rotational delay, but require more buffer<ul> <li>Pick up more blocks, e.g. 250 blocks</li> <li>Only costs more transfer time</li> </ul> </li> <li>If page fault is 10ms, transfer of 250 blocks takes 2.5s<ul> <li>As an extent, cost is 0.260s</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#buffering","title":"Buffering","text":"<p>Use of buffers in main memory can speed up block transfer; while one buffer is being read/written, the CPU can process data in the other buffer using independent disk I/O. Processes run concurrently in an interleaved fashion with a single CPU; parallel processing is possible with multiple CPUs.</p> <p>A buffer manager (software component of DBMS) responds to data requests and decides which buffers to use and which pages to replace to accommodate requested blocks.</p> <ul> <li>The buffer pool (available main memory storage) size is a parameter for the DBMS</li> <li>A pin-count is the number of times a page has been requested (number of current users of that page); unpinned is a 0 count, pinning is incrementing the count<ul> <li>Generally, pinned blocks should not be allowed to be written to disk</li> </ul> </li> <li>A dirty bit, initially 0, is set to 1 whenever a page is updated by an application program</li> </ul> <p>Buffer management strategies include:</p> <ul> <li>Most-recently-used (MRU)</li> <li>Least-recenty-used (LRU)<ul> <li>Free up the LRU memory (oldest out)</li> <li>Buffer manager maintains a table with a record of times a page is accessed</li> <li>Excellent for merge joins</li> <li>Kills nested loop joins (use MRU)</li> </ul> </li> <li>Clock policy, which chooses buffers based on rotation through the buffers and looking for a 0 dirty bit</li> <li>FIFO, same concept as LRU but without maintaining table of page access times<ul> <li>May not work effectively with blocks that are needed continuously</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#records-on-disk","title":"Records on Disk","text":"<p>Records consist of a collection of data values or items. Each value is formed of bytes and corresponts to a field of the record. A collection of field names and their data types constitute a record type or record format definition.</p> <p>A file is a sequence of records.</p> <ul> <li>Fixed-length records: every file is the same size</li> <li>Variable-length records: file size varies<ul> <li>Fields may be variable-length</li> <li>Repeating fields (multivalue) with repeating groups may be used</li> <li>Optional fields</li> <li>Mixed file: file may contain records of different record types</li> <li>Distinguishable separator chacters may be used to determine field value length</li> <li>A field type code may be assigned to each field</li> <li>Each record is preceded by a record type indicator</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#allocating-file-blocks","title":"Allocating File Blocks","text":"<ul> <li>Contiguous allocation allocates consecutive disk blocks<ul> <li>Fast for reading the whole file using double buffering</li> <li>Expanding the file is difficult</li> </ul> </li> <li>Linked allocation uses a pointer in each file block to indicate the next file block<ul> <li>Easy to expand the file</li> <li>Slow to read the whole file</li> </ul> </li> <li>Consecutive clusters (file segments, extents) of blocks can be allocated and linked</li> <li>In index allocation, index blocks can contain pointers to actual file blocks</li> <li>These techniques can be combined</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#file-organization","title":"File Organization","text":"<ul> <li>Searching for a file on disk requires copying blocks to the main memory buffer, then searching them</li> <li>Avoid inefficient linear search (required when the address of the needed block isn't known) and full scan of file</li> </ul> <p>A file header (file descriptor) contains information for accessing the file records:</p> <ul> <li>For determining disk addresses of the file blocks</li> <li>Format descriptions which may include:<ul> <li>Field lengths and order of fields within a record (fixed-length records)</li> <li>Field type codes, separator characters, record type codes (variable-length records)</li> </ul> </li> </ul> <p>Primary file organizations determine how records are physically placed on disk (accessed): heap, sorted, hashed, and B-trees.</p> <p>Secondary organization or auxiliary access structure allows access based on alternate fields: indexes.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#operations-on-files","title":"Operations on Files","text":"<p>Operations that are expected to be applied more frequently should be performed more efficiently.</p> <ul> <li>Retrieval operations<ul> <li>Locate records</li> <li>No change to data in file</li> </ul> </li> <li>Update operations<ul> <li>Change file(s) by insertion/deletion of record or modification of field values</li> </ul> </li> <li>Select record for update operation based on selection condition (filtering condition)<ul> <li>Simple selection condition, e.g. comparison of field values</li> <li>The first record that satisfies a condition is designated the current record</li> </ul> </li> <li>Open: prepare file for read/write<ul> <li>Allocate buffers (typically at least two) and retrieves file header</li> <li>Set file pointer to beginning of file</li> </ul> </li> <li>Close: complete file access by releasing the buffers and performing any cleanup operations</li> </ul> <p>Record-at-a-time operations:</p> <ul> <li>Reset: set file pointer of an open file to beginning of file</li> <li>Find (locate): search for the first record that satisfies a search condition<ul> <li>Transfer the block containing the record to main memory buffer (becomes current record)</li> </ul> </li> <li>Read (get): copies the current record from the buffer to a program variable in the user program<ul> <li>May advance the currrent record pointer to the next record in the file (necessitates reading next block)</li> </ul> </li> <li>FindNext: search for the next record in the file that satisfies the search condition<ul> <li>Transfer the containing block into main memory buffer (becomes the current record)</li> </ul> </li> <li>Delete: delete current record and (eventually) update file on disk</li> <li>Modify: modifies field values for current record and (eventually) update file on disk</li> <li>Insert: insert a new record<ul> <li>Locate the block where the record is to be inserted</li> <li>Transfer the block to main memory buffer</li> <li>Write the record into the buffer</li> <li>Eventually write the buffer to disk</li> </ul> </li> </ul> <p>Find, FindNext, and Read can be streamlined into scan:</p> <ul> <li>Returns the first record if the file has just been opened or reset</li> <li>Otherwise, return the next record</li> <li>If there is a condition, return the first/next record matching the condition</li> </ul> <p>Set-at-a-time higher level operations:</p> <ul> <li>FindAll: locate all the records in the file that satisfy a condition</li> <li>Find (locate): search for the first record that satisfies a condition then continue to locate next n-1 records that satisfy the condition; transfer the blocks containing the n records to main memory</li> <li>FindOrdered: retrieve all records in the file in the specified order</li> <li>Reorganize: reorganize some file organizations that require it preiodically; e.g. reorder file records by sorting on a specified field</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#heap-lookup","title":"Heap Lookup","text":"<p>Heap files; unsorted records.</p> <ul> <li>New records are inserted at the end; insertion is very efficient<ul> <li>Last disk block is copied into a buffer, new record is added, then block is rewritten back to disk</li> <li>Address of the last block is kept in file header</li> </ul> </li> <li>Searching for a record is inefficient (linear search)</li> <li>Often used with secondary access paths, e.g. secondary indexes</li> </ul> <p>Lookup time (average) is N/2 where N is the number of data blocks: e.g. with 200,000 data blocks:</p> <p>200,000 / 2 * 0.01s = 16.6min</p> <p>To delete a record:</p> <ul> <li>Program finds block</li> <li>Copies block into buffer</li> <li>Delete record from buffer</li> <li>Rewrite block to disk, leaving unused space in disk block<ul> <li>To avoid wasting storage space, a deletion marker can be stored with each record</li> <li>A \"deleted\" record is just indicated using the marker; excluded in searches</li> <li>Periodic reorganization will pack and remove deleted records</li> </ul> </li> </ul> <p>Relative or direct file: with a file of unordered fixed-length blocks that uses unspanned blocks and contiguous allocation, records can be accessed by position.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sorted-lookup","title":"Sorted Lookup","text":"<p>Ordered or sequential file: the ordering field value is used to order the records of a file on disk. An ordering field that is also a key field of the file is called an ordering key.</p> <p>Ordering doesn't improve accessing files based on values of the nonordering fields -- use linear search, necessitating creating another sorted copy of the file in a different order.</p> <p>Insert and delete are expensive:</p> <ul> <li>Records must remain physically ordered, so space must be made for inserts</li> <li>On average, half the file records must be moved to make room (read/write half the file blocks)</li> <li>Deletion is less inefficient if delete markers are used</li> </ul> <p>To improve insertion:</p> <ul> <li>Keep unused space in each block (only works until blocks get filled)</li> <li>Create a temporary unordered file: overflow or transaction file<ul> <li>The ordered file is called main or primary</li> <li>New records are inserted at the end of the overflow file, then periodically sorted and merged with the primary</li> <li>Insertion becomes more efficient; searching more complex</li> </ul> </li> </ul> <p>Sorted linear search is the same as heap: 16.6min by this example (still looks at each item it encounters until the target is found).</p> <p>Lookup time for 2-ary (binary) search is log\u2082(N) where N (capital) is the number of data blocks:</p> <ul> <li>log\u2082(200,000) = 18</li> <li>18 * 0.01s = 0.18s</li> </ul> <p>Used with a primary index, resulting in an indexed-sequential file.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#single-level-ordered-indexes","title":"Single-Level Ordered Indexes","text":"<ul> <li>An index access structure is usually defined on a single field of a file, an indexing field (indexing attribute)</li> <li>Index stores each value of the index field plus pointers to the disk blocks that contain the records with that field value</li> <li>Values are ordered to enable binary search (efficient)</li> </ul> <p>Types of ordered indexes include:</p> <ul> <li>Primary index, specified on the ordering key field (physical order) on an ordered file of records</li> <li>Clustering index, or clustered file, which can be used if numerous records have the same value for the ordering field</li> <li>Secondary index can be specified on nonordering fields; data file can have several of these in addition to primary</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#primary-index","title":"Primary Index","text":"<p>Ordered file with records of a fixed length. An index is built of the key value and pointer for each data block: two fields (PK, pointer) to act as an access structure.</p> <ul> <li>For point and range queries</li> <li>One index file for each block in the data file</li> <li>Pointer may be:<ul> <li>The physical address of a block/page</li> <li>The record address: block address + record ID/offset in the block</li> <li>Logical address of the block or of the record in the file; relative number to be mapped to a physical address</li> </ul> </li> <li>First block of data file is the anchor record (block anchor)</li> <li>Sorted data results in a sorted index</li> </ul> <p>Lookup time is log\u2082(n)+1 where n (lowercase) is the number of index blocks. We add 1 because once the value is found in the index, we still need to access the data.</p> <p>Index page holds many entries, since it's just the keys. For example:</p> <ul> <li>Block pointer: 4 bytes (80% filled)</li> <li>Key length (varchar(50)) plus pointer: 54</li> <li>54 / 3200 gives fanout ~60 (60 key values and corresponding pointers) TODO</li> <li>4 million records</li> <li>200,000 data blocks</li> <li>Need to point to 200,000 blocks with a fanout of 60 TODO<ul> <li>200,000 / 60 makes 3334 blocks in a sparse index</li> <li>4,000,000 / 60 makes 66,666 blocks in a dense index</li> </ul> </li> </ul> <p>Binary search on index file requires fewer block accesses than binary search on data file.</p> <ul> <li>Binary search on ordered data file: log\u2082b block accesses</li> <li>If primary index file has b\u1d62 blocks, locating a record with a search key value requires log\u2082b\u1d62 + 1: binary search of index plus access to block containing record</li> </ul> <p>Example calculation of necessary block accesses:</p> <ul> <li>An ordered file with 300,000 records<ul> <li>Stored on a disk with block size 4,096 bytes</li> <li>Assume file records are of fixed size, unspanned, record length of 100 bytes</li> <li>Recall bfr: floor(4,096/100) = 40 records per block</li> <li>Number of blocks needed for the file is b = \u2308(r/bfr)\u2309 = \u2308(300,000/40)\u2309 = 7,500 blocks</li> <li>Binary search on the data file needs \u2308log\u2082 b\u2309 = \u2308(log\u2082 7,500)\u2309 = 13 block accesses</li> </ul> </li> <li>On a primary index<ul> <li>Ordering key field of V = 9 bytes length</li> <li>Block pointer of P = 6 bytes</li> <li>Size of each index entry: R\u1d62 = (9+6) = 15 bytes</li> <li>bfr\u1d62 = \u230a(B/R\u1d62)\u230b = \u230a(4,096/15)\u230b = 273 entries per block</li> <li>Total number of index entries is the same as number of blocks in the data file: 7,500 (r\u1d62)</li> <li>Number of index blocks b\u1d62 = \u2308(r\u1d62/bfr\u1d62)\u2309 = \u2308(7,500/273)\u2309 = 28 blocks</li> <li>Binary search on the index file needs \u2308(log\u2082 b\u1d62)\u2309 = \u2308(log\u2082 28)\u2309 = 5 block accesses<ul> <li>+1 to get the data file = 6</li> </ul> </li> <li>If the index is small and kept in main memory, only 1 block access is needed to retrieve record</li> </ul> </li> </ul> <p>Some operations don't need to access the data, just the index -- e.g. MAX, MIN, AVG.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#sparse-index","title":"Sparse index","text":"<p>Fewer entries than the number of records in a file.</p> <p>Sparse index (pick up only first key value of each block) lookup:</p> <ul> <li>(log\u2082(200,000/60)+1) * 0.01s</li> <li>(12+1) * 0.01s = 0.13s</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#dense-index","title":"Dense index","text":"<p>Total number of entries is the same as the number of disk blocks in the ordered data file.</p> <p>Dense index (pick up every key value) lookup:</p> <ul> <li>(log\u2082(4,000,000/60)+1) * 0.01s</li> <li>(16+1) * 0.01s = 0.17s</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#clustering-index","title":"Clustering Index","text":"<p>If the ordering attribute is not a key (and thus a distinct value), the file is called a clustered file. The nonkey field that the records are physically ordered on is the clustering field.</p> <ul> <li>Ordered file with two fields; (value, pointer to disk block)</li> <li>One entry in the clustering index for each distinct value of the clustering field</li> <li>Insert/delete are tricky because data records are physically ordered<ul> <li>To help, a whole block or cluster of contiguous blocks may be reserved for each value of the clustering field</li> <li>All records with that value are placed in the block/block cluster</li> </ul> </li> <li>Sparse index (entry for each distinct value only)</li> </ul> <p>Example calculation of block accesses:</p> <ul> <li>An ordered file with 300,000 records<ul> <li>Stored on a disk with block size 4,096 bytes</li> <li>Assume file records are of fixed size, unspanned, record length of 100 bytes</li> <li>Recall bfr: floor(4,096/100) = 40 records per block</li> <li>Number of blocks needed for the file is b = \u2308(r/bfr)\u2309 = \u2308(300,000/40)\u2309 = 7,500 blocks</li> <li>Total number of index entries is the same as number of blocks in the data file: 7,500 (r\u1d62)</li> <li>Assume ordered by <code>Zipcode</code>, 1,000 zip codes in the file (average 300 records per zip code)</li> <li>Index has 1,000 entries of 11 bytes each (5 bytes zip code and block pointer 6 bytes)</li> <li>bfr\u1d62 = \u230a(B/R\u1d62)\u230b = \u230a(4,096/11)\u230b = 372 entries per block</li> <li>Number of index blocks b\u1d62 = \u2308(r\u1d62/bfr\u1d62)\u2309 = \u2308(1,000/372)\u2309 = 3 blocks</li> <li>Binary search on the index needs \u2308(log\u2082 b\u1d62)\u2309 = \u2308(log\u2082 3)\u2309 = 2 block accesses<ul> <li>+1 access to the data file to get the record</li> </ul> </li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#secondary-index","title":"Secondary Index","text":"<ul> <li>For point queries</li> <li>Need more storage space and longer search time than primary index (dense)<ul> <li>Improvement in search time for an arbitrary record</li> </ul> </li> <li>Data file records could be ordered, unordered, or hashed</li> <li>Can be created on candidate key (unique values) or nonkey field (duplicate values)</li> <li>Index is an ordered file with two fields: (indexing field, block or record pointer)<ul> <li>Entries are ordered by value of indexing field (not physically ordered; cannot use block anchors)</li> </ul> </li> <li>Multiple secondary indexes can be created for the same file</li> <li>Provides a logical ordering on records by the indexing field</li> <li>Assumes that the field used for physical ordering of records in the file is the same as the indexing field</li> </ul> <p>A secondary index access structure built on a unique key (secondary key) has one index entry for each record (dense).</p> <p>Lookup time is also log\u2082(n)+1 where n (lowercase) is the number of index blocks.</p> <p>Secondary indexes are built on data that is unsorted, and so can only be dense indexes. The index pointers are sorted initially; we then sort on the values (assuming uniqueness). This means secondary indexes are sorted, but pointers are out of order (hence point queries only).</p> <p>Dense index (pick up every key value) lookup:</p> <ul> <li>(log\u2082(4,000,000/60)+1) * 0.01s</li> <li>(16+1) * 0.01s = 0.17s</li> </ul> <p>Example calculation of block accesses:</p> <ul> <li>An ordered file with 300,000 records</li> <li>Stored on a disk with block size 4,096 bytes</li> <li>Assume file records are of fixed size, unspanned, record length of 100 bytes</li> <li>Recall bfr: floor(4,096/100) = 40 records per block</li> <li>Number of blocks needed for the file is b = \u2308(r/bfr)\u2309 = \u2308(300,000/40)\u2309 = 7,500 blocks</li> <li>Total number of index entries is the same as number of blocks in the data file: 7,500 (r\u1d62)</li> <li>Search for a record using secondary key that is V = 9 bytes long<ul> <li>Without a secondary index: b/2 = 7,500/2 = 3,759 blocks to access</li> </ul> </li> <li>With a secondary index (6 byte pointer), each index entry is R\u1d62 = (9+6) = 15 bytes</li> <li>bfr\u1d62 = \u230a(B/R\u1d62)\u230b = \u230a(4,096/15)\u230b = 273 entries per block</li> <li>Number of index entries is same as number of records: 300,000</li> <li>Number of index blocks b\u1d62 = \u2308(r\u1d62/bfr\u1d62)\u2309 = \u2308(300,000/273)\u2309 = 1,099 blocks</li> <li>Binary search on the index needs \u2308(log\u2082 b\u1d62)\u2309 = \u2308(log\u2082 1,099)\u2309 = 11 block accesses<ul> <li>+1 access to the data file to get the record = 12</li> </ul> </li> </ul> <p>Implementing a secondary index on a nonkey, nonordering field of a file can be accomplished by several options:</p> <ol> <li>Include duplicate index entries with the same index field value K(i) -- dense index with one for each record</li> <li>Have variable-length records for index entries with a repeating field for the pointer -- one pointer to each block that contains a record with indexing field value K(i)</li> <li>Keep index entries at fixed length and have a single entry for each index field value (most common)</li> <li>Nondense, uses pointer in index entry to point to disk block that contains a set of record pointers</li> <li>Each record pointer in disk block points to one of the data file records with the indexing field value</li> <li>A linked list is used if the value occurs in too many records to fit in a single disk block</li> <li>Can apply binary search to the ordered index file</li> </ol>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#static-hashing","title":"Static Hashing","text":"<p>Hash function takes keys from key space (large) and assigns them an address in bucket space (block address -- smaller).</p> <p>A good hash function:</p> <ul> <li>Distributes values uniformly over the address space</li> <li>Fills the bucket as much as possible (pieces could be on disk and require retrieval)</li> <li>Avoids collisions</li> </ul> <p>Lookup time is constant(-ish) if bucket directory is in main memory:</p> <ul> <li>(1 to 2) * 0.01s = 0.01 to 0.02s<ul> <li>One if it's in memory; two if it's not</li> </ul> </li> <li>Bucket directory page, then data block</li> </ul> <p>Dynamic hashing expands bucket directory when needed; the more data that gets inserted with the same bucket directory size, the more the number of linked data blocks (linked list) we need to traverse.</p> <p>Example:</p> <ul> <li>Assume unspanned records, no overflow, uniform distribution<ul> <li>Unspanned records per track = blocks per track * bfr (ignoring unused space)</li> </ul> </li> <li>Unspanned records per block:<ul> <li>8,000 bytes per block</li> <li>120 bytes in a record</li> <li>8000/120 = 66 (round down) records per block</li> </ul> </li> <li>5 blocks per bucket</li> <li>Each bucket 80% full, affecting the fillable blocks in it:<ul> <li>5 blocks * 0.8 = 4 full blocks per bucket</li> </ul> </li> <li>132 million records / 66 records per block = 2 mil blocks needed per file</li> <li>2 mil blocks / 4 blocks in a bucket = 500,000 buckets required in the file</li> </ul> <p>Read time:</p> <ul> <li>Each track is 2 million bytes / block size of 8,000 = 250 blocks in a track</li> <li>Transfer time per block 0.1 ms</li> <li>250 * 0.1ms = 25 ms</li> <li>Add one seek and one rotational delay</li> </ul> <p>Hash file: organization using hash function (or randomizing function) applied to the hash field value of a record; yields the address of a disk block where the record is stored. For internal files, implemented using hash table.</p> <p>Methods for collision resolution include:</p> <ul> <li>Open addressing: check subsequent positions until an open (unused, empty) position is found</li> <li>Chaining: place colliding record in a predesignated unused overflow location, and set pointer of the occupied hash address location to the overflow location</li> <li>Multiple hashing: apply a second hash function if the first results in a collision</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#mixed-records","title":"Mixed Records","text":"<ul> <li>Relationships are implemented by logical field references:<ul> <li>Relationships between records in various files may be represented by connecting fields</li> <li>The value points to the created record in another file</li> </ul> </li> <li>Relationships may be implemented in object DBMSs or legacy systems as physical relationships; physical contiguity (physical clustering) of related records or by physical pointers<ul> <li>Assign an area of the disk to hold records of more than one type</li> <li>In data warehouse, input initialy undergoes an integration and is collected into an operational data store (ODS)<ul> <li>ODS typically contains files where multiple records are kept together</li> <li>After ETL (extract, transform, load), passed on to data warehouse</li> </ul> </li> </ul> </li> <li>Each record in a mixed file has a record type field, typically the first in the record</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#multi-level-index","title":"Multi-level Index","text":"<p>Index of the index of the index of...</p> <ul> <li>Binary search: (log\u2082 b\u1d62) block accesses<ul> <li>Each step of the algorithm reduces the part of the index file we need to search by 2</li> </ul> </li> <li>Multilevel index wants to reduce the part of the index we need to search by the blocking factor, bfr\u1d62, called fan-out of the multilevel index (symbol fo)<ul> <li>Record search space is divided n-ways where n = fo</li> <li>Searching a multilevel index requires (log_{fo} b\u1d62)</li> </ul> </li> <li>Fan-out depends on how many entries (key + block pointer) fit in a block<ul> <li>E.g. 4-byte block pointer and 9-byte key, fan-out = 315</li> </ul> </li> <li>Useful on any type of index as long as first level has distinct values for K(i) and fixed-length entries</li> </ul> <p>Lookup time is:</p> \\[ log_{fanout}(n) + 1 \\] <p>... where n (lowercase) is the number of index blocks. The cost decreases as the fanout increases.</p> <ul> <li>The index file (first or base level) is an ordered file with a distinct value for each K(i)</li> <li>Can create a primary index for the first level (second level)<ul> <li>Can use block anchors so there is one entry for each block of the first level</li> </ul> </li> <li>Blocking factor for second and subsequent levels is the same as first level<ul> <li>Blocking factor and fan-out are the same</li> <li>If first level has r\u2081 entries, it needs r\u2082 = \u2308(r\u2081/fo)\u2309 blocks; this is the number of entries needed at the second level</li> <li>Third level entries is r\u2083 = \u2308(r\u2082/fo)\u2309</li> </ul> </li> <li>All index levels are physically ordered files</li> </ul> <p>The top index level is the tth level. To calcuate t:</p> \\[ 1 \\leq ((r_{1}/((fo)^{t}))) \\] <p>Thus a multilevel index with r\u2081 first-level entries has approximately t levels, where:</p> \\[ t = \\lceil(log_{fo}(r_{1}))\\rceil \\] <p>Since a single block is retrieved at each level and t is the number of levels, t disk blocks are accessed for an index search.</p> <p>Example calculation of block access:</p> <ul> <li>An ordered file with 300,000 records</li> <li>Stored on a disk with block size 4,096 bytes</li> <li>With a secondary index (6 byte pointer), each index entry is R\u1d62 = (9+6) = 15 bytes</li> <li>bfr\u1d62 = \u230a(B/R\u1d62)\u230b = \u230a(4,096/15)\u230b = 273 entries per block, also the fo</li> <li>Number of first level blocks b\u2081 is 1,099</li> <li>Number of second level blocks is b\u2082 = \u2308(b\u2081/fo)\u2309 = \u2308(1,099/273)\u2309 = 5</li> <li>Number of third level blocks is b\u2083 = \u2308(b\u2082/fo)\u2309 = \u2308(5/273)\u2309 = 1</li> <li>Third level is the top level, t = 3</li> <li>To search multilevel index for a record, we access one block at each level plus one block from data file:<ul> <li>t + 1 = 3 + 1 = 4 block accesses</li> </ul> </li> </ul> <p>Indexed sequential (file) access method (ISAM)</p> <ul> <li>Used in early IBM systems</li> <li>Ordered file with a multilevel primary index on its ordering key field</li> <li>Two-level index related to organization of disk (cylinders and tracks)<ul> <li>First level: cylinder index, has key, value of an anchor record for each cylinder occupied by the file, and pointer to the track index of the cylinder</li> <li>Track index: has key, value of an anchor record for each track in the cylinder and a pointer to the track</li> </ul> </li> <li>Track can be searched sequentially for the record/block</li> <li>Insertion handled by overflow file</li> <li>Index is re-created during file reorganization</li> </ul> <p>Sparse index:</p> <ul> <li>(log\u2086\u2080(3334)+1) * 0.01s</li> <li>(2+1) * 0.01s = 0.03s</li> </ul> <p>Many levels make blocks more susceptible to overflow; when a record needs to be split across blocks, the indexes are impacted (ripple).</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#dynamic-multilevel-indexes","title":"Dynamic Multilevel Indexes","text":"<ul> <li>Reduce insert/delete problems that come with physically ordered files</li> <li>Leave some space in each block for inserting new entries</li> <li>Implemented using B-trees and B\u207a-trees</li> </ul> <p>A tree is balanced when all its leaf nodes are at the same level.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#search-trees-and-b-trees","title":"Search Trees and B-Trees","text":"<ul> <li>A search tree of order p is a tree where each node contains at most p-1 search values and p pointers, where q \u2264 p in the order:</li> </ul> \\[ &lt;P_{1}, K_{1}, P_{2}, K_{2}, ... P_{q-1}, K_{q-1}, P_{q}&gt; \\] <ul> <li>P\u1d62 is a pointer to a child node or NULL</li> <li>K\u1d62 is a search value from an ordered set, assumed unique</li> </ul> <p>Two constraints in a search tree must hold at all times:</p> <ol> <li>Within each node:   $$   K_{1} &lt; K_{2} &lt; ... &lt; K_{q-1}   $$</li> <li>For all values X in the subtree indicated by P\u1d62, follow the pointer according to:   $$   K_{i-1} &lt; X &lt; K_{i}\\ for\\ 1 &lt; i &lt; q   $$   $$   X &lt; K_{i}\\ for\\ i = 1   $$   $$   and\\ K_{i-1} &lt; X\\ for\\ i = q   $$</li> </ol> <p>Goals for balancing a search tree:</p> <ul> <li>Guarantee that nodes are evenly distributed<ul> <li>Depth of tree is minimized for given set of keys and tree does not get skewed with some nodes at deep levels</li> </ul> </li> <li>Make the search speed uniform so that the average time to find a given key is roughly the same</li> </ul> <p>Implicitly, ensure the index tree does not need much restructuring when records are inserted and deleted.</p> <ul> <li>Keep nodes as full as possible</li> <li>Avoid empty nodes if there are deletions</li> </ul> <p>Analysis and simulation shows that after random insertions and deletions, nodes of a B-tree and a B\u207a-tree are approximately 69% full when the number of values in the tree stabilizes.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#b-tree","title":"B-Tree","text":"<p>Multilevel access, balanced tree structure.</p> <p>Adds constraints to ensure tree is always balanced and that space wasted by deletion is not excessive. A B-tree of order p (used as an access structure on a key field to search for a record) is defined as:</p> <ol> <li>Each internal node is of the form   $$   , P_{2}, \\, ..., \\, P_{q}&gt;   $$ <li>Within each node,   $$   K_{1} &lt; K_{2} &lt; ... &lt; K_{q-1}   $$</li> <li>For all search key field values X in the subtree pointed at by P\u1d62:   $$   K_{i-1} &lt; X &lt; K_{i}\\ for\\ 1 &lt; i &lt; q   $$   $$   X &lt; K_{i}\\ for\\ i = 1   $$   $$   and\\ K_{i-1} &lt; X\\ for\\ i = q   $$</li> <li>Each node in a tree of order p has at most p-1 search values and p tree pointers.</li> <li>Each node (except root and leaf nodes) has at least \u2308(p/2)\u2309 tree pointers.</li> <li>Root node has at least two tree pointers unless it is the only node</li> <li>A node with q tree pointers, q \u2264 p, has q-1 search key field values (hence, data pointers).</li> <li>All leaf nodes are at the same level (balanced). Leaf nodes are the same as internal nodes except that all their tree pointers P\u1d62 are NULL.</li> <p>Calculating blocks and levels:</p> <ul> <li>With a nonordering key field for a serach field and a B-tree with p = 23</li> <li>Assume that each node is 69% full<ul> <li>Average pointers of each node is p * 0.69 = 23 * 0.69 = 16</li> <li>Hence 15 search key field values</li> </ul> </li> <li>Average fan-out fo = 16</li> <li>At each level of the tree, calculate the number of key entries by<ul> <li>Total number of pointers at previous level * 15 (average number of entries in each node)</li> </ul> </li> </ul> Level Nodes Key entries Pointers Root 1 15 16 L1 16 240 256 L2 256 3,840 4,096 L3 4,096 61,440 <ul> <li>With block size 512 bytes</li> <li>Record pointer 7 bytes and tree pointer 6 bytes</li> <li>Search key field size 9 bytes</li> <li>Then a two-level B-tree of order 23 with 69% occupancy holds 3,840 + 240 + 15 = 4,095 entries on average</li> <li>A three-level B-tree holds 61,440 + 4,095 = 65,535 entries on average</li> </ul> <p>B-trees can be primary file organizations if the whole records stored in the nodes are relatively small in size and number.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#b-trees","title":"B\u207a-Trees","text":"<ul> <li>Every value of the search field appears once at some level in the tree, with a data pointer</li> <li>Data pointers are stored only at the leaf nodes of the tree; leaf node structure differs from internal node structure</li> <li>Leaf nodes have an entry for every value of the search field and a data pointer to the record or its containing block<ul> <li>If nonkey search field, pointer points to a block containing pointers to the data file records, adding an additional step for retrieval</li> </ul> </li> <li>Data is at the bottom with multi-level index nodes above</li> <li>Popular in RDBMS</li> <li>B for balance: insert, delete, update operations used to keep the tree balanced<ul> <li>Maintain distance from the root to the base level -- maintain search time</li> </ul> </li> <li> <p>Lower level overflow rarely propagates more than 1-2 levels up ** Internal nodes of B\u207a-tree of order p:</p> </li> <li> <p>Each internal node, where q \u2264 p and each P\u1d62 is a tree pointer, is of the form:   $$      $$ <li>Within each internal node,   $$   K_{1} &lt; K_{2} &lt; ... &lt; K_{q-1}   $$</li> <li>For all search key field values X in the subtree pointed at by P\u1d62:   $$   K_{i-1} &lt; X \\leq K_{i}\\ for\\ 1 &lt; i &lt; q   $$   $$   X \\leq K_{i}\\ for\\ i = 1   $$   $$   and\\ K_{i-1} &lt; X\\ for\\ i = q   $$</li> <li>Each internal node has at most p tree pointers.</li> <li>Each internal node except the root has at least \u2308(p/2)\u2309 tree pointers.</li> <li>Root node has at least two tree pointers if it is an internal node</li> <li>An internal node with q pointers, q \u2264 p, has q-1 search field values.</li> <p>Leaf nodes of B\u207a-tree of order p:</p> <ol> <li>Each leaf node, where q \u2264 p, Pr\u1d62 is a data pointer, and P\u2099\u2091\u2093\u209c points to the next leaf node of the tree, has the form:   $$   &lt;, , ..., , P_{next}&gt;   $$ <li>Within each leaf node,   $$   K_{1} \\leq K_{2} ..., K_{q-1}, q \\leq p   $$</li> <li>Each Pr\u1d62 is a data pointer to the record whose search field value is K\u1d62, or to a file block containing the record<ul> <li>Or if the search field is not a key, to a block of record pointers that point to records whose search field value is K\u1d62</li> </ul> </li> <li>Each leaf node has at least \u2308(p/2)\u2309 values.</li> <li>All leaf nodes are at the same level.</li> <p>To calculate order p of a B\u207a-tree:</p> <ul> <li>Suppose search key field is V = 9 bytes, block size B = 512 bytes, record pointer Pr = 7 bytes, and block pointer/tree pointer is P = 6 bytes</li> <li>Internal node can have up to p tree pointers and p-1 search field values that must fit in a single block</li> </ul> \\[ (p * P) + ((p-1) * V) \\leq B \\] <p>Evaluates to (15 * p) \u2264 512 and we choose the largest value that satiesfies p = 34.</p> <p>Leaf nodes order is calculated:</p> \\[ ( p_{leaf} * (Pr + V)) + P \\leq B \\] <p>Resulting in (16 * pleaf) \u2264 506 and p = 31.</p> <p>To calculate the number of entries in a B\u207a-tree:</p> <ul> <li>Assume each node is 69% full</li> <li>Each internal node on average will have 34 * 0.69 = ~23 pointers, 22 values</li> <li>Each leaf node on average will hold 0.69 * pleaf = 0.69 * 31 = ~21 data record pointers</li> </ul> Level Nodes Key entries Pointers Root 1 22 23 L1 23 506 529 L2 529 11,638 12,167 Leaf 12,167 255,507 <p>Leaf node calculation accounts for 69% occupancy of the leaf node: 12,167 * 21</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#leaf-node","title":"Leaf node","text":"<p>Insertion:</p> <ul> <li>A full leaf node overflows and must be split</li> <li>A number of the first entries are kept, determined by:   $$   j = \\lceil ((P_{leaf} + 1)/2)\\rceil   $$</li> <li>Remaining entries are moved to a new leaf node</li> <li>jth search value is replicated in the parent internal node</li> <li>An extra pointer to the new node is created in the parent</li> <li>If the parent internal node is full, it overflows and also must be split</li> <li>Splits can propagate all the way up to create a new root node and new level for the tree</li> </ul> <p>Deletion:</p> <ul> <li>Deleted entry is always removed from leaf level</li> <li>If it occurs in an internal node, the value to its left in the leaf node must replace it in the internal node<ul> <li>That value is now the rightmost entry in the subtree</li> </ul> </li> <li>May cause underflow by reducing the number of entries in the leaf node to below required minimum<ul> <li>Try to find and redistribute entries among the node and its sibling so both are at least half full</li> <li>Or, merge node with its sibling and reduce overall number of leaf nodes</li> <li>Commonly, try to redistribute entries with left sibling, or if that fails, the right<ul> <li>If both are not possible, three nodes are merged into two leaf nodes</li> </ul> </li> <li>Underflow may propogate to internal nodes because one fewer tree pointer and search value are needed<ul> <li>Can reduce tree levels</li> </ul> </li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#notes-on-indexes","title":"Notes on Indexes","text":""},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#logical-vs-physical-index","title":"Logical vs Physical Index","text":"<ul> <li>Physical index pointer must be changed if the record is moved to another disk location</li> <li>Logical index can be used when physical record addresses are expected to change frequently</li> </ul> <p>Logical index entries are of the form , where: <ul> <li>K is a value for the secondary indexing field</li> <li>K\u209a is the value of the field used for primary file organization</li> <li>The secondary index is searched on the value of K and the corresponding value of K\u209a is located</li> <li>K\u209a is used to access the record through the primary file organization</li> <li>An additional level of indirection between access stucture and data is introduced (extra search on primary file organization)</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#index-creation","title":"Index Creation","text":"<p>Creating an index is not part of the SQL standard, but implemented by many RDBMSs:</p> <pre><code>CREATE [UNIQUE] INDEX name\nON table_name (&lt;column name&gt; [ &lt;order&gt; ] {, &lt;column name&gt; [ &lt;order&gt; ]})\n[CLUSTER];\n</code></pre> <p>Keywords UNIQUE and CLUSTER (also sort data file records on indexing attribute) are optional.</p> <ul> <li>Index is not an integral oart of the data file in many systems; created, discarded dynamically (access structure)</li> <li>Secondary index is usually created to avoid physical ordering of the records in the data file on disk<ul> <li>Theoretically can be created in conjunction with any primary record organization</li> <li>E.g. with large B\u207a-tree, file nor index may fit in main memory; insertion of large number of entries is accomplished with bulk loading</li> </ul> </li> <li>Indexing with strings that can be of variable length and too long may limit fan-out<ul> <li>String as search key may give an uneven number of keys per index node, fo varies</li> <li>May force nodes to split when full regardless of number of keys in them</li> <li>Prefix compression stores only the prefix of the search key (enough to distinguish it from the keys that are separated and directed to the subtree)</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#index-tuning","title":"Index Tuning","text":"<p>Indexes may be tuned when:</p> <ul> <li>Certain queries take too long to run without one</li> <li>Indexes prove to go unused</li> <li>Indexes undergo too much updating because it is built on an attribute that changes frequently</li> </ul> <p>Command or trace functions in DBMSs (e.g. SQL explain) show how a query was executed and can help demonstrate when indexes would benefit from tuning for better performance.</p> <p>Rebuilding the index may also improve performance by reclaiming wasted space; reorganize table ordered on a key for a clustered index.</p>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#constraints-and-duplicates","title":"Constraints and Duplicates","text":"<ul> <li>An index can be used to enforce a key constrain on an attribute</li> <li>Duplicate index key values can result in the rejection of an insertion</li> <li>Indexes created on a nonkey field can result in duplicates<ul> <li>Some systems add a row ID so duplicate record keys have unique identifier</li> </ul> </li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#other-access-methods","title":"Other Access Methods","text":"<ul> <li>A fully inverted file has a secondary index on every one of its fields</li> <li>New records are inserted at the end of the file</li> <li>The data file itself is an unordered (heap) file</li> <li>Virtual storage access method (VSAM) is similar to B\u207a-tree structure (IBM)</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#indexing-hints-in-queries","title":"Indexing Hints in Queries","text":"<ul> <li>Hints can be alloweed in queries that suggest alternatives to the query processor; can optimize to expedite query execution</li> <li>Indexing hints suggest use of an index when it would improve a query; appear as a special comment</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#column-based-storage-of-relations","title":"Column-Based Storage of Relations","text":"<ul> <li>Alternative to row-by-row</li> <li>Offers benefits for read-only queries</li> </ul> <p>Column-store RDBMS consider storing each column of data individuallY:</p> <ul> <li>Vertically partitions table column-by-column so that two-column table is constructed for every attribute; only needed columns are accessed</li> <li>Uses column-wise indexes and join indexes on multiple tables to answer queries without needing access to data tables</li> <li>Uses materialized views to support queries on multiple columns</li> </ul>"},{"location":"course-notes/db-systems-concepts-design/db-systems-concepts-design/#physical-database-design","title":"Physical Database Design","text":"<p>DB designer must know the job mix (queries, transactions, applications) that will run to design the DB for best performance.</p> <p>For retrieval queries, know:</p> <ul> <li>The files (relations) accessed</li> <li>Attributes on which selection conditions are specified</li> <li>If the selection condition is an equality, inequality, or range condition</li> <li>Attributes on which join conditions or conditions for linking tables/objects are specified</li> <li>Attribute whose values are to be retrieved</li> </ul> <p>For update operations or transactions:</p> <ul> <li>Files to be updated</li> <li>Type of operation (insert, update, delete)</li> <li>Attributes on which selection conditions of a delete or update are specified</li> <li>Attributes whose values will be changed by an update operation</li> </ul> <p>Other points to analyze:</p> <ul> <li>Expected frequency of invocation (80% of the processing to be done by 20% of the transactions)</li> <li>Time constraints of queries/transactions</li> <li>Expected frequencies of updates (minimum number of access paths for affected files)</li> <li>Uniqueness constraints on attributes (specify access paths on candidate keys that are PK or unique)</li> </ul> <p>Design decisions include:</p> <ul> <li>Whether to index an attribute</li> <li>What attribute(s) to index on</li> <li>Whether to use a clustered index (main benefit is retrieving records)</li> <li>Whether to use a hash index instead of tree index</li> <li>Whether to use dynamic hashing for files that are growing/shrinking often</li> </ul>"},{"location":"course-notes/iis/intro-information-security/","title":"Introduction to Information Security","text":""},{"location":"course-notes/iis/intro-information-security/#textbook","title":"Textbook","text":"<ul> <li>Computer Security: Principle and Practice, 4 th Edition, by William Stallings and Lawrie Brown. (ISBN-10: 9780134794105)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#attacks","title":"Attacks","text":"<p>Avenues for attack include:</p> <ul> <li>User input (injection)<ul> <li>E.g. command injection: construction of a command that is injected and later executed by the system with the privileges of the web server</li> </ul> </li> <li>Server variables logged without sanitization</li> <li>Second-order injection</li> <li>Modifying cookies</li> <li>Physical input through RFID, barcodes, scanned forms, etc.</li> <li>Inference attacks: use authorized queries to infer unauthorized data</li> </ul> <p>Contingency planning involves:</p> <ul> <li>Establishing a disaster-recovery failover environment</li> <li>Regularly scheduled backup operations</li> <li>Redundancy to ensure availability of critical resources and systems</li> </ul> <p>Security maintenance involves:</p> <ul> <li>Monitoring and logging</li> <li>Regularly scheduled backup and archive</li> <li>Regular system tests</li> <li>Software patches, updates, configuration checks, preferably automatic</li> </ul> <p>Detection includes:</p> <ul> <li>Signature-based: attempts to match specific attack patterns</li> <li>Anomaly-based: attempts to define normal behavior and detect patterns outside normal range</li> <li>Code analysis: test suites or static analysis</li> </ul> <p>Effects include:</p> <ul> <li>Incapacitation: disabling system operation</li> <li>Disruption: interrupt or prevention of the correct operations of system functions</li> <li>Corruption: undesirable alteration of system operation or data by adversary</li> <li>Obstruction: interrupt or hindering delivery of system services</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#denial-of-service-dos","title":"Denial-of-Service (DoS)","text":"<p>SYN spoofing generates connection request packets with forged source addresses. TCP SYN flood attacks include indirect attacks that utilize multiple systems:</p> <ul> <li>DDoS</li> <li>Reflector attack</li> <li>Amplifier attack</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#distributed-denial-of-service-ddos","title":"Distributed Denial-of-Service (DDoS)","text":"<p>Sends large volume of DoS traffic using techniques such as Amplified Distributed Reflective Attack:</p> <ul> <li>Attacker queries open recursive DNS servers while spoofing victim's IP</li> <li>Victim receives large DNS text (TXT) records which amount to many GB of traffic</li> <li>Difficult to distinguish legitimate traffic from DDoS traffic</li> <li> <p>Attacker doesn't have to use his own computer</p> </li> <li> <p>Defenses include:</p> <ul> <li>Prevention and preemption</li> <li>Detection and filtering</li> <li>Reaction</li> <li>Source traceback and identification</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#sql-injection-sqli","title":"SQL injection (SQLi)","text":"<p>If user input is not sanitized, SQL can be injected to change intended queries.</p> <p>With a query such as:</p> <pre><code>`SELECT accounts FROM users WHERE login ='\" + login + \"'AND pass = '\" + password + \"' AND pin = \" + pin;`\n</code></pre> <p>Input for <code>login</code> such as <code>\" 'or 1=1 --\"</code> will select the full <code>users</code> table (because <code>1=1</code> is always true) and the comment syntax <code>--</code> negates the rest of the query.</p> <ul> <li>Effectively prevented by using parameterized queries</li> </ul> <p>SQLi types include:</p> <ul> <li>Inband: uses the same communication channel for injection and getting results</li> <li>Out-of-band: data retrieval using a different channel than injection</li> <li>Inferential: no actual data transfer; data is reconstructed through observing behavior resulting from injection<ul> <li>E.g. error pages, long-running queries</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#advanced-persistent-threat-apt","title":"Advanced Persistent Threat (APT)","text":"<p>Persistent and long-term operations, can be nation states.</p> <ul> <li>High-value targets</li> <li>Uses special malware, altered common malware, social engineering (SE) including phishing, and 0-days</li> <li>Blends with normal activities, cleans up logging tracks</li> </ul> <p>Lifecycle of operations is cyclical:</p> <ol> <li>Define its (next) target</li> <li>Research target and people involved (SE)</li> <li>Test for network detection, test exploitation of target servers</li> <li>Exploit deployment and success (infiltration)</li> <li>Establish outbound connections (create a path for exfiltration)</li> <li>Exfiltrate data</li> <li>Remain undetected</li> </ol>"},{"location":"course-notes/iis/intro-information-security/#stack-overflow","title":"Stack Overflow","text":"<ul> <li>Stack buffer overflow is also called stack smashing</li> <li>Memory leak is caused by incorrectly managed memory<ul> <li>Memory in languages like C must be allocated and released when done with</li> </ul> </li> <li>Payload is shellcode: machine code corresponding to machine instructions that implements an attacker's desired function</li> </ul> <p>Defenses include:</p> <ul> <li>Using a non-executable stack if the OS or hardware support it<ul> <li>Stack in this case is not writable</li> <li>Does not prevent read-only attacks e.g. Heartbleed</li> </ul> </li> <li>Stack canaries<ul> <li>Writes a canary value just before return address that detects buffer overflow when overwritten</li> <li>Before returning from function, the code checks to see if the canary value has changed</li> <li>Detects modification to return address to prevent execution takeover, e.g. in return-to-libc attacks</li> </ul> </li> <li>Static code analysis using software tools</li> <li>Address Space Layout Randomization (ASLR) makes it harder for attackers to find important locations (e.g. libc function address)<ul> <li>ASLR can't prevent read-only attacks where the attacker already has an address</li> </ul> </li> </ul> <p>The function's stack frame stores:</p> <ul> <li>Return address</li> <li>Arguments</li> <li>Local variables (referenced as offset to EBP, eg. <code>EBP - 4</code>)</li> <li>Base pointer (EBP) for current stack frame</li> </ul> <p>The stack starts at higher memory addresses and \"grows down\" in memory (towards lower memory addresses). The heap starts at lower memory addresses \"grows upward\" (toward higher memory address). See Smashing The Stack For Fun And Profit (PDF).</p>"},{"location":"course-notes/iis/intro-information-security/#reading-x86","title":"Reading x86","text":"<p>The below lists can help you understand output from GNU Project Debugger (GDB) commands, such as <code>disassemble main</code>.</p> <p>x86 32 bit registers include:</p> <ul> <li>%eax: accumulators used for arithmetic, interrupt calls, and I/O operations</li> <li>%ebx: base register used to access memory, pass system call arguments, return values</li> <li>%ecx: counter register</li> <li>%edx: data register used for arithmetic, interrupt calls, I/O operations</li> <li>%ebp: base pointer containing the address of the current stack frame</li> <li>%eip: instruction pointer containing the address of the next instruction to be executed</li> <li>%esi: source index register, a pointer for string or array operations</li> <li>%esp: current stack pointer containing the address of the \"top\" of the stack</li> </ul> <p>x86 assembly language instructions include:</p> <ul> <li><code>MOV src, dest</code>: copy value from source into destination</li> <li><code>LEA src, dest</code>: copy address (load the address) of source into destination</li> <li><code>ADD</code>/<code>SUB</code>/<code>AND</code>/<code>OR</code>/<code>XOR</code> <code>src, dest</code>: perform the mathematical operation in source and leave the result in the destination</li> <li><code>CMP val1, val2</code>: compare the two values and set CPU flags as a result</li> <li><code>JMP addr</code>: jump to address</li> <li><code>PUSH src</code>: push source value onto stack</li> <li><code>POP dest</code>: pop value off the top of the stack into destination</li> <li><code>CALL addr</code>: call the function at address</li> <li><code>LEAVE</code>: clean up the stack frame before leaving function</li> <li><code>RET</code>: return from function correctly</li> <li><code>INT num</code>: software interrupt to access an OS function</li> <li><code>NOP</code>: no operation</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#authentication","title":"Authentication","text":"<p>Goals include:</p> <ul> <li>Availability<ul> <li>No false negatives -- if it's really me, I can get access</li> </ul> </li> <li>Authenticity<ul> <li>No false positives, meaning if it's not me but they guess my password, they get access</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#trusted-computing-base-tcb","title":"Trusted Computing Base (TCB)","text":"<p>The TCB needs to know who makes a request for a protected resource. The request comes from the process running on behalf of a user and contains claims about an identity and credentials to prove it.</p> <ul> <li>Protects access to physical resources</li> <li>Requires functional correctness</li> <li>Must maintain data integrity</li> <li>Protects disclosure of sensitive data in presence of untrusted software</li> <li>High assurance can be shown with formal proof</li> </ul> <p>TCB design principles include:</p> <ul> <li>Least privilege (damage containment)</li> <li>Economy of mechanism (simple and easy to analyze and test)</li> <li>Open design (avoid \"security by obscurity\" which is not a thing)</li> <li>Complete mediation (check every access and prevent bypass)</li> <li>Fail-safe defaults (deny by default)</li> <li>Ease of use (users avoid security that's a hassle)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#authentication-implementation","title":"Authentication Implementation","text":"<p>How can the user prove who they are?</p> <ul> <li>Password or personal identification number (PIN): something you know, e.g. passphrase</li> <li>Token: something you have, e.g. RFID keycards, physical keys</li> <li>Static biometrics: something you are, e.g. fingerprint, retina, face</li> <li>Dynamic biometrics: something you do, e.g. voice recognition, handwriting</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#passwords","title":"Passwords","text":"<ul> <li>Reactive password checking: a system runs its own password cracker to find and cancel guessable passwords (see John the Ripper)</li> <li>Proactive password checking or complex password policy: check to see if password is allowable at time of selection and offer guidance</li> </ul> <p>Passwords should be stored salted and hashed in a password file. (See SP 800-63B, 5.1.1.2 Memorized Secret Verifiers). Password salting:</p> <ul> <li>Prevents duplicate passwords from being visible in the password file</li> <li>Increases the difficulty of offline dictionary attacks</li> <li>Mitigates the risk of discovering whether a person uses the same password on more than one system</li> </ul> <p>Defenses against client attacks on authentication include:</p> <ul> <li>Choosing passwords or passphrases with high entropy</li> <li>Limiting attempts at password input</li> <li>Using physical tokens that would require theft</li> </ul> <p>Defenses against host attack on authentication include:</p> <ul> <li>Choosing passwords or passphrases with high entropy</li> <li>Protecting the password database</li> <li>Using one-time passwords (OTP)</li> <li>Using challenge-response protocols</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#assurance-requirements","title":"Assurance Requirements","text":"<p>Assurance levels help communicate an organization's confidence in their authentication. Levels range from L1 (relatively low) to L3 (relatively high). See NIST guidance for details in: SP 800-63-3, Selecting Assurance Levels.</p> <ul> <li>System analysis (architecture, integrity, testing)</li> <li>Design specification and verification (correctness of implementation, ideally formal verification)</li> <li>Covert channel analysis (identify possible means of bypass)</li> <li>Trusted facility management (roles, policies)</li> <li>Trusted recovery (operations after failures)</li> <li>Trusted distribution (protect against unauthorized modification along the chain)</li> <li>Configuration management</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#database-security","title":"Database Security","text":"<p>Threats to DB include:</p> <ul> <li>Insiders and unauthorized users</li> <li>Bevy of information all in one place means it's an attractive target</li> <li>Query languages can be abused to gain unauthorized access</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#access-control","title":"Access Control","text":"<p>For details on DAC, RBAC, and MAC, see SP 800-53 Rev. 5, AC-3 Access Enforcement.</p> <p>Enterprise-wide access control needs to manage resources, privileges, and policies.</p>"},{"location":"course-notes/iis/intro-information-security/#discretionary-access-control-dac","title":"Discretionary Access Control (DAC)","text":"<ul> <li>Based on the identity of the requestor (user)</li> <li>Describes the privileges a subject has (who can access what) based on the policy</li> <li>A subject may be able to grant access to objects to other subjects at their discretion</li> <li>Access control matrix (ACM): 2-D matrix database that stores access rights of users for objects<ul> <li>Rows are users (subjects) or groups</li> <li>Columns correspond to resources (objects) to be protected</li> <li><code>ACM [U,O]</code> defines what access rights <code>U</code>ser has for <code>O</code>bject</li> </ul> </li> <li>Access control list (ACL): the columns of an ACM describing how objects can be accessed<ul> <li>Column for object <code>Oi</code>: <code>[(ui1, rights1), (ui2, rights2), ...]</code></li> </ul> </li> <li>Capability list (C-list): the rows of an ACM describing capabilities (rights) of each user<ul> <li>For user <code>Ui</code>, row in the matrix is: <code>[(oi1, rights1), (oi2, rights2), ...]</code></li> <li>Rights are described by permissions, e.g. read, write, execute</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#role-based-access-control-rbac","title":"Role-based Access Control (RBAC)","text":"<ul> <li>Users have roles; roles grant certain rights as defined in policy</li> <li>Roles do not need to be changed frequently as users come and go</li> <li>If policy doesn't specify access for a user, fail safe and deny by default</li> <li>RBAC0 (minimum functionality), RBAC1 (adds role hierarchies for inheritance), RBAC2 (adds constraints for configuration, eg prerequisites, cardinality)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#mandatory-access-control-mac","title":"Mandatory Access Control (MAC)","text":"<ul> <li>Centrally-managed policies (company decides how data should be shared)</li> <li>Uses the comparison of security labels describing classification of objects and clearances of subjects</li> <li>Examples include Bell-LaPadula (DoD)<ul> <li>Read down, write up</li> </ul> </li> <li>...and Biba Integrity Model<ul> <li>Read up, write-down</li> </ul> </li> <li>Labels are totally ordered, sets are partially ordered<ul> <li>Succeeded sets are contained in the higher one, otherwise they're not comparable</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#comparing-labels","title":"Comparing labels","text":"<ul> <li> <p><code>L1</code> dominates <code>L2</code> if: <code>L1</code> &gt; <code>L2</code> AND <code>comp1</code> &gt; <code>comp2</code></p> <ul> <li>e.g. <code>L1 = (TS, {A,B,C})</code> and <code>L2 = (S, {A, B})</code></li> <li>levels are totally ordered and first set contains the second</li> </ul> </li> <li> <p><code>L2</code> dominates <code>L1</code> if: <code>L1</code> &lt; <code>L2</code> AND <code>comp1</code> &lt; <code>comp2</code></p> </li> <li> <p><code>L1</code> equals <code>L2</code> if: <code>L1</code> = <code>L2</code> AND <code>comp1</code> = <code>comp2</code></p> </li> <li> <p><code>L1</code> not comparable with <code>L2</code> if: <code>L1</code> not greater than and not less than and not equal to <code>L2</code></p> <ul> <li>probably because sets (partially ordered) aren't comparable</li> <li>e.g. <code>L3 = (S, {B,C,D})</code> is not comparable with L1 above; first set doesn't contain second</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#attribute-based-access-control-abac","title":"Attribute-Based Access Control (ABAC)","text":"<ul> <li>Access by subject (users) to objects (files, tables, programs, and networks), according to a preconfigured access control policy</li> <li>Policy rule base or policy store contains rules</li> <li>Access control compares attributes of the subject and object to rules and current environmental conditions to determine access</li> <li>Strength in expressive power</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#unix-file-access-control","title":"UNIX File Access Control","text":"<ul> <li>Permissions are: read, write, execute</li> <li>Classes are: owner, group, and other (world)</li> <li>Control checks occur when you try to open the file (<code>open()</code> executed by OS), not at read/write time<ul> <li>Granted access returns a file descriptor (<code>fd</code>), a pointer to a process' file table</li> </ul> </li> <li>The <code>setUID</code> bit temporarily allocates permissions for a file's owner to the executor</li> <li>Time-to-check-time-to-use-vulnerability (TOCTOU) arises when file permissions change after <code>open()</code> completes and before file is closed</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#virtual-machines-vm","title":"Virtual Machines (VM)","text":"<ul> <li>Full virtualization: multiple full OS instances execute in parallel on virtual hardware</li> <li>Hypervisor or virtual machine monitor (VMM): a trusted computing base (TCB) for VM that coordinates guest OS access to memory, storage, and CPU<ul> <li>Acts as API between hardware and OS</li> <li>Partitions and manages physical resources</li> </ul> </li> <li>Types of full virtualization systems:<ul> <li>Type 1 hypervisor: native<ul> <li>Software directly atop physical hardware</li> <li>Better security and performance</li> <li>Typically for servers</li> </ul> </li> <li>Type 2 hypervisor: hosted<ul> <li>Software atop host OS, atop physical hardware</li> <li>Typically for clients</li> </ul> </li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#malware","title":"Malware","text":"<ul> <li>May require a host software<ul> <li>Trap doors (e.g. flight simulator easter egg)</li> <li>Logic bomb (predefined condition)</li> <li>Trojan (keyloggers, phishing)</li> <li>Viruses (copies itself to spread)</li> </ul> </li> <li>...or be independent<ul> <li>Worms (spreads through network connections)</li> <li>Botnets</li> <li>Advanced persistent threats (APT)</li> </ul> </li> <li>Components include an infection mechanism, payload, and trigger</li> </ul> <p>Obfuscation can be achieved by packing: part or all of the file is compressed, encrypted or transformed.</p> <ul> <li>Defeats signature matching</li> <li>Unpacking code needs to be included</li> <li>Hard to detect since legitimate programs may also use packing</li> <li>Static and dynamic analysis can be combined to unpack and analyze malware</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#viruses","title":"Viruses","text":"<p>Viruses are inserted into a host program (virus sandwich). Detection can be avoided by compressing the host program code. Steps:</p> <ol> <li>Host program is run.</li> <li>Go to main of virus.</li> <li>Check flag to see if a previous infection is present, to avoid repeat.</li> <li>Find and infect uninfected programs.</li> <li>Execute arbitrary functionality.</li> <li>Go to first line of host program.</li> </ol> <p>Stages include:</p> <ul> <li>Dormant</li> <li>Propagation (spreading, e.g. via email)</li> <li>Triggered (host program runs)</li> <li>Executing (looking for new targets)</li> </ul> <p>Types include:</p> <ul> <li>Boot sector infector (when system is booted, before the OS)</li> <li>File infector (executable files)</li> <li>Macro virus (with macro, or scripting code)</li> <li>Multipartite virus (multiple types of files)</li> </ul> <p>Concealment classes include:</p> <ul> <li>Encrypted virus (encryption obscures content)</li> <li>Stealth virus (tries to hide from anti-virus)</li> <li>Polymorphic virus (changes its signature with every copy)</li> <li>Metamorphic (mutates with every infection, rewriting itself)</li> </ul> <p>Memory-resident viruses (rootkit)</p> <ul> <li>Rootkit resides at the OS level, modifies OS and data structure to hide itself from the user<ul> <li>Can filter itself from calls like <code>ls</code> by intercepting function calls</li> </ul> </li> <li>Classes include:<ul> <li>Persistent across boot (you can scan for these)</li> <li>Memory-based (doesn't survive reboot)</li> <li>User mode (hides via intercepted API calls)</li> <li>Kernel mode (changes system calls, can be fixed with a new OS installation)</li> <li>VM-based</li> <li>External mode (outside the normal operations with direct hardware access, e.g. BIOS or system management modes)</li> </ul> </li> </ul> <p>Antivirus includes:</p> <ul> <li>Simple scanners (signature-based)</li> <li>Heuristic scanners (compare integrity checksums)</li> <li>Activity traps (activity signatures, not effective against new behavior)</li> <li>Full-featured (combines host-based, network-based, and sandbox)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#botnet","title":"Botnet","text":"<ul> <li>Network of many \"zombie\" computers controlled by an attacker</li> <li>The bot code (malware) needs communication with attacker's servers for C&amp;C<ul> <li>C&amp;C goals are to not be easily detected or blend with normal traffic, be efficient and reliable, and be hard to block</li> </ul> </li> <li>Purposes include spamming, DDoS, key logging and ID theft, clickfraud, computation for password cracking, phishing, anonymized criminal communication, online games cheating</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#firewalls","title":"Firewalls","text":"<ul> <li>Active filtering, fails closed</li> <li>Prevention by enforcing defined policies</li> <li>Limited effectiveness:<ul> <li>Only filters what it sees (all traffic must pass through firewall)</li> <li>Must be immune to subversion (some malware can disable firewall)</li> <li>Can be misconfigured by hoomans</li> </ul> </li> <li>Advantages:<ul> <li>Simple, fast, transparent to user</li> <li>Provides insight to traffic via logging (not high-level though)</li> <li>Can do network address translation</li> <li>Can encrypt traffic</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#filtering","title":"Filtering","text":"<p>Two main types of filtering: packet and session.</p> <p>Packet filtering is applied per-packet.</p> <ul> <li>Typically configured to filter packets in both directions</li> <li>Applies rules based on policy (ACL)</li> <li>Applies rules based on packet's info, e.g. source IP, destination IP, transport-level address, IP protocol field, interface</li> <li>Rules must be precise to allow wanted traffic and block unwanted traffic, specifying:<ul> <li>Direction</li> <li>Source and destination addressesP</li> <li>Protocol</li> <li>Destination port</li> <li>Source port</li> </ul> </li> <li>Limitations:<ul> <li>Decisions are per-packet, not effective against attack over multiple packets</li> <li>See IP fragment attack</li> <li>No state info kept</li> </ul> </li> <li>Default policies<ul> <li>Discard: prohibit unless permitted (whitelist)</li> <li>Forward: permit unless prohibited (blacklist)<ul> <li>Easier to manage a blacklist, but less secure</li> </ul> </li> </ul> </li> </ul> <p>Session filtering filters a packet based on its context within a session.</p> <ul> <li>Includes Dynamic Packet Filtering and Stateful Inspection Firewall</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#stateful-inspection-firewall","title":"Stateful Inspection Firewall","text":"<ul> <li>Directory with entry for each established TCP connection (Connection State Table)</li> <li>Packet filter allows incoming traffic to high-numbered ports only for packets that fit the profile of a directory entry</li> <li>Reviews packet info, records info about TCP connections</li> <li>Keeps track of TCP sequence numbers to prevent attacks that depend on that sequence number</li> <li>Inspect data for protocols like FTP, IM, SIPS commands</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#application-level-gateway","title":"Application-Level Gateway","text":"<ul> <li>Application proxy</li> <li>Relay of app-level traffic</li> <li>Must implement proxy code for each application you want to support</li> <li>Can restrict application features as preferred</li> <li>More secure that packet filtering</li> <li>Additional processing overhead for each connection (vs other types of firewalls)</li> </ul> <p>Here's a typical workflow:</p> <ol> <li>User contacts the gateway via TCP/IP to make request of application</li> <li>Gateway requests name of remote host</li> <li>User supplies valid auth info to gateway</li> <li>Gateway contacts application and relays TCP segments</li> <li>If proxy code is not implemented, remote host reports to gateway that service is not supported</li> <li>Gateway forwards response to user</li> </ol>"},{"location":"course-notes/iis/intro-information-security/#bastion-hosts","title":"Bastion Hosts","text":"<ul> <li>Machine with an application-level gateway</li> <li>Critical strong point in network security</li> <li>Typically a secure OS with only essential services</li> <li>Requires authentication even from internal traffic to access proxy or host</li> <li>Limited disk use</li> <li>Each proxy is isolated and runs as a non-privileged user</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#host-based-firewalls","title":"Host-based Firewalls","text":"<ul> <li>Software module used to secure an individual host</li> <li>Filters and restricts traffic inbound and outbound</li> <li>Commonly on a server</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#personal-firewalls","title":"Personal Firewalls","text":"<ul> <li>Home routers, typically less complex than server/standalone firewalls</li> <li>Primarily denies unauthorized remote access</li> <li>May monitor outgoing traffic to detect and block worms and malware activity</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#firewall-deployment","title":"Firewall Deployment","text":"<p>External firewalls are between the Internet-connected router and the internal DMZ network, where email, web, and DNS servers live.</p> <p>Internal firewalls add additional separation between logical business areas of the internal network and provide two-way protection for the DMZ by monitoring incoming and outgoing (exfiltrated data, anyone?) traffic.</p> <p>Distributed firewall deployment may use stand-alone external, internal, host-based, and personal firewalls together to section servers logically. This helps with security monitoring and log aggregation.</p>"},{"location":"course-notes/iis/intro-information-security/#firewall-topologies","title":"Firewall Topologies","text":"<ul> <li>Host-resident firewall: personal firewall software, software on servers</li> <li>Screening router: single router between internal/external networks with stateless or full packet filtering</li> <li>Single bastion inline: single firewall device between internal and external router</li> <li>Single bastion T: third network interface on bastion to DMZ for external services</li> <li>Double bastion inline: DMZ sandwiched between bastion firewalls</li> <li>Double bastion T: DMZ on separate network interface on bastion firewall</li> <li>Distributed firewall configuration: see Firewall Deployment</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#intrusion-detection-systems-ids","title":"Intrusion Detection Systems (IDS)","text":"<p>A mechanism that detects evidence of an unwanted presence on the network.</p> <ul> <li>Good for known attack types, some sophisticated attacks</li> <li>Not good for 0-days or APT</li> <li>Alerts must be interpreted</li> </ul> <p>Assumes that:</p> <ul> <li>System activities can be observed</li> <li>It's possible to differentiate between normal and intrusive activities</li> </ul> <p>An IDS uses:</p> <ul> <li>Sensors, analyzers, and user interface to gather and analyze information from the computer or network to identify possible intrusion</li> <li>Passive monitoring (fails open)</li> <li>Signature-based detection or anomaly detection</li> </ul> <p>A host-based IDS (HIDS) is deployed on a single host.</p> <ul> <li>Monitors system activity, e.g. process identifiers and system calls</li> <li>Detects internal and external intrusions</li> </ul> <p>A network-based IDS (NIDS) monitors network traffic at selected points.</p> <ul> <li>Many sensors, one or more servers and management consoles</li> <li>Segments, devices, transport and application protocols</li> <li>Large networks may produce lots of alerts; prioritize these for ease of sysadmin</li> <li>Uses inline sensors...<ul> <li>Can block a detected attack (IPS)</li> </ul> </li> <li>...or passive sensors<ul> <li>Monitors a copy of network traffic, causing less overhead</li> </ul> </li> <li>Sensor deployment follows firewall deployment strategy</li> </ul> <p>A distributed or hybrid IDS combines multiple sensors in a central analyzer for a more holistic view.</p> <ul> <li>Coordinates many NIDS</li> <li>May have one or more collection and analysis points on the network</li> <li>Uses raw data or summary data</li> <li>May deal with different sensor data formats</li> </ul> <p>Workflow looks like this:</p> <ul> <li>Network/system data goes through data preprocessing<ul> <li>Generates activity records</li> </ul> </li> <li>Detection engine uses detection models to examine activities<ul> <li>Produces alerts</li> </ul> </li> <li>Decision engine uses decision table to produce responses/reports</li> </ul> <p>Deployment strategies include:</p> <ul> <li>Between external network and Internet<ul> <li>Sees all attempted attacks targeting tne network</li> <li>Nothing filtered by a firewall</li> </ul> </li> <li>Just inside external firewall<ul> <li>Can catch any traffic that should have been blocked by firewall</li> <li>Can analyze outgoing network traffic</li> </ul> </li> <li>In front of a subnet or server group<ul> <li>Smaller traffic volume for ease of analysis</li> <li>Can better locate intrusions from inside network</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#signature-detection","title":"Signature Detection","text":"<ul> <li>Matches known patterns to detect malicious traffic</li> <li>Cannot detect new threats, only known ones</li> <li>New signatures need to be added to database</li> <li>Antivirus, NIDS</li> <li>Advantages:<ul> <li>Low cost and resource usage</li> </ul> </li> <li>Disadvantages:<ul> <li>Effort to identify, review, create new malware signatures</li> <li>Inability to detect 0-day attacks</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#anomaly-detection-approaches","title":"Anomaly Detection Approaches","text":"<p>Statistical approach uses univariate, multivariate, or time-series models of observed metrics.</p> <ul> <li>Multivariate: metrics considered by correlations</li> <li>Univariate: each metric treated as an independent random variable</li> <li>Time-series: considers time and order of events</li> <li>Advantages:<ul> <li>Relatively simple</li> <li>Low computational cost</li> <li>Lack of assumptions about expected behavior</li> </ul> </li> <li>Disadvantages:<ul> <li>Must select suitable metrics</li> <li>Cannot model all behaviors</li> </ul> </li> </ul> <p>Knowledge-based approach uses an expert system (knowledgeable experts write classification rules) to define normal parameters.</p> <ul> <li>E.g. \"office programs are typically used between 9-5.\"</li> <li>Advantages:<ul> <li>Easy to update</li> <li>Flexible rules</li> </ul> </li> <li>Disadvantages:<ul> <li>Must trust the experts</li> <li>Time and effort is required to develop knowledge from data</li> </ul> </li> </ul> <p>Machine learning uses data to train and develop a model to automatically classify behaviors.</p> <ul> <li>Will detect attacks that are similar to past attacks, possibly 0-days</li> <li>Advantages:<ul> <li>Adaptable, can handle small changes automatically</li> <li>Captures interdependencies between observable metrics</li> </ul> </li> <li>Disadvantages:<ul> <li>Depends on good training data</li> <li>High false positives</li> <li>High resource cost in the training phase</li> </ul> </li> </ul> <p>Machine learning approaches include:</p> <ul> <li>Bayesian networks: probabilistic relationships</li> <li>Markov models: model with a set of states</li> <li>Neural networks: simulates the brain to classify data</li> <li>Fuzzy logic: fuzzy set theory, approximation</li> <li>Genetic algorithms: inheritance, mutation, selection, recombination</li> <li>Clustering and outlier detection</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#heuristic-or-rules-based-detection","title":"Heuristic or Rules-Based Detection","text":"<ul> <li>Uses rules to identify known patterns of behavior for penetrations</li> <li>Tends to be specific to the machine or OS</li> <li>Example: SNORT is a rule-based NIDS that uses a rule header and options<ul> <li>Actions are: alert, log, pass, activate, dynamic, drop, reject, sdrop</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#detection-accuracy","title":"Detection Accuracy","text":"<p>For overview, see Classification: True vs. False and Positive vs. Negative.</p> <p>For formulas, see Sensitivity and specificity.</p> <ul> <li>Detection rate or True Positive (TP) rate: when there is an intrusion, the likelihood that the IDS will correctly output an alert</li> <li>False Negative Rate: how many intrusions were missed (<code>FN = - TP</code>)</li> <li>False alarm or False Positive (FP) rate: without an intrusion, likelihood that the IDS will falsely produce an alert</li> <li>True Negative Rate: how likely normal activities are correctly classified as normal (<code>TN = 1 - FP</code>)</li> <li>Bayesian detection rate: given that alert was produced, how likely is it that an intrusion occurred<ul> <li>See Bayesian based intrusion detection system</li> </ul> </li> </ul> <p>The base rate fallacy says that people tend to ignore an established base rate in the face of individual information. See base rate fallacy for interesting general applicability.</p> <ul> <li>Base rate: prior probability of attacks (<code>P(I)</code>)</li> <li>Base rate depends on where it is measured</li> </ul> <p>At the network packet level, data volume is huge and base rate is low, so the base rate fallacy tells us that applying analysis here can result in a low Bayesian detection rate.</p> <ul> <li>Instead, apply detection algorithms to data that has a higher base rate<ul> <li>Process event data by selection, filtering, and summarizing</li> <li>Use a filtered packet stream (libpcap, tcpdump filters)</li> <li>This decreases volume of data</li> </ul> </li> <li>Higher base rate, thus higher Bayesian detection rate, is desired</li> <li>A low false alarm rate, as close to zero as possible, is desired</li> </ul> <p>As long as intrusion evidence is kept, decreasing the volume of overall packets produces a much higher base rate than the original packet data.</p>"},{"location":"course-notes/iis/intro-information-security/#attacking-ids","title":"Attacking IDS","text":"<p>Evasion techniques can allow attackers to bypass an IDS.</p> <ul> <li>IDS monitoring is passive, so traffic may still reach its destination while an ongoing attack is analyzed</li> <li>Different operating systems and ambiguities in TCP/IP protocol implementations can be exploited, e.g. if the IDS runs on Linux and the target is Windows</li> <li>Overlapping (malicious) packet fragments may be discarded by an IDS while the end host accepts them</li> </ul> <p>Insertion attacks can use bad checksums to disguise malicious traffic. The IDS will accept a packet with a bad checksum, which disrupts the overall attack pattern, but the end host will reject the bad packet, which reconstructs the attack.</p> <p>DoS attacks can cause resource exhaustion and disrupt IDS:</p> <ul> <li>Large traffic results in resource exhaustion and can keep the IDS busy while another attack slips by</li> <li>A reactive IDS can be abused by causing it to create an overwhelming number of alerts that humans have to deal with (DoS on humans)</li> </ul> <p>See more at Intrusion detection system evasion techniques.</p>"},{"location":"course-notes/iis/intro-information-security/#intrusion-prevention-systems-ips","title":"Intrusion Prevention Systems (IPS)","text":"<p>It's an IDS that also tries to block malicious activity.</p>"},{"location":"course-notes/iis/intro-information-security/#honeypots","title":"Honeypots","text":"<ul> <li>Decoy systems with fabricated information designed to catch illegitimate access</li> <li>Logs information about attacker's activities</li> </ul> <p>Low-interaction honeypots mimic services or systems without implementing a full version of the system. They're a low resource operation but won't fool an attacker too long.</p> <p>High-interaction honeypots are a real, full OS or service. They're instrumented and provide a more realistic target for attackers, but require more resources to run.</p> <p>Deployment strategies include:</p> <ul> <li>Outside external firewall<ul> <li>No increase to risk for internal network</li> <li>Can reduce alerts issued from firewall</li> <li>Cannot trap internal attackers</li> </ul> </li> <li>In DMZ<ul> <li>Attempted attacks may be blocked by firewall</li> </ul> </li> <li>In internal network<ul> <li>Can detect firewall misconfiguration</li> <li>If compromised, can attack internal systems</li> <li>Firewall has to allow traffic to internal network</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#cryptography","title":"Cryptography","text":"<p>Auguste Kerckhoffs's principle: A cryptosystem should be secure even if everything about the system, except the key, is public knowledge.</p> <p>In other words, \"security by obscurity\" is not a thing.</p>"},{"location":"course-notes/iis/intro-information-security/#encryption","title":"Encryption","text":"<p>The most often used cryptographic operation, encryption converts plaintext data to ciphertext that is unintelligible to a third-party. It provides:</p> <ul> <li>One-to-one mapping of plaintext to ciphertext (ensure that the message can always be decrypted)</li> <li>Confidentiality</li> <li>Integrity checking (assurance that message was not tampered with)</li> <li>Authenticity and authentication (the message is genuinely sent from the sender)</li> </ul> <p>Encryption can be symmetric or asymmetric.</p> <p>Attacks on encryption include:</p> <ul> <li>Brute-force attack (iteratively trying all possible keys)</li> <li>Cryptanalysis (of cipher's data characteristics)</li> <li>Attacks on implementation, e.g. side channel</li> <li>Social engineering, see $5 wrench.</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#decryption","title":"Decryption","text":"<p>The process of converting the ciphertext back to plaintext. Requires the decryption key.</p>"},{"location":"course-notes/iis/intro-information-security/#ciphers","title":"Ciphers","text":"<p>An encryption scheme. Simple cipher examples: see Caesar Cipher or shift cipher. Or for fun, see A Unicode substitution cipher algorithm.</p> <p>A fixed-shift cipher has only 26 possible encodings (for alphabetical letters) and can be trivially brute-forced. A monoalphabetic or substitution cipher that arbitrarily maps letters will have 26! or (~2\u2078\u2078) possible keys.</p> <p>Substitution ciphers can be defeated by analyzing statistical frequencies of letters. See letter frequency.</p> <p>Vigen\u00e8re cipher uses a matrix to map letters (polyalphabetic substitution).</p>"},{"location":"course-notes/iis/intro-information-security/#symmetric-vs-asymmetric","title":"Symmetric vs. Asymmetric","text":"<p>When 4 people want to talk, they need:</p> <ul> <li>6 individual keys for symmetric encryption \u2327</li> <li>4 key pairs for asymmetric encryption (8 total keys: 4 private, 4 public)</li> </ul> <p>Asymmetric is better for:</p> <ul> <li>Securely distributing a session key, e.g. TLS</li> <li>Scalability (you need fewer key pairs)</li> </ul> <p>Symmetric is better for:</p> <ul> <li>Confidentiality with speed (asymmetric is slower)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#symmetric-cryptography","title":"Symmetric Cryptography","text":"<p>Uses a single shared secret key for encryption and decryption.</p> <p>Symmetric encryption components:</p> <ul> <li>Plaintext and ciphertext</li> <li>Encryption algorithm</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#symmetric-cipher-attacks","title":"Symmetric Cipher Attacks","text":"<p>Known-plaintext attacks: a specific known plaintext is compared to its ciphertext to the determine key.</p> <p>Chosen-plaintext attacks: Any known plaintext compare to its ciphertext.</p> <p>Differential cryptanalysis: analyze (compare) effect of changes to the known plaintext on the resulting ciphertext.</p> <p>Linear cryptanalysis: determine the encryption function by analyzing (modeling) known plaintexts and their ciphertext using linear equations and derive the key bits.</p>"},{"location":"course-notes/iis/intro-information-security/#asymmetric-cryptography","title":"Asymmetric Cryptography","text":"<p>Also \"public key cryptography.\" Uses a key pair (two mathematically-paired keys): a public key for encryption and verification, and a private key for decryption and signing.</p> <p>Principle components include:</p> <ul> <li>A public and private key pair</li> <li>Encryption and decryption algorithms (cipher suite)</li> <li>Plaintext and ciphertext</li> </ul> <p>Public key algorithms include:</p> <ul> <li>RSA (see RSA)</li> <li>Diffie-Hellman key exchange: one of the first public-key protocols and uses asymmetric encryption to enable two users to agree on a shared secret key for subsequent symmetric encryption exchange</li> <li>Digital Signature Standard (DSS): a Federal Information Processing Standard (FIPS) specifying a suite of cryptographic algorithms including Digital Signature Algorithm (DSA).<ul> <li>Only for signing</li> </ul> </li> <li>Elliptic-Curve Cryptography (ECC): meant to improve on RSA; see Elliptic Curve Cryptography<ul> <li>Equal security to RSA with a smaller bit size</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#public-key-certificate-digital-signatures","title":"Public Key Certificate (Digital Signatures)","text":"<p>A Certificate Authority (CA) vouches for the validity of the public key:</p> <ol> <li>Key holder provides public key and identifying information to the CA</li> <li>CA combines indentifying information and public key with certificate information (e.g. validity period), and hashes it</li> <li>CA signs the resulting certificate block with its own private key (vouching for authenticity)</li> </ol> <p>When you provide your public key certificate to someone, they can verify it's valid:</p> <ol> <li>Extracting and calculating the hash code of the certificate</li> <li>Verify the digital signature using the CA's public key and the signature verification algorithm</li> </ol> <p>Relies on trust in CA: see DigiNotar.</p>"},{"location":"course-notes/iis/intro-information-security/#digital-envelopes","title":"Digital Envelopes","text":"<p>Uses public key encryption to send a \"sealed letter.\"</p> <p>A message is encrypted with a shared key. The shared key is then encrypted with someone's public key. Only the intended recipient (who holds the private key) can use the shared key to decrypt the message.</p>"},{"location":"course-notes/iis/intro-information-security/#block-cipher","title":"Block Cipher","text":"<p>The most common symmetric encryption algorithm, a block cipher takes plaintext input in fixed-size blocks and produces an equally-sized block of ciphertext.</p> <p>The algorithm need not be secret and is encouraged to be public, so others can verify it.</p> <p>Primitives include:</p> <ul> <li>Confusion: substitution is used to obscure the relationship between the key and ciphertext</li> <li>Diffusion: permutation is used to spread the influence of one plaintext bit over many ciphertext bits and hide the statistical properties of the plaintext</li> <li>Round: a combination of substitution and permutation<ul> <li>Many rounds increase security by propagating changes throughout the ciphertext</li> </ul> </li> </ul> <p>Comparisons of block cipher sizes:</p> Thing DES size (bits) Triple DES size (bits) AES size (bits) Plaintext block size 64 64 128 Ciphertext block size 64 64 128 Key size 56 112 or 168 128, 192, or 256 <p>A longer key length means more keys, and is harder to brute-force.</p>"},{"location":"course-notes/iis/intro-information-security/#des","title":"DES","text":"<p>Symmetric key block cipher algorithm, Feistel and IBM, 1977</p> <ul> <li>64 bit key (8 bytes) with one parity bit for each byte; effective key length is only 56 bits</li> <li>Outputs a 64 bit block ciphertext</li> </ul> <p>There are 16 DES rounds:</p> <ul> <li>Each round's input is the ciphertext produced by the previous round</li> <li>Encryption rounds use K1...K16, decryption uses K16...K1</li> <li>Implementation of a Feistel cipher, using [F-function]](https://en.wikipedia.org/wiki/Data_Encryption_Standard#The_Feistel_(F)_function) with the four stages:<ul> <li>Expansion: use expansion permutation (E-expansion) to duplicate half the bits</li> <li>Key mixing: XOR the result with subkey (derived from main key using key schedule)</li> <li>Substitution: processing by substitution boxes (S-boxes), one of 8 predefined tables -- this is the core of DES security<ul> <li>Given a six bit value <code>011011</code>, the outer two bits (<code>0</code> and <code>1</code>) represent the rows and the inner four (<code>1101</code>) the columns</li> </ul> </li> <li>Permutation: rearrange the 32 outputs according to fixed permutation (P-box)</li> </ul> </li> </ul> <p>How to XOR, or \"same-same zero, different is one\":</p> <ul> <li><code>0 XOR 0 = 0</code></li> <li><code>1 XOR 1 = 0</code></li> <li><code>0 XOR 1 = 1</code></li> <li><code>1 XOR 0 = 1</code></li> </ul> <p>DES isn't the most secure anymore:</p> <ul> <li>2\u2075\u2076 keys is too small a keyspace</li> <li>S-box design criteria is secret, although still shown to be resistant to attacks</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#triple-des","title":"Triple DES","text":"<p>It's DES run three times with three different keys to overcome the small key space. Effective key lengths are 56, 112, or 168.</p> <p>Triple DES is vulnerable to collision attacks.</p>"},{"location":"course-notes/iis/intro-information-security/#aes","title":"AES","text":"<p>Symmetric key block cipher algorithm, NIST, 2001</p> <p>A subset of the Rijndael block cipher, more efficient than Triple DES. AES replaces DES.</p> <ul> <li>Variant of Rijndael, not a Feistel structure</li> <li>Fixed block size of 128 bits</li> <li>Entire block processed in parallel during each round</li> <li>Substitution and permutation</li> <li>Key length can be 128, 192, or 256 bit (effectively defeats brute forcing at time of writing)</li> </ul> <p>AES rounds differ with key length:</p> <ul> <li>10 rounds for 128-bit keys</li> <li>12 rounds for 192-bit keys</li> <li>14 rounds for 256-bit keys</li> </ul> <p><code>KeyExpansion</code>: round keys are derived from the cipher key using the AES key schedule</p> <p>The algorithm steps are:</p> <ol> <li>To begin, <code>AddRoundKey</code>: bitwise XOR combines each byte of the state with a byte of the round key</li> <li>For 9, 11, or 13 rounds:<ol> <li><code>SubBytes</code>: substitution step replaces each byte according to lookup table<ul> <li>Uses a 16x16 matrix (S-box) with permutation of all possible 256 8-bit values</li> <li>Left 4 bits are the row value, right 4 bits are the column value for indexing</li> <li>S-box is designed to have a low correlation between input bits and output bits</li> </ul> </li> <li><code>ShiftRows</code>: transposition of last three rows of the state, cyclically shifted some number of steps (diffusion)<ul> <li>A circular left shift is performed starting with 1 byte at the second row, 2 bytes at the third row, then 3 bytes at the fourth row.</li> </ul> </li> <li><code>MixColumns</code>: linear mixing operation combines four bytes in each column of the state (diffusion)<ul> <li>The four bytes of each column are combined using an invertible linear transformation (matrix multiplication)</li> </ul> </li> <li><code>AddRoundKey</code> again</li> </ol> </li> <li>Final round:<ol> <li><code>SubBytes</code></li> <li><code>ShiftRows</code></li> <li><code>AddRoundKey</code></li> </ol> </li> </ol> <p>Each operation in AES is reversible, which is how AES is decrypted.</p> <p>Theoretical attacks include:</p> <ul> <li>XSL attack</li> <li>Side-channel attack</li> <li>Related-key attack</li> <li>Known-key distinguishing attack</li> <li>Key-recovery attack</li> </ul> <p>At time of writing there are no known feasible attacks that would break AES.</p>"},{"location":"course-notes/iis/intro-information-security/#rsa-rivest-shamir-adleman","title":"RSA (Rivest, Shamir, Adleman)","text":"<p>A block cipher that depends on the difficulty of factoring a large integer (\ud835\udc8f) into two primes (p and q). The plaintext M and ciphertext C are integers between 0 and \ud835\udc8f-1 for some \ud835\udc8f.</p> <p>Two prime numbers, p and q, are chosen (using RNG). They must be different and sufficiently large and random. Their product \ud835\udc8f is used to generate public and private keys.</p> <ul> <li>The public key is {\ud835\udc86,\ud835\udc8f}</li> <li>The private key is {\ud835\udc85,\ud835\udc8f}</li> <li>The relationship between \ud835\udc86 and \ud835\udc85 is: \ud835\udc85\ud835\udc86 mod \u03c6(\ud835\udc8f) = 1<ul> <li>\u03c6(\ud835\udc8f) = (p\u22121)(q\u22121)</li> </ul> </li> <li>\ud835\udc86 and \ud835\udc85 are multiplicative inverses modulo \u03c6(\ud835\udc8f) (the Euler totient function)</li> <li>The key \ud835\udc85 can be found with modular multiplicative inverse: \ud835\udc85 \u2261 \ud835\udc86\u207b\u00b9(mod \u03c6(\ud835\udc8f))</li> </ul> <p>The message M is independent of the values for p and q, allowing any message to be encrypted using the same public-private key pair. The values p and q are independent of the exponent \ud835\udc86.</p> <p>Approaches to attacking RSA include:</p> <ul> <li>Brute force (try all private keys)</li> <li>Mathematical attacks<ul> <li>Factoring \ud835\udc8f into p and q</li> <li>Determining \u03c6(\ud835\udc8f) (without finding p and q)</li> <li>Determining \ud835\udc85 without determining \u03c6(\ud835\udc8f)</li> </ul> </li> <li>Timing attacks (using the running time of the decryption algorithm)</li> <li>Chosen ciphertext attacks</li> </ul> <p>RSA is susceptible to these when the key space is insufficiently small.</p>"},{"location":"course-notes/iis/intro-information-security/#block-cipher-modes","title":"Block Cipher Modes","text":"<p>A block cipher mode of operation uses a block cipher to provide confidentiality or authenticity. The idea is to repeatedly apply a cipher's single-block operation to transform data larger than a single block.</p> <p>Authenticated Encryption (AE) protects confidentiality and integrity of communications simultaneously, and can provide security against chosen ciphertext attacks. AE is implemented using a block cipher mode structure.</p> <p>Block cipher modes defined in NIST SP 800-38A are:</p> <ul> <li>Electronic Codebook (ECB)</li> <li>Cipher Block Chaining (CBC)</li> <li>Cipher Feedback (CFB)</li> <li>Output Feedback (OFB)</li> <li>Counter (CTR)</li> </ul> Mode Description Typically used in ECB Each block of 64 bits independently encrypted using the same key Transmission of single values, e.g. encryption key CBC Input to the encryption algorithm is the XOR of the next 64 bits of plaintext and the preceding 64 bits of ciphertext Block-oriented transmission, authentication CFB Input processed s bits at a time using preceding ciphertext as input to produce pseudorandom output. Output XORed with plaintext to produce next ciphertext unit Stream-oriented transmission, authentication OFB Like CFB, but input is the preceding DES output Stream-oriented transmission on noisy channels, e.g. satellite communication) CTR Each block of plaintext is XORed with an encrypted counter, incremented for each subsequent block Block-oriented transmission, high-speed requirements"},{"location":"course-notes/iis/intro-information-security/#electronic-codebook-ecb","title":"Electronic Codebook (ECB)","text":"<p>ECB is the simplest confidentiality mode.</p> <p>Issues abound:</p> <ul> <li>ECB has weak confidentiality: the same plaintext block produces the same ciphertext block, which makes it vulnerable to analysis because it does not hide patterns well</li> <li>ECB has weak integrity: plaintext blocks are encrypted independently, making them vulnerable to cipher block substitution and rearrangement attacks</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#cipher-block-chaining-cbc","title":"Cipher Block Chaining (CBC)","text":"<p>More secure than ECB, this is the most widely used approach for encrypting large messages.</p> <p>The IV is XORed with the first plaintext block to produce the first ciphertext. Subsequent blocks are XORed with the resulting ciphertext from the previous block. This makes CBC more resistant to cryptanalysis.</p> <p>CBC maintains integrity since, if the order of blocks are changed, it will not be properly decrypted. Both parties need the IV to decrypt the ciphertext.</p> <p>The last block of CBC is the CBC residue and can be sent as a measure of protecting message integrity. Modification of the plaintext means that the CBC residue computed by the receiver will differ from the CBC residue from the sender.</p> <p>To have both confidentiality and integrity with CBC, two separate keys should be used to do encryption and generate residue. Alternatively, compute a hash of the message then append and encrypt it together.</p> <p>Some helpful formulas:</p> Mode Formula Ciphertext ECB <code>Y\u1d62 = F(PlainText\u1d62, Key)</code> <code>Y\u1d62</code> CBC <code>Y\u1d62 = PlainText\u1d62 XOR Ciphertext\u1d62\u208b\u2081</code> <code>F(Y, Key); Ciphertext\u2080 = IV</code> CFB <code>Y\u1d62 = Ciphertext\u1d62\u208b\u2081</code> <code>Plaintext XOR F(Y, Key); Ciphertext\u2080 = IV</code>"},{"location":"course-notes/iis/intro-information-security/#stream-cipher","title":"Stream Cipher","text":"<p>A stream cipher converts a plaintext message to ciphertext bit-by-bit.</p>"},{"location":"course-notes/iis/intro-information-security/#rc4","title":"RC4","text":"<p>Variable-key-size stream cipher, Ron Rivest and RSA Security, 1987</p> <p>Based on the use of a random permutation, RC4 generates a pseudorandom keystream (stream of bits). It was used in SSL/TLS, WEP, WPA, until prohibited for all versions of TLS by RFC 7465 in 2015.</p> <p>The permutation is initialized using the key-scheduling algorithm (KSA):</p> <ol> <li>A 256-byte state vector, S, is initialized from a variable length key of 1-256 bytes (8 to 2048 bits)<ul> <li>Initially the entries of S are 0-255 (S[0]... S[255])</li> <li>If the private key, K, is 256 bytes, a temporary vector T holds K; otherwise, the bytes of K are repeated to fill up T</li> </ul> </li> <li>T is used to produce the initial permutation of S<ul> <li>For each byte in S (S[\u1d62]), we swap with another byte S[j] according to the scheme dictated by T</li> </ul> </li> </ol> <p>A keystream is generated using the pseudo-random generation algorithm (PRGA). For each iteration i:</p> <ol> <li>The i element of S, S[i], is added to j</li> <li>Exchange the values of S[i] and S[j] then use the sum S[i] + S[j] (modulo 256) as an index to fetch a third element of S, the keystream value K</li> <li>Do bitwise XOR with the next byte of the message to produce the next byte of either ciphertext or plaintext</li> </ol> <p>Encryption is performed by XOR-ing each byte of K with the next byte of the plaintext. Decryption is by XOR-ing each byte of K with the next byte of ciphertext.</p> <p>RC4 is vulnerable:</p> <ul> <li>Fluhrer, Mantin and Shamir attack broke the WEP standard when they found RC4 to be vulnerable due to the first few bytes of the output keystream being strongly non-random</li> <li>Andreas Klien showed more correlations between the RC4 keystream and key in Klien's attack, which lead to Erik Tews, Ralf-Philipp Weinmann, and Andrei Pychkine cracking 128-bit WEP in under a minute</li> <li>Bit-flipping attack is possible if RC4 is not used with a strong message authentication code (MAC)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#modular-math","title":"Modular Math","text":"<p>Concepts to review:</p> <ul> <li>Modular multiplication</li> <li>Modular exponentiation</li> <li>Multiplicative inverse</li> <li>Euclidean algorithm and B\u00e9zout's identity</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#hash-function","title":"Hash Function","text":"<p>Cryptographic algorithm that:</p> <ul> <li>Takes a message digest (data) input of any size and produces a fixed-length output<ul> <li>Output is typically 128-512 bits</li> </ul> </li> <li>Efficient on computational resources (fast to compute)</li> <li>Is a one-way function (cannot be reversed to find the original input)</li> </ul> <p>Hash functions are useful for message authentication, password security, and intrusion detection.</p> <p>Hash functions should have collision resistance, which means that it is not desirable for different inputs to produce the same output.</p> <p>Weak collision resistance: bound to a particular message <code>m</code>, it's computationally infeasible to find <code>m'</code> with <code>m' != m</code> so that <code>h(m) = h(m')</code>.</p> <p>Strong collision resistance: given any arbitrary message <code>x</code>, there exists no <code>x</code> and <code>x'</code> with <code>x != x'</code> so that <code>h(x) = h(x')</code>. This automatically satisfies weak collision resistance.</p> <p>See What is the difference between weak and strong resistance.</p> <p>Hash function weaknesses include:</p> <ul> <li>Pigeonhole principle: <code>n = m</code><ul> <li>One pigeon (n) per hole (m)</li> <li>If <code>n &gt; m</code> then at least one hole has more than one pigeon</li> </ul> </li> <li>Birthday paradox: how many people do you need to put in a room until you have a greater than 50% chance that two of them will have the same birthday?<ul> <li>For 100% chance that two people in the room have the same birthday, you need 367 people (leap years)</li> <li>For less than 100%, computed as <code>P(A) = 1 \u2212 P(A\u2032)</code></li> <li>Probability that a pair share the same birthday: <code>1-(k)\u2099/k\u207f</code></li> <li>See Birthday problem</li> </ul> </li> </ul> <p>How long of a hash value do we need to avoid collisions?</p> Hash length Possible number of hash values Number of messages for collision l 2\u00b9 2\u00b9/\u00b2 64 2\u2076\u2074 2\u00b3\u00b2"},{"location":"course-notes/iis/intro-information-security/#secure-hash-algorithm-sha","title":"Secure Hash Algorithm (SHA)","text":"<ul> <li>SHA-1: 1995 FIPS 180-1, from National Security Agency (NSA) in DSA -- insecure as of 2010</li> <li>SHA-2: 2002 FIPS 180-2, encompasses:<ul> <li>SHA-256</li> <li>SHA-384</li> <li>SHA-512</li> </ul> </li> <li>SHA-3: 2015 FIPS 202 -- compact and useful for embedded devices</li> </ul> <p>Message digest generation (SHA-512) follows these steps:</p> <ol> <li>Message is (always) padded (<code>100...0</code> appended to last block) so it is a multiple of 1024 bits</li> <li>A 128-bit block is appended (unsigned 128-bit integer containing pre-padded length of original message)</li> <li>512-bit hash buffer is initialized to hold intermediate and final results</li> <li>Registers initialized to the hard-coded IV</li> <li>Message processed in 1024-bit (128-words) blocks:</li> <li>Each block has 80 rounds</li> <li>First block is processed with IV, giving hash buffer the first intermediate value</li> <li>Each round takes as input the previous intermediate value, a constant (k), and some words from the previous block</li> <li>Operations include circular shifts, primitive pulling functions (and, or, not, XOR)</li> <li>After all N blocks are processed, the output is the 512-bit message digest</li> </ol>"},{"location":"course-notes/iis/intro-information-security/#sha-numbers-table","title":"SHA Numbers Table","text":"Variant Message digest size Message size Block size Word size Rounds SHA-1 160-bit &lt;2\u2076\u2074 512 32-byte words 80 SHA-256 256 bits &lt;2\u2076\u2074 512 32-byte words 64 SHA-384 384 bits &lt;2\u00b9\u00b2\u2078 1024 64-byte words 80 SHA-512 512 bits &lt;2\u00b9\u00b2\u2078 1024 64-byte words 80"},{"location":"course-notes/iis/intro-information-security/#hash-based-message-authentication-hmac","title":"Hash Based Message Authentication (HMAC)","text":"<p>Hash functions are suitable for message authentication because:</p> <ul> <li>They are fast to compute compared to encryption algorithms (DES)</li> <li>Library code is widely available</li> </ul> <p>To use a hash algorithm for message authentication, we need to incorporate use of a secret key. Enter HMAC, RFC 2104.</p> <p>HMAC makes modular use of the hash function. A new hash function could easily be used instead, if so desired one day.</p> <p>The HMAC process goes like this:</p> <ol> <li>Secret key K is padded with zeroes so it is the same length as the number of bits in a block, b<ul> <li>E.g. if this HMAC uses SHA-512, K is padded to make it 1024 bits (see SHA numbers table)</li> </ul> </li> <li>XOR the padded key K\u207a with ipad, producing S\u1d62</li> <li>Append the message M to S\u1d62, producing the stream for step 3</li> <li>Apply the embedded hash function H to the stream from step 3</li> <li>XOR the padded key K\u207a with opad to produce S\u2080</li> <li>Append the hash result from step 4 to S\u2080, producing the stream for step 6</li> <li>Apply the embedded hash function H to the stream from step 6</li> <li>Output the result</li> </ol> <p>Not Apple devices:</p> <ul> <li>ipad: 36 in hexadecimal (00110110), repeated b/8 times</li> <li>opad: 5C in hexadecimal (01011100), repeated b/8 times</li> </ul> <p>HMAC security:</p> <ul> <li>Depends on the cryptographic strength of the embedded one-way hash function</li> <li>Makes it harder to find collisions (compared to the underlying hash function) due to the use of the secret key<ul> <li>This means HMAC cannot be attacked by generating message/code pairs for the underlying hash function offline because attacker does not know the secret key</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#diffie-hellman-key-exchange","title":"Diffie-Hellman Key Exchange","text":"<ul> <li>Allows two people to exchange a secret value, with math</li> <li>Relies on the infeasibility of computing discrete logarithms</li> </ul> <p>See cryptographic explanation:</p> <ol> <li>Alice and Bob publicly agree to use a public prime modulus p = 23 and public prime base g = 5 (which is a primitive root modulo 23).</li> <li>Alice chooses a secret integer (private key) a = 4, then sends Bob her public key A = g\u1d43 mod p<ul> <li>A = 5\u2074 mod 23 = 4</li> </ul> </li> <li>Bob chooses a secret integer (private key) b = 3, then sends Alice his public key B = g\u1d47 mod p<ul> <li>B = 5\u00b3 mod 23 = 10</li> </ul> </li> <li>Alice computes s = B\u1d43 mod p<ul> <li>s = 10\u2074 mod 23 = 18</li> </ul> </li> <li>Bob computes s = A\u1d47 mod p<ul> <li>s = 4\u00b3 mod 23 = 18</li> </ul> </li> <li>Alice and Bob now share a secret (the number 18).</li> </ol> <p>Limitations of Diffie-Hellmain include:</p> <ul> <li>Only used for key exchange</li> <li>It involves expensive exponential operations, so DoS is possible by requesting multiple sessions</li> <li>Susceptible to MitM attack if there is no authentication of the participants (fix this by signing the messages, digital signatures, public key certificates)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#security-protocols","title":"Security Protocols","text":"<p>A protocol defines rules and conventions, in other words, \"the way we do things around here.\"</p> <p>Secure communication involves:</p> <ul> <li>Mutual authentication</li> <li>Establishing and exchanging keys</li> <li>Agreeing on which cipher suite to use</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#mutual-authentication","title":"Mutual Authentication","text":"<p>Alice and Bob share a key.</p> <ol> <li>Alice claims she's Alice</li> <li>Bob sends a challenge value, R1</li> <li>Alice encrypts the challenge value using their shared key and sends it back</li> <li>Bob decrypts Alice's response and sees if it matches R1</li> <li>Bob says, OK Alice.</li> <li>Alice sends a challenge value, R2</li> <li>Bob encrypts R2 with the shared key and sends it back to Alice</li> <li>Alice decrypts the response and sees if it matches R2</li> <li>Alice says, OK Bob.</li> </ol> <p>Mutual authentication depends on:</p> <ul> <li>Random challenges being unpredictable large numbers</li> <li>Challenge values and authentication messages not being repeatable (replay attack)</li> <li>The shared secret key remaining secret</li> </ul> <p>Simplified mutual authentication can be susceptible to reflection attack. Here are the steps of the genuine path, with the sub-points describing the attack:</p> <ol> <li>Alice claims she's alice and sends R1<ul> <li>Charlie can impersonate Alice and send R1</li> </ul> </li> <li>Bob sends the encrypted R1 (ciphertext) and his own challenge R2<ul> <li>Charlie can receive this but doesn't have the key to encrypt R2</li> <li>In a new connection, Charlie impersonates Alice and sends R2 as the first challenge</li> <li>Bob responds with the encrypted R2, which Charlie can use in the first connection</li> </ul> </li> <li>Alice decrypts the ciphertext and matches it to R1, then sends the encrypted R2<ul> <li>Charlie impersonates Alice, sending the encrypted R2 from Bob</li> </ul> </li> </ol> <p>Defeat the MitM reflection attack by using different keys for Alice and Bob, or odd and even challenge numbers.</p> <p>Signing or encryption using public key cryptography can also be used for mutual authentication.</p>"},{"location":"course-notes/iis/intro-information-security/#establishing-session-keys","title":"Establishing Session Keys","text":"<p>Asymmetric cryptography is more computationally expensive. You can establish symmetric keys (shared secret) after authentication so that exchanging messages is more efficient.</p> <ul> <li>A long-term (master) key can be derived from some password</li> <li>Master key is used to authenticate and establish a session key</li> <li>Session keys are per-session only to limit consequence of exposure</li> </ul> <p>Diffie-Hellman key exchange is used for this purpose.</p>"},{"location":"course-notes/iis/intro-information-security/#key-distribution-center","title":"Key Distribution Center","text":"<p>A Key Distribution Center (KDC) can be used to scale the sharing of master keys with the help of the Security Service Module (SSM).</p> <p>If Alice and Bob each share a master key with the KDC:</p> <ol> <li>Alice sends a connection request packet to the SSM</li> <li>The SSM asks the KDC for permission to establish the session with Bob</li> <li> <p>KDC approves the connection request and generate and delivers a session key to Alice and Bob's SSMs</p> </li> <li> <p>The communication between any SSM and the KDC is encrypted using a master key unique to this SSM and KDC</p> </li> <li>Data exchanged between Alice and Bob is encrypted using the secret session key, which is unique to this session</li> </ol> <p>Public key certificates are exchanged through a CA. A certificate can be verified using its public key whether or not the CA is online. See public key certificate.</p>"},{"location":"course-notes/iis/intro-information-security/#kerberos-protocol","title":"Kerberos Protocol","text":"<ul> <li>Provides authentication and access control, session keys</li> <li>Uses ticket-granting-tickets, per-day keys to reduce use and transmission of master keys</li> <li>Each principal has a master key derived from a password (or configured, if not human)<ul> <li>Keys are stored encrypted in KDC</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#public-key-infrastructure-pki","title":"Public Key Infrastructure (PKI)","text":"<p>The X.509 standard defines a format for public-key certificates used in IPSec, SSL, SET, and more. The standard describes these components:</p> <ul> <li>Version</li> <li>Certificate serial number</li> <li>Signature algorithm identifier</li> <li>Issuer name</li> <li>Period of validity</li> <li>Subject name</li> <li>Subject's public-key info</li> <li>Issuer's unique identifier</li> <li>Subject's unique identifier</li> <li>Extensions</li> <li>Signature</li> </ul> <p>Most commonly these are:</p> <ul> <li>CA certificate: used only to sign other certificates</li> <li>End user certificate: used to verify identities, sign and encrypt data</li> </ul> <p>The PKI standard has these problems:</p> <ul> <li>Reliance on user to make an informed decision when certificate can't be verified</li> <li>Different implementations use different trust stores and present different security views to users</li> <li>Assumption that all CAs in the trust store are equally trusted and apply equivalent policies</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#ip-security-ipsec","title":"IP Security (IPSec)","text":"<p>The main goal is to encrypt or authenticate all traffic at the IP level, below the transport layer. It has these main protocols:</p> <ul> <li>Authentication Headers (AH) provides connectionless data integrity and data origin authentication for IP datagrams and provides protection against replay attacks.</li> <li>Encapsulating Security Payloads (ESP) provides confidentiality, connectionless data integrity, data origin authentication, an anti-replay service (a form of partial sequence integrity), and limited traffic-flow confidentiality.</li> <li>Internet Security Association and Key Management Protocol (ISAKMP) provides a framework for authentication and key exchange...</li> </ul> <p>AH uses a hash function to provide authentication. It doesn't cover mutable fields in original IP header (DSCP/ToS, ECN, Flags, Fragment Offset, TTL and Header Checksum) and does not provide encryption. AH has two modes:</p> <ul> <li>Transport mode: places authentication code in the AH header, inserted after the IP header</li> <li>Tunnel mode: places AH header after a new IP header</li> </ul> AH Modes, Wikipedia <p>AH shouldn\u2019t be used alone since ESP can also provide authentication. IPsecv3 provides backwards compatibility to support AH.</p> <p>The AH header contains:</p> <ul> <li>Next header</li> <li>Payload length</li> <li>Reserved</li> <li>Security Parameter Index (SPI)</li> <li>Sequence number<ul> <li>Optional; protects against replay attacks using sliding window</li> </ul> </li> <li>Integrity Check Value (ICV)</li> </ul> <p>If both AH and ESP are used, ESP is applied first for encryption followed by AH for authentication.</p> <p>ESP provides authentication, integrity using hash functions, and confidentiality through encryption. Integrity is computed before encryption. ESP has two modes:</p> <ul> <li>Transport mode: encrypts and optionally authenticates IP payload<ul> <li>Doesn't cover original IP header</li> <li>End-to-end (host-to-host)</li> </ul> </li> <li>Tunnel mode: protects the entire IP packet (used for VPN)<ul> <li>Encrypts the original IP header</li> <li>Gateway-to-gateway encrypted connection</li> </ul> </li> </ul> ESP Modes, Wikipedia <p>An IP can be spoofed unidirectionally, such as for DoS attacks.</p> <p>IPSec ensures that:</p> <ul> <li>A router advertisement comes from an authorized router</li> <li>A routing update is not forged</li> <li>A redirect message comes from the router to which the initial packet was sent</li> </ul> <p>Sequence number checking is used to help prevent replay attack in AH or if the authentication option in ESP is used. A sliding window checks packets:</p> <ul> <li>If the sequence number in IPSec header is greater than the largest number of the current anti-replay window, packet is authenticated and window is advanced</li> <li>If it is smaller, the packet is rejected</li> <li>Duplicates are rejected</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#internet-key-exchange-ike","title":"Internet Key Exchange (IKE)","text":"<p>Key exchange for IPSec standard can be provided by IKE. IKE:</p> <ol> <li>Establishes a shared secret using Diffie-Hellman</li> <li>Sets up a Security Association (SA), a logical group of security information describing a one-way relationship between sender and receiver</li> <li> <p>This SA is then used to negotiate further SAs for other services like IPSec</p> </li> <li> <p>IKE offers perfect forward secrecy (PFS) if the SA keys established in step 3 are independent of the SA in step 2</p> </li> <li>SAs are stored in a Security Association Database (SADB)<ul> <li>Each SA has a unique Security Parameter Index (SPI) (or SA ID) in the SADB</li> <li>SPI is included in outgoing packets and used to identify SA associated with a packet</li> </ul> </li> <li>Policies used to establish SAs are stored in the Security Policy Database (SPD)</li> </ol> <p>If the packet is outgoing, the SPD is checked for the policy.</p> <p>If the packet is incoming, the SPI is used to look up the SA in the SADB. SPD is checked for matching security measures before the packet is delivered.</p>"},{"location":"course-notes/iis/intro-information-security/#ssl-and-tls","title":"SSL and TLS","text":"<p>You may like to read What is TLS? Transport Layer Security encryption explained in plain english.</p> <ul> <li>A TLS session is created using the handshake protocol and defines the cipher suite used by connections in this session<ul> <li>Sessions are used to avoid re-negotiating every connection</li> </ul> </li> <li>A TLS connection is transient and associated with one only session</li> <li>TLS doesn't rely on IPSec</li> </ul> <p>Handshake protocol parameters include:</p> <ul> <li>The highest TLS version understood by the client</li> <li>A random 32-bit timestamp and 28 bytes from an RNG</li> <li>A session ID</li> <li>The cipher suites supported by the client</li> <li>The compression methods supported by the client</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#wifi","title":"WiFi","text":"<ul> <li>Broadcast communications with no inherent physical protection</li> <li>Security threats include:<ul> <li>Accidental association (user connects to the neighbor's network)</li> <li>Malicious association (fake WiFi access point)</li> <li>Ad hoc networks (P2P networks without central access point)</li> <li>Nontraditional networks (Bluetooth and eavesdropping)</li> <li>Identity theft (MAC spoofing)</li> <li>MitM</li> <li>DoS</li> <li>Network injection</li> </ul> </li> </ul> <p>Wireless security measures for securing transmissions include:</p> <ul> <li>Signal-hiding techniques: hide wireless AP by:<ul> <li>Turning off SSID</li> <li>Reducing signal strength</li> <li>Minimizing signal at building exterior</li> <li>Using directional antennas</li> <li>Using signal shielding</li> </ul> </li> <li>Encryption</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#wep-and-wpa2","title":"WEP and WPA2","text":"<p>You might like to read WPA Key, WPA2, WPA3, and WEP Key: Wi-Fi security explained.</p> <p>WEP is insecure. WPA introduced these improvements:</p> <ul> <li>Access control model based on IEEE 802.1X</li> <li>A flexible authentication protocol based on EAP</li> <li>Message integrity check algorithm TKIP, which dynamically generates a new 128-bit key per-packet</li> <li>(WPA2) Mandatory support for CCMP, based on AES</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#mobile-security","title":"Mobile Security","text":"<p>Android vs. iOS Sandbox permissions:</p> Android iOS App announces permissions required Apps have same permissions Installation-time approval First-use time approval App may escalate permissions No escalation"},{"location":"course-notes/iis/intro-information-security/#ios-security-overview","title":"iOS Security Overview","text":"<ul> <li>The crypto engine and keys are hardware embedded<ul> <li>Each device has dedicated AES-256 crypto engine</li> <li>Apple provides device ID (UID) and device group ID (GID) as AES 256 bit keys burned into the silicon (secure enclave)</li> </ul> </li> <li>App Sandbox isolates apps from each other</li> <li>The trusted bootchain, BootROM code is burned into hardware<ul> <li>Each step verifies the kernel is properly signed by Apple, and iOS only runs on Apple-validated devices</li> </ul> </li> <li>Uses Data Protection key hierarchy<ul> <li>Uses per-file key, files are assigned with a class</li> <li>The file key is wrapped with the class key, class key is stored in the file's metadata</li> <li>The metadata of all files is encrypted with the File System Key</li> </ul> </li> <li>Apps have mandatory code signing with Apple-issued certificates<ul> <li>There's no dynamic code generation or self-modifying code</li> <li>At run time, signature checks are performed of all executable memory pages to ensure there was no modification since the last update</li> </ul> </li> <li>App Store has restricted app distribution and developers are verified by Apple to gain certificates<ul> <li>App Store apps are reviewed by Apple</li> </ul> </li> <li>Third-party apps are sandboxed</li> <li>ASLR</li> <li>Non-executable memory pages (write and execute permissions are mutually exclusive)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#android-security-overview","title":"Android Security Overview","text":"<ul> <li>The software stack is based on Linux kernel</li> <li>Uses Android Runtime (Dalvik VM), Java-based core libraries wrapping C and C++ libraries</li> <li>Application sandbox is essentially provided from the VM<ul> <li>UID provides CPU and memory protection enforced by Unix kernel</li> </ul> </li> <li>Apps are self-signed by developers, no vetting<ul> <li>Code signing is used to ensure apps come from the same developer, to facilitate upgrades</li> </ul> </li> </ul>"},{"location":"course-notes/iis/intro-information-security/#web-security","title":"Web Security","text":"<p>You may like to read SQL injection and XSS: what white hat hackers know about trusting user input.</p> <p>Injection attacks include:</p> <ul> <li>Cross Site Scripting (XSS): code is injected into a web page and changes that page's behavior</li> <li>SQLi: malicious actors may be able to send SQL commands that affect a SQL DB; see Bobby Tables</li> <li>Cross-Site Request Forgery (CSRF): a separate external site causes a user to send unauthorized commands to a target site</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#cybercrime-law","title":"Cybercrime Law","text":"<p>US Computer Fraud and Abuse Act (CFAA) defines criminal sanctions for unauthorized access.</p> <p>The Convention on Cybercrime sets out a common criminal policy defining:</p> <ul> <li>Illegal access</li> <li>Illegal interception</li> <li>Data interference</li> <li>System intereference</li> <li>Misuse of devices</li> <li>Computer-related forgery</li> <li>Computer-related fraud</li> <li>Offenses related to child pornography</li> <li>Infringements of copyright and related rights</li> <li>Attempt at aiding or abetting</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#intellectual-property","title":"Intellectual Property","text":"<p>Three types of property (US legal system):</p> <ul> <li>Real property: land and things attached to them that you can't pick up and move</li> <li>Personal property: things you can move, or that you own</li> <li>Intellectual property: intangible assets that consist of human knowledge and ideas</li> </ul> <p>Copyrights protect the tangible expressions of an idea. Rights protected against infringement include:</p> <ul> <li>Reproduction</li> <li>Modification</li> <li>Distribution</li> <li>Public performance</li> <li>Public display</li> </ul> <p>Types of patents include:</p> <ul> <li>Utility: for inventing or discovering any new and useful process, machine, articule of manufacturer, composition of matter, or new and useful improvement</li> <li>Design: for inventing a new, original, and ornamental design for an article of manufacture</li> <li>Plan: for inventing or discovering and asexually reproducing a distinct and new plant variety</li> </ul> <p>Software, databases, digital content, and algorithms are intellectual property. For example, RSA was patented by RSA Security from 1983-2000.</p> <p>The Digital Millennium Copyright Act (DMCA) seeks to protect intellectual property (IP) by defining circumventing anti-piracy functionality as a crime.</p> <p>Exemptions to the DMCA:</p> <ul> <li>Fair use</li> <li>Reverse engineering</li> <li>Encryption research (Ed Felten's reserach on audio watermarking removal)</li> <li>Security testing</li> <li>Personal privacy</li> </ul> <p>Digital Rights Management (DRM) is not a single standard but refers generally to systems that ensure identification of holders of digital rights. A typical model has these components:</p> <ul> <li>Content provider (e.g. music record label)</li> <li>Distributor (e.g. online shop)</li> <li>Consumer (uses the system and pays for the digital license)</li> <li>Clearinghouse (pays royalties to content provider, distributor)</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#ethics","title":"Ethics","text":"<p>Professional Codes of Conduct provide guidance and articulate ethical expectations, since ethics cannot be reduced to precise laws or facts. E.g. the ACM, IEEE, and AITP have codes and standards of conduct. Common themes include:</p> <ol> <li>Dignity and worth of other people</li> <li>Personal integrity and honesty</li> <li>Responsibility for work</li> <li>Confidentiality of information</li> <li>Public safety, health, welfare</li> <li>Participation in professional societies to improve professional standards</li> <li>The idea that public knowledge and access to technology is equivalent to social power</li> </ol> <p>The Rules, or Moral Responsibility for Computing Artifacts, are guidelines produced by the Ad Hoc Committee on Responsible Computing. Generally, they say that people who design, develop, or deploy computing artifacts (programs) are responsible (shared responsibility) for the foreseeable effects of doing so.</p>"},{"location":"course-notes/iis/intro-information-security/#privacy","title":"Privacy","text":"<p>General privacy policy guidelines address:</p> <ul> <li>Consent: participants can make informed decisions</li> <li>Privacy and confidentiality</li> <li>Ownership and authorship: who has the responsibilty for and rights to the data</li> <li>Data sharing: data matching and reuse related to the social benefits of research</li> <li>Governance and custodianship: oversight and implementation of the management, organization, access, and preservation of data</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#oecd-privacy-guidelines","title":"OECD Privacy Guidelines","text":"<p>The OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data address:</p> <ul> <li>Collection limitation</li> <li>Data quality</li> <li>Purpose specification</li> <li>Use limitation</li> <li>Security safeguards</li> <li>Openness</li> <li>Individual participation:<ul> <li>to obtain from a data controller, or otherwise, confirmation of whether or not the data controller has data relating to them;</li> <li>to have communicated to them, data relating to them within a reasonable time; at a charge, if any, that is not excessive; in a reasonable manner; and in a form that is readily intelligible to them;</li> <li>to be given reasons if a request made under (a) and (b) is denied, and to be able to challenge such denial</li> <li>to challenge data relating to them and, if the challenge is successful to have the data erased, rectified, completed, or amended.</li> </ul> </li> <li>Accountability</li> </ul>"},{"location":"course-notes/iis/intro-information-security/#it-security-controls","title":"IT Security Controls","text":"<p>Risk is the potential for loss computed as the combination of:</p> <ul> <li>Likelihood that a given threat exploits a vulnerability to an asset</li> <li>Magnitude of harmful consequences that result</li> </ul> <p>An equation for calculating risk is: (Probability that threat occurs) x (Cost to organization)</p> <p>Security control classes include:</p> <ul> <li>Management Controls (security policies, guidelines, standards)</li> <li>Operational Controls (Implementing security policy and standards with mechanisms)</li> <li>Technical Controls (Correctly using hardware and software security capabilties)</li> </ul> <p>Each class can include:</p> <ul> <li>Supportive controls</li> <li>Preventative controls (mitigations)</li> <li>Detection and recovery controls (detecting and responding to a breach)</li> </ul>"}]}